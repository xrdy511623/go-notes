
---
CPU使用率
---


# 1 CPU使用率

Linux通过/proc虚拟文件系统，向用户空间提供了系统内部状态的信息，而/proc/stat提供的就是系统的CPU和任务统计信息。比如，
如果你只关注CPU的话，可以执行下面的命令:




![grep-cpu.png](images%2Fgrep-cpu.png)





这里的输出结果是一个表格。其中，第一列表示的是CPU编号，如CPU0，CPU1，而第一行没有编号的CPU，表示的是所有CPU的累加。
其他列则表示不同场景下CPU的累加节拍数，其单位是USER_HZ，也就是10ms(1/100秒)，所以这其实就是不同场景下的CPU时间。





![top-cpu.png](images%2Ftop-cpu.png)





user(通常缩写为us)，代表用户态CPU时间。注意，它不包括下面的nice时间，但是包含了guest时间。
这个比例越高，说明CPU的利用率越好，因为我们的目的就是让CPU将更多的时间用在执行用户代码上。如果这一项过高引起了业务抖动，那就需要去分析业务代码了。
nice(通常缩写为ni)，代表低优先级用户态CPU时间，也就是进程的nice值被调整为1-19之间时的CPU时间。这里注意，nice可取值范围是-20到19，数值越大，优先级反而越低。
system(通常缩写为sys)，代表内核态CPU时间，这个比例越低越好，因为CPU不应该把时间浪费在执行内核函数上，如果在内核函数里浪费了很多时间，那说明内核可能需要优化了。
idle(通常缩写为id)，代表空闲CPU时间。注意，它不包括等待I/O的时间(iowait)。为了提升系统的资源利用率，我们的目标就是尽量降低idle，当然降低idle的前提是业务的SLA不应该受到影响。
iowait(通常缩写为wa)，代表等待I/O的CPU时间，也就是CPU阻塞在I/O上的时间。比如说CPU从磁盘读取文件内容时，由于磁盘I/O太慢，导致CPU不得不等待数据就绪，然后才能继续执行下一步操作，这就是wa时间。这个值越高，说明I/O处理能力出现了问题。
irq(通常缩写为hi)，代表处理硬中断的CPU时间。正常情况下这个值都很低，因为中断处理是很快的，即使有大量的硬件中断，也不会消耗很多的CPU时间。
softirq(通常缩写为si)，代表处软中断的CPU时间。系统中常见的软中断有网络收发包的软中断、写文件落盘产生的软中断等。在网络吞吐量高的系统中，这个值也会高一些。
steal(通常缩写为st)，代表当系统运行在虚拟机的时候，被其他虚拟机占用的CPU时间。
guest(通常缩写为guest)，代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的CPU时间。
guest_nice(通常缩写为gnice)，代表以低优先级运行虚拟机的时间。


而我们通常所说的CPU使用率，就是除了空闲时间外的其他时间占总CPU时间的百分比，用公式来表示就是:
CPU使用率 = 1 - 空闲时间/总CPU时间

根据这个公式，我们就可以从/proc/stat中的数据，很容易的计算出CPU的使用率。当然，也可以用每一个场景的CPU时间，除以总的CPU时间，计算出每个场景的CPU使用率。
但是这些时间都是系统开机启动以来的节拍数累加值，所以直接算出来的，是开机以来的平均CPU使用率，参考价值不大。
事实上，为了计算CPU使用率，性能工具(top, vmstat等)一般都会取间隔一段时间(比如3秒)的两次值，作差后，再计算出这段时间内的平均CPU使用率，即
平均CPU使用率 = 1 - （new空闲时间 -  old空闲时间）/  （new总CPU时间 - old总CPU时间）

这个公式，就是我们用各种性能工具所看到的CPU使用率的实际计算方法。


跟系统的指标类似，Linux也给每个进程提供了运行情况的统计信息，也就是/proc/[pid]/stat。不过，这个文件包含的数据就比较丰富了，总共有52列数据。

性能分析工具给出的都是间隔一段时间的平均CPU使用率，所以要注意间隔时间的设置，特别是用多个工具对比分析时，一定要保证它们用的是相同的间隔时间。
比如，对比一下top和ps这两个工具报告的CPU使用率，默认的结果很可能不一样，因为top默认使用3秒时间间隔，而ps使用的却是进程的整个生命周期。


# 2 如何查看CPU使用率？

top显示的是系统整体的CPU和内存使用情况，以及各个进程的资源使用情况。
ps则只显示了每个进程的资源使用情况。
top的输出格式为：





![top-whole.png](images%2Ftop-whole.png)





这个输出结果中，第三行%CPU就是系统的CPU使用率，具体每一列就是不同场景下的CPU使用率，比如us表示用户态CPU使用率，sy表示
系统内核态CPU使用率等等。需要注意的是，top默认显示的是所有CPU的平均值，此时只需要按下数字1，就可以切换到每个CPU的使用率了。

继续往下看，空白行之后是进程的实时信息，每个进程都有一个%CPU列，表示进程的CPU使用率。它是进程用户态和内核态CPU使用率的总和，
包括进程用户空间使用的CPU，通过系统调用执行的内核空间CPU，以及在就绪队列等待运行的CPU。在虚拟化环境中，它还包括了运行虚拟机占用的CPU。
top并没有细分进程的用户态CPU和内核态CPU，要了解具体细分场景下的CPU使用率，可以使用pidstat工具。

每隔3秒输出一组数据，共输出5组





![pidstat-cpu.png](images%2Fpidstat-cpu.png)





上面的pidstat命令，间隔3秒展示了进程的5组CPU使用率，包括:
用户态CPU使用率(%usr)
内核态CPU使用率(%system)
运行虚拟机CPU使用率(%guest)
等待CPU使用率(%wait)
总的CPU使用率(%CPU)

最后的Average部分，还计算了5组数据的平均值。


# 3 CPU使用率过高怎么办？

通过top，ps，pidstat等工具，我们能够轻松找到CPU使用率较高(比如100%)的进程，那接下来如何找到占用CPU的到底是代码里的
哪个函数呢？这里推荐使用perf。perf是Linux 2.6.31后内置的性能分析工具，它以性能事件采样为基础，不仅可以分析系统的
各种事件和内核性能，还可以用来分析指定应用程序的性能问题。

使用perf分析CPU性能问题，最常用的两种方法是perf top 以及组合使用perf record和perf report

perf top类似于top，能够实时显示占用CPU时钟最多的函数或指令，因此可以用来查找热点函数。





![perf-top.png](images%2Fperf-top.png)





输出结果中，第一行包含3个数据，分别是采样数(samples)，事件类型(event)和事件总数量(Event count)。比如上面这个例子，
perf总共采集了1k(1000)个CPU时钟事件，而总事件数则为244937500。
另外，采样数据需要我们特别注意，如果采样数过少(比如只有十几个)，那下面的排序和百分比就没有什么实际参考价值了。

再往下看是一个表格样式的数据，每一行包含四列，分别是：
第一列Overhead，是该符号的性能事件在所有采样事件中的比例，用百分比来表示。
第二列Shared，是该函数或指令所在的动态共享对象(Dynamic Shared Object)，如内核、进程名、动态链接库名、内核模块名。
第三列Object，是动态共享对象的类型。比如[.]表示用户空间的可执行程序、或者动态链接库，而[k]则表示内核空间。

最后一列Symbol是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。
以上面的输出为例，占用CPU时钟最多的是perf工具自身，不过它的比例也只有7.28%，说明系统并没有性能问题。

Perf top虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或后续的分析。而perf record则提供了
保存数据的功能(按下Ctrl+C终止采样)，保存后的数据，需要使用perf report来解析展示。

在实际使用中，我们还经常为perf top和perf record加上-g参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。


**总结**

用户CPU和Nice CPU使用率高，说明用户态进程占用了较多的CPU，所以应该着重排查进程的性能问题。
系统CPU使用率高，说明内核态占用了较多的CPU，应该着重排查内核线程或者系统调用的性能问题。
I/O等待CPU使用率高，说明等待I/O的时间比较长，所以应该着重排查系统存储是不是出现了I/O问题。
软中断和硬中断使用率高，说明软中断或硬中断的处理程序占用了较多的CPU，所以应该着重排查内核中的中断处理服务程序。

碰到CPU使用率升高的问题，我们可以使用top、pidstat等工具，确认引发CPU性能问题的来源；然后再使用perf等工具，
排查出引起性能问题的具体函数。