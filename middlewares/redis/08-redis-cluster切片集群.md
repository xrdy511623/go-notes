
---
切⽚集群：数据增多了，是该加内存还是加实例？
---


# 1 纵向扩展的瓶颈

假设有这么⼀个需求：要⽤Redis保存5000万个键值对，每个键值对⼤约是512B，为了能快速部署并对
外提供服务，我们采⽤云主机来运⾏Redis实例，那么，该如何选择云主机的内存容量呢？

我们可以粗略地计算⼀下，这些键值对所占的内存空间⼤约是25GB（5000万*512B）。所以，我们可能想到的
第⼀个⽅案就是：选择⼀台32GB内存的云主机来部署Redis。因为32GB的内存能保存所有数据，⽽且还留
有7GB，可以保证系统的正常运⾏。同时，还采⽤RDB对数据做持久化，以确保Redis实例故障后，还能
从RDB恢复数据。

但是，在使⽤的过程中，我发现，Redis的响应有时会⾮常慢。后来，我们使⽤INFO命令查看Redis的
latest_fork_usec指标值（表⽰最近⼀次fork的耗时），结果显⽰这个指标值特别⾼，快到秒级别了。
这跟Redis的持久化机制有关系。在使⽤RDB进⾏持久化时，Redis会fork⼦进程来完成，fork操作的⽤时和
Redis的数据量是正相关的，⽽fork在执⾏时会阻塞主线程。数据量越⼤，fork操作造成的主线程阻塞的时
间越⻓。所以，在使⽤RDB对25GB的数据进⾏持久化时，数据量较⼤，后台运⾏的⼦进程在fork创建时阻
塞了主线程，于是就导致Redis响应变慢了。

看来，第⼀个⽅案显然是不可⾏的，我们必须要寻找其他的⽅案。这个时候，我们注意到了Redis的切⽚集
群。虽然组建切⽚集群⽐较⿇烦，但是它可以保存⼤量数据，⽽且对Redis主线程的阻塞影响较⼩。

切⽚集群，也叫分⽚集群，就是指启动多个Redis实例组成⼀个集群，然后按照⼀定的规则，把收到的数据
划分成多份，每⼀份⽤⼀个实例来保存。回到我们刚刚的场景中，如果把25GB的数据平均分成5份（当然，
也可以不做均分），使⽤5个实例来保存，每个实例只需要保存5GB数据。如下图所⽰：





![cluster-store-data-demo.png](images%2Fcluster-store-data-demo.png)





那么，在切⽚集群中，实例在为5GB数据⽣成RDB时，数据量就⼩了很多，fork⼦进程⼀般不会给主线程带
来较⻓时间的阻塞。采⽤多个实例保存数据切⽚后，我们既能保存25GB数据，⼜避免了fork⼦进程阻塞主
线程⽽导致的响应突然变慢。

在实际应⽤Redis时，随着⽤⼾或业务规模的扩展，保存⼤量数据的情况通常是⽆法避免的。⽽切⽚集群，
就是⼀个⾮常好的解决⽅案。


# 2 如何保存更多数据？

在刚刚的案例⾥，为了保存⼤量数据，我们使⽤了⼤内存云主机和切⽚集群两种⽅法。实际上，这两种⽅法
分别对应着Redis应对数据量增多的两种⽅案：纵向扩展（scale up）和横向扩展（scale out）。

纵向扩展：升级单个Redis实例的资源配置，包括增加内存容量、增加磁盘容量、使⽤更⾼配置的CPU。
就像下图中，原来的实例内存是8GB，硬盘是50GB，纵向扩展后，内存增加到24GB，磁盘增加到
150GB。

横向扩展：横向增加当前Redis实例的个数，比如原来使⽤1个8GB内存、50GB磁盘的实例，现
在使⽤三个相同配置的实例。

那么，这两种⽅式的优缺点分别是什么呢？

⾸先，纵向扩展的好处是，实施起来简单、直接。不过，这个⽅案也⾯临两个潜在的问题。

第⼀个问题是，当使⽤RDB对数据进⾏持久化时，如果数据量增加，需要的内存也会增加，主线程fork⼦进
程时就可能会阻塞（⽐如刚刚的例⼦中的情况）。不过，如果你不要求持久化保存Redis数据，那么，纵向
扩展会是⼀个不错的选择。

不过，这时，你还要⾯对第⼆个问题：纵向扩展会受到硬件和成本的限制。这很容易理解，毕竟，把内存从
32GB扩展到64GB还算容易，但是，要想扩充到1TB，就会⾯临硬件容量和成本上的限制了。

与纵向扩展相⽐，横向扩展是⼀个扩展性更好的⽅案。这是因为，要想保存更多的数据，采⽤这种⽅案的
话，只⽤增加Redis的实例个数就⾏了，不⽤担⼼单个实例的硬件和成本限制。在⾯向百万、千万级别的⽤
⼾规模时，横向扩展的Redis切⽚集群会是⼀个⾮常好的选择。

不过，在只使⽤单个实例的时候，数据存在哪⼉，客⼾端访问哪⼉，都是⾮常明确的，但是，切⽚集群不可
避免地涉及到多个实例的分布式管理问题。要想把切⽚集群⽤起来，我们就需要解决两⼤问题：

数据切⽚后，在多个实例之间如何分布？
客⼾端怎么确定想要访问的数据在哪个实例上？

接下来，我们来看，redis cluster是如何解决这两个问题的。


# 3 数据切⽚和实例的对应分布关系

在切⽚集群中，数据需要分布在不同实例上，那么，数据和实例之间如何对应呢？这就和接下来我要讲的
Redis Cluster⽅案有关了。不过，我们要先弄明⽩切⽚集群和Redis Cluster的联系与区别。

实际上，切⽚集群是⼀种保存⼤量数据的通⽤机制，这个机制可以有不同的实现⽅案。在Redis 3.0之前，
官⽅并没有针对切⽚集群提供具体的⽅案。从3.0开始，官⽅提供了⼀个名为Redis Cluster的⽅案，⽤于实
现切⽚集群。Redis Cluster⽅案中就规定了数据和实例的对应规则。

具体来说，Redis Cluster⽅案采⽤哈希槽（Hash Slot，接下来我会直接称之为Slot），来处理数据和实例
之间的映射关系。在Redis Cluster⽅案中，⼀个切⽚集群共有16384个哈希槽，这些哈希槽类似于数据分
区，每个键值对都会根据它的key，被映射到⼀个哈希槽中。

具体的映射过程分为两⼤步：⾸先根据键值对的key，按照CRC16算法计算⼀个16 bit的值；然后，再⽤这
个16bit值对16384取模，得到0~16383范围内的模数，每个模数代表⼀个相应编号的哈希槽。

那么，这些哈希槽⼜是如何被映射到具体的Redis实例上的呢？

我们在部署Redis Cluster⽅案时，可以使⽤cluster create命令创建集群，此时，Redis会⾃动把这些槽平均
分布在集群实例上。例如，如果集群中有N个实例，那么，每个实例上的槽个数为16384/N个。

当然， 我们也可以使⽤cluster meet命令⼿动建⽴实例间的连接，形成集群，再使⽤cluster addslots命
令，指定每个实例上的哈希槽个数。

举个例⼦，假设集群中不同Redis实例的内存⼤⼩配置不⼀，如果把哈希槽均分在各个实例上，在保存相同
数量的键值对时，和内存⼤的实例相⽐，内存⼩的实例就会有更⼤的容量压⼒。遇到这种情况时，你可以根
据不同实例的资源配置情况，使⽤cluster addslots命令⼿动分配哈希槽。

下面这张图展示了，数据、哈希槽、实例这三者的映射分布情况。





![data-map-into-shard.png](images%2Fdata-map-into-shard.png)





⽰意图中的切⽚集群⼀共有3个实例，同时假设有5个哈希槽，我们⾸先可以通过下⾯的命令⼿动分配哈希
槽：实例1保存哈希槽0和1，实例2保存哈希槽2和3，实例3保存哈希槽4。

```shell
redis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1
redis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3
redis-cli -h 172.16.19.5 –p 6379 cluster addslots 4
```

在集群运⾏的过程中，key1和key2计算完CRC16值后，对哈希槽总个数5取模，再根据各⾃的模数结果，就
可以被映射到对应的实例1和实例3上了。

另外，需要注意的是，在⼿动分配哈希槽时，需要把16384个槽都分配完，否则Redis集群⽆法正常
⼯作。

好了，通过哈希槽，切⽚集群就实现了数据到哈希槽、哈希槽再到实例的分配。但是，即使实例有了哈希槽
的映射信息，客⼾端⼜是怎么知道要访问的数据在哪个实例上呢？


# 4 客户端如何定位数据？

在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客⼾端发送请求时来执⾏。
但是，要进⼀步定位到实例，还需要知道哈希槽分布在哪个实例上。

⼀般来说，客⼾端和集群实例建⽴连接后，实例就会把哈希槽的分配信息发给客⼾端。但是，在集群刚刚创
建的时候，每个实例只知道⾃⼰被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。

那么，客⼾端为什么可以在访问任何⼀个实例时，都能获得所有的哈希槽信息呢？这是因为，Redis实例会
把⾃⼰的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，
每个实例就有所有哈希槽的映射关系了。

客⼾端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客⼾端请求键值对时，会先计算键所对应的哈希
槽，然后就可以给相应的实例发送请求了。

但是，在集群中，实例和哈希槽的对应关系并不是⼀成不变的，最常⻅的变化有两个：

在集群中，实例有新增或删除，Redis需要重新分配哈希槽；
为了负载均衡，Redis需要把哈希槽在所有实例上重新分布⼀遍。

此时，实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客⼾端是⽆法主动感知这些
变化的。这就会导致，它缓存的分配信息和最新的分配信息就不⼀致了，那该怎么办呢？

Redis Cluster⽅案提供了⼀种重定向机制，所谓的“重定向”，就是指，客⼾端给⼀个实例发送数据读写操
作时，这个实例上并没有相应的数据，客⼾端要再给⼀个新实例发送操作命令。

那客⼾端⼜是怎么知道重定向时的新实例的访问地址呢？当客⼾端把⼀个键值对的操作请求发给⼀个实例
时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客⼾端返回下⾯的MOVED命
令响应结果，这个结果中就包含了新实例的访问地址。

```shell
GET hello:key
(error) MOVED 13320 172.16.19.5:6379
```

其中，MOVED命令表⽰，客⼾端请求的键值对所在的哈希槽13320，实际是在172.16.19.5这个实例上。通
过返回的MOVED命令，就相当于把哈希槽所在的新实例的信息告诉给客⼾端了。这样⼀来，客⼾端就可以
直接和172.16.19.5连接，并发送操作请求了。

我画⼀张图来说明⼀下，MOVED重定向命令的使⽤⽅法。可以看到，由于负载均衡，Slot 2中的数据已经从
实例2迁移到了实例3，但是，客⼾端缓存仍然记录着“Slot 2在实例2”的信息，所以会给实例2发送命令。
实例2给客⼾端返回⼀条MOVED命令，把Slot 2的最新位置（也就是在实例3上），返回给客⼾端，客⼾端就
会再次向实例3发送请求，同时还会更新本地缓存，把Slot 2与实例的对应关系更新过来。






![cluster-move.png](images%2Fcluster-move.png)





需要注意的是，在上图中，当客⼾端给实例2发送命令时，Slot 2中的数据已经全部迁移到了实例3。在实际
应⽤时，如果Slot 2中的数据⽐较多，就可能会出现⼀种情况：客⼾端向实例2发送请求，但此时，Slot 2中
的数据只有⼀部分迁移到了实例3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客⼾端就会收
到⼀条ASK报错信息，如下所⽰：

```shell
GET hello:key
(error) ASK 13320 172.16.19.5:6379
```

这个结果中的ASK命令就表⽰，客⼾端请求的键值对所在的哈希槽13320，在172.16.19.5这个实例上，但是
这个哈希槽正在迁移。此时，客⼾端需要先给172.16.19.5这个实例发送⼀个ASKING命令。这个命令的意思
是，让这个实例允许执⾏客⼾端接下来发送的命令。然后，客⼾端再向这个实例发送GET命令，以读取数据。

看起来好像有点复杂，我再借助图⽚来解释⼀下。

在下图中，Slot 2正在从实例2往实例3迁移，key1和key2已经迁移过去，key3和key4还在实例2。客⼾端向
实例2请求key2后，就会收到实例2返回的ASK命令。

ASK命令表⽰两层含义：第⼀，表明Slot数据还在迁移中；第⼆，ASK命令把客⼾端所请求数据的最新实例
地址返回给客⼾端，此时，客⼾端需要给实例3发送ASKING命令，然后再发送操作命令。






![cluster-ask.png](images%2Fcluster-ask.png)





和MOVED命令不同，ASK命令并不会更新客⼾端缓存的哈希槽分配信息。所以，在上图中，如果客⼾端再
次请求Slot 2中的数据，它还是会给实例2发送请求。这也就是说，ASK命令的作⽤只是让客⼾端能给新实例
发送⼀次请求，⽽不像MOVED命令那样，会更改本地缓存，让后续所有命令都发往新实例。


# 5 为什么是 16384 个哈希槽？

Redis Cluster 选择 16384（2^14）个槽而非更大的数，是经过精心权衡的设计决策。

**Gossip 消息体大小的约束**

集群节点之间通过 Gossip 协议交换信息，每条消息都需要携带发送方的**槽位图（slot bitmap）**，用来告知对方"我负责哪些槽"。槽位图的大小为：

```
槽数 / 8 = 位图字节数

16384 / 8 = 2KB
65536 / 8 = 8KB
```

如果使用 65536 个槽，每条 Gossip 消息就要多携带 6KB 的数据。集群中每个节点每秒会与多个节点交换消息，**消息体过大会显著增加网络带宽消耗**，尤其在大规模集群中。

**集群规模的上限**

Redis 官方建议集群节点数不超过 **1000 个**。如果有 1000 个主节点，每个节点平均分配约 16 个槽，粒度已经足够细。使用更多的槽数不会带来更好的数据分布均匀性，反而会增加通信开销。

**压缩效率**

当节点数较少时（这是绝大多数场景），槽位图中大部分位是连续的 0 或 1，这种稀疏/密集分布非常适合压缩。16384 位的位图在大多数情况下压缩效率很好。

> Redis 作者 antirez 在 GitHub issue 中明确说明了这个设计决策：16384 是在**消息体大小、集群规模、分布粒度**三者之间的最佳平衡点。


# 6 Gossip 协议：集群的通信机制

Redis Cluster 中的节点之间没有使用中心化的配置服务器，而是通过 **Gossip 协议**实现去中心化的信息传播。每个节点都维护着集群的完整状态，并通过周期性的消息交换来保持状态一致。

## 6.1 Gossip 消息类型

| 消息类型 | 发送时机 | 携带信息 | 作用 |
|---------|---------|---------|------|
| **MEET** | `cluster meet` 命令触发 | 发送方节点信息 | 将新节点加入集群 |
| **PING** | 每秒随机选取节点发送 | 发送方信息 + 部分已知节点信息 | 探活 + 传播集群状态 |
| **PONG** | 收到 PING/MEET 后回复 | 与 PING 相同 | 确认存活 + 传播集群状态 |
| **FAIL** | 确认某节点故障后广播 | 故障节点 ID | 通知所有节点某节点已下线 |
| **PUBLISH** | 客户端执行 PUBLISH 命令 | 频道 + 消息内容 | 在集群中传播 pub/sub 消息 |

## 6.2 PING/PONG 消息结构

每条 PING/PONG 消息由**消息头**和**消息体**两部分组成：

```
消息头（clusterMsg）:
  ├── 发送方节点 ID、IP、端口
  ├── 发送方负责的槽位图（16384 bit = 2KB）
  ├── 发送方的 configEpoch
  └── 集群状态标志（如 CLUSTER_OK / CLUSTER_FAIL）

消息体（clusterMsgDataGossip[]）:
  ├── 节点 1: ID、IP、端口、标志、最近PING/PONG时间
  ├── 节点 2: ...
  └── ... (默认携带集群中 1/10 的节点信息)
```

每次 PING 消息会随机选取集群中 **1/10 的节点信息**放入消息体，这样经过几轮交换后，集群中每个节点都能获得所有节点的最新状态。

## 6.3 通信频率与带宽控制

Redis Cluster 对 Gossip 消息的发送频率做了精细控制：

1. **每秒随机 PING**：每个节点每秒随机选取 **5 个节点**，从中挑选最久没有通信的 **1 个**发送 PING
2. **超时补偿 PING**：如果某个节点超过 `cluster-node-timeout / 2` 时间没有收到 PONG，立即补发 PING
3. **FAIL 广播**：当确认节点故障时，使用广播而非 Gossip 传播，确保所有节点尽快收到

这种设计在保证**故障检测及时性**的同时，将 Gossip 消息的带宽开销控制在合理范围内。对于一个 200 节点的集群，每个节点每秒的 Gossip 流量约为几十 KB。


# 7 集群的主从架构与故障转移

Redis Cluster 并不只是一个数据分片方案，它同时内置了**高可用机制**。每个负责哈希槽的主节点（master）可以配备一个或多个从节点（replica），当主节点故障时，从节点会自动提升为主节点。

## 7.1 集群主从拓扑

一个典型的 6 节点集群（3 主 3 从）拓扑如下：

```
Master-1 (slots 0-5460)      ←→  Replica-1
Master-2 (slots 5461-10922)  ←→  Replica-2
Master-3 (slots 10923-16383) ←→  Replica-3
```

创建集群时可以通过 `--cluster-replicas` 指定每个主节点的从节点数量：

```bash
redis-cli --cluster create \
  192.168.1.1:6379 192.168.1.2:6379 192.168.1.3:6379 \
  192.168.1.4:6379 192.168.1.5:6379 192.168.1.6:6379 \
  --cluster-replicas 1
```

## 7.2 故障检测：PFAIL → FAIL

集群的故障检测与哨兵机制类似，也分为主观下线和客观下线两个阶段，但实现细节不同：

**第一阶段：PFAIL（Probable Fail，疑似下线）**

当节点 A 在 `cluster-node-timeout` 时间内没有收到节点 B 的 PONG 回复，A 就将 B 标记为 **PFAIL**。PFAIL 是节点 A 的单方面判断，相当于哨兵的"主观下线"。

**第二阶段：FAIL（确认下线）**

PFAIL 标记会通过 Gossip 消息传播给其他节点。当节点 A 收集到**超过半数的主节点**都将 B 标记为 PFAIL 时，A 就将 B 的状态升级为 **FAIL**，并向集群广播 FAIL 消息。

```
时间线：
  T0: 节点B停止响应
  T1: 节点A标记B为PFAIL（经过cluster-node-timeout）
  T2: 通过Gossip传播，多个主节点将B标记为PFAIL
  T3: 某主节点收集到半数以上PFAIL → 广播FAIL
  T4: 触发故障转移
```

**PFAIL→FAIL 与哨兵 SDOWN→ODOWN 的差异**：

| 对比维度 | 哨兵模式 | Cluster 模式 |
|---------|---------|-------------|
| 检测者 | 专用哨兵实例 | 集群中的所有主节点 |
| 判定阈值 | quorum（可配置） | 半数以上主节点（固定） |
| 信息传播 | `is-master-down-by-addr` 主动询问 | Gossip 被动传播 + FAIL 广播 |
| 检测延迟 | 通常更快（1s PING） | 受 Gossip 传播速度影响 |

## 7.3 自动故障转移

当主节点被标记为 FAIL 后，其从节点会自动发起故障转移，流程如下：

1. **资格检查**：从节点检查自己与故障主节点的最近通信时间，如果断开时间超过 `cluster-node-timeout * cluster-replica-validity-factor`，该从节点放弃竞选（数据太旧）
2. **延迟竞选**：所有合格的从节点按照**复制偏移量**计算一个延迟时间——偏移量越大（数据越新）的从节点延迟越短，越先发起选举
3. **拉票**：从节点向所有主节点发送 `FAILOVER_AUTH_REQUEST`，请求投票
4. **投票**：每个主节点在同一个 `currentEpoch` 中只能投一票（先到先得）
5. **当选**：如果从节点获得**超过半数主节点**的投票，它将自己提升为主节点
6. **接管**：新主节点广播 PONG 消息通知所有节点更新槽映射，旧主节点恢复后自动变为新主节点的从节点

> **设计亮点**：通过复制偏移量来设置竞选延迟，可以让数据最新的从节点优先当选，最大程度减少数据丢失。这一机制不需要额外的仲裁节点（如哨兵），是 Redis Cluster 的自治特性之一。


# 8 集群扩缩容

生产环境中，随着业务增长或缩减，需要对集群进行扩缩容操作。Redis 提供了 `redis-cli --cluster` 工具来简化这些操作。

## 8.1 扩容：添加节点

扩容分两步：**添加节点**和**迁移槽**。

```bash
# 第一步：将新节点加入集群（作为空的主节点）
redis-cli --cluster add-node 192.168.1.7:6379 192.168.1.1:6379

# 第二步：将部分槽从现有节点迁移到新节点
redis-cli --cluster reshard 192.168.1.1:6379 \
  --cluster-from <source-node-id> \
  --cluster-to <new-node-id> \
  --cluster-slots 4096

# 也可以添加从节点来提高新主节点的可用性
redis-cli --cluster add-node 192.168.1.8:6379 192.168.1.7:6379 \
  --cluster-slave --cluster-master-id <master-node-id>
```

**reshard 的内部过程**：

```
对于每个要迁移的槽 S：
  1. 目标节点执行 CLUSTER SETSLOT S IMPORTING <source-id>
  2. 源节点执行 CLUSTER SETSLOT S MIGRATING <target-id>
  3. 循环：源节点 CLUSTER GETKEYSINSLOT S <count> → MIGRATE 到目标节点
  4. 所有 key 迁移完毕后，广播 CLUSTER SETSLOT S NODE <target-id>
```

在迁移过程中，客户端访问正在迁移的槽时可能收到 ASK 重定向（如第 4 节所述），这保证了迁移期间服务不中断。

## 8.2 缩容：移除节点

缩容是扩容的逆操作：**先迁移槽，再移除节点**。

```bash
# 第一步：将该节点的所有槽迁移到其他节点
redis-cli --cluster reshard 192.168.1.1:6379 \
  --cluster-from <removing-node-id> \
  --cluster-to <target-node-id> \
  --cluster-slots <slot-count>

# 第二步：移除已经没有任何槽的空节点
redis-cli --cluster del-node 192.168.1.1:6379 <removing-node-id>
```

> **注意**：如果要移除的是主节点，必须先将它的所有槽迁走；如果要移除的是从节点，可以直接删除。

## 8.3 自动均衡

当多次扩缩容后槽分布不均匀时，可以使用 `rebalance` 命令自动均衡：

```bash
# 按照各节点权重自动均衡槽分布
redis-cli --cluster rebalance 192.168.1.1:6379

# 指定节点权重（默认都是1）
redis-cli --cluster rebalance 192.168.1.1:6379 \
  --cluster-weight <node-id-1>=2 <node-id-2>=1
```


# 9 集群的限制与使用注意事项

Redis Cluster 虽然强大，但有一些重要的限制需要了解。

## 9.1 多 key 操作限制

Redis Cluster 中，**涉及多个 key 的命令（如 MGET、MSET、SUNION 等）要求所有 key 必须位于同一个哈希槽**。否则会返回 `CROSSSLOT` 错误：

```shell
# 错误：key1 和 key2 可能在不同的槽
MGET key1 key2
(error) CROSSSLOT Keys in request don't hash to the same slot
```

**解决方案——Hash Tag**：

通过在 key 中使用 `{}` 语法，Redis 只对 `{}` 内的部分计算哈希值，从而将相关 key 映射到同一个槽：

```shell
# user:{1000}:name 和 user:{1000}:email 会被分配到同一个槽
# 因为 Redis 只对 "{1000}" 部分计算 CRC16
SET user:{1000}:name "Alice"
SET user:{1000}:email "alice@example.com"
MGET user:{1000}:name user:{1000}:email   # 正常执行
```

> **注意**：Hash Tag 会导致数据倾斜——同一个 tag 下的所有 key 都集中在一个槽上。如果某个 tag 下的 key 数量过多，会导致该节点负载过重。

## 9.2 其他限制

| 限制 | 说明 |
|-----|------|
| **不支持多数据库** | 集群模式只支持 db0，不能使用 `SELECT` 切换数据库 |
| **事务受限** | `MULTI/EXEC` 事务中的所有 key 必须在同一个槽，跨槽事务不被支持 |
| **Lua 脚本受限** | 脚本中访问的所有 key 必须在同一个槽 |
| **发布订阅开销** | `PUBLISH` 消息会被广播到集群所有节点，大规模 pub/sub 会显著增加集群内部流量 |
| **批量操作性能** | Pipeline 中涉及多个槽时，客户端需要按槽分组发送，降低了批量操作的效率 |
| **大 key 迁移** | reshard 过程中迁移大 key（如大 Hash、大 List）会阻塞源节点，影响服务 |


# 10 集群核心配置汇总

| 配置项 | 默认值 | 说明 |
|-------|-------|------|
| `cluster-enabled` | no | 是否开启集群模式 |
| `cluster-config-file` | nodes.conf | 集群配置文件（自动生成，勿手动修改） |
| `cluster-node-timeout` | 15000 (ms) | 节点超时时间，超过则标记 PFAIL |
| `cluster-replica-validity-factor` | 10 | 从节点有效性因子，断开超过 timeout × factor 则不参与选举 |
| `cluster-migration-barrier` | 1 | 主节点至少保留的从节点数，防止单点故障 |
| `cluster-require-full-coverage` | yes | 是否要求所有槽都有节点负责才对外提供服务 |
| `cluster-allow-reads-when-down` | no | 集群状态为 FAIL 时从节点是否仍然接受读请求 |
| `cluster-allow-pubsubshard-when-down` | yes | 集群 DOWN 时是否允许分片 pub/sub |

**生产建议**：

- `cluster-node-timeout`：建议设置为 **5000-15000ms**。太小会导致网络抖动时频繁误判，太大则故障检测延迟
- `cluster-require-full-coverage`：**建议设置为 no**。默认 yes 意味着只要有一个槽没有节点负责，整个集群就拒绝服务，这在生产中过于严格
- `cluster-migration-barrier`：当从节点充足时，Redis 会自动将多余的从节点迁移给没有从节点的主节点，该参数控制迁移条件


# 11 小结

| 主题 | 核心要点 |
|------|---------|
| 纵向 vs 横向扩展 | 纵向扩展受 fork 阻塞和硬件成本限制，横向扩展通过切片集群解决大数据量问题 |
| 哈希槽分片 | CRC16(key) % 16384 映射到槽，槽再分配到节点，两层映射解耦数据与节点 |
| 16384 个槽的设计 | Gossip 消息位图 2KB，兼顾带宽开销和分片粒度 |
| 客户端定位 | 缓存槽映射 → MOVED（永久迁移） / ASK（迁移中）重定向 |
| Gossip 协议 | PING/PONG 去中心化通信，每条消息携带槽位图 + 部分节点信息 |
| 故障转移 | PFAIL→FAIL 两阶段检测 + 按复制偏移量优先选举 + 半数以上主节点投票 |
| 扩缩容 | add-node → reshard → rebalance，迁移期间通过 ASK 保证服务不中断 |
| 使用限制 | 多 key 必须同槽（Hash Tag）、仅 db0、事务/Lua 受限 |

**生产实践要点**：

1. **至少 6 节点起步**（3 主 3 从），每个主节点至少配 1 个从节点保证高可用
2. **将 `cluster-require-full-coverage` 设为 no**，避免单个槽故障导致整个集群不可用
3. **合理使用 Hash Tag**，在满足多 key 操作需求的同时注意避免数据倾斜
4. **大 key 拆分后再上集群**，避免 reshard 过程中迁移大 key 导致阻塞
5. **监控 `cluster info` 和 `cluster nodes`**，关注 `cluster_state`、各节点的连接状态和槽覆盖情况

在 Redis 3.0 之前，业界已有 ShardedJedis（客户端分区）、Codis、Twemproxy（代理层分区）等切片集群方案。下一节以 Codis 为例，讲解其实现机制与实践经验。