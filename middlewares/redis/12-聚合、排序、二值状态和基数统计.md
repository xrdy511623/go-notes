
---
聚合、排序、二值状态和基数统计
---


# 1 背景

在Web和移动应⽤的业务场景中，我们经常需要保存这样⼀种信息：⼀个key对应了⼀个数据集合。举⼏个例⼦。

⼿机App中的每天的⽤⼾登录信息：⼀天对应⼀系列⽤⼾ID或移动设备ID；
电商⽹站上商品的⽤⼾评论列表：⼀个商品对应了⼀系列的评论；
⽤⼾在⼿机App上的签到打卡信息：⼀天对应⼀系列⽤⼾的签到记录；
应⽤⽹站上的⽹⻚访问信息：⼀个⽹⻚对应⼀系列的访问点击。

我们知道，Redis集合类型的特点就是⼀个键对应⼀系列的数据，所以⾮常适合⽤来存取这些数据。但是，
在这些场景中，除了记录信息，我们往往还需要对集合中的数据进⾏统计，例如：

在移动应⽤中，需要统计每天的新增⽤⼾数和第⼆天的留存⽤⼾数；
在电商⽹站的商品评论中，需要统计评论列表中的最新评论；
在签到打卡中，需要统计⼀个⽉内连续打卡的⽤⼾数；
在⽹⻚访问记录中，需要统计独⽴访客（Unique Visitor，UV）量。

通常情况下，我们⾯临的⽤⼾数量以及访问量都是巨⼤的，⽐如百万、千万级别的⽤⼾数量，或者千万级
别、甚⾄亿级别的访问信息。所以，我们必须要选择能够⾮常⾼效地统计⼤量数据（例如亿级）的集合类型。

要想选择合适的集合，我们就得了解常⽤的集合统计模式。这节课，我就给你介绍集合类型常⻅的四种统计
模式，包括聚合统计、排序统计、⼆值状态统计和基数统计。我会以刚刚提到的这四个场景为例，和你聊聊
在这些统计模式下，什么集合类型能够更快速地完成统计，⽽且还节省内存空间。掌握了今天的内容，之后
再遇到集合元素统计问题时，你就能很快地选出合适的集合类型了。


# 2 聚合统计

我们先来看集合元素统计的第⼀个场景：聚合统计。

所谓的聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把
两个集合相⽐，统计其中⼀个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。

在刚才提到的场景中，统计⼿机App每天的新增⽤⼾数和第⼆天的留存⽤⼾数，正好对应了聚合统计。

要完成这个统计任务，我们可以⽤⼀个集合记录所有登录过App的⽤⼾ID，同时，⽤另⼀个集合记录每⼀天
登录过App的⽤⼾ID。然后，再对这两个集合做聚合统计。我们来看下具体的操作。

记录所有登录过App的⽤⼾ID还是⽐较简单的，我们可以直接使⽤Set类型，把key设置为user:id，表
⽰记录的是⽤⼾ID，value就是⼀个Set集合，⾥⾯是所有登录过App的⽤⼾ID，我们可以把这个Set叫作累
计⽤⼾Set。

需要注意的是，累计⽤⼾Set中没有⽇期信息，我们是不能直接统计每天的新增⽤⼾的。所以，我们还需要
把每⼀天登录的⽤⼾ID，记录到⼀个新集合中，我们把这个集合叫作每⽇⽤⼾Set，它有两个特点：

1. key是user:id以及当天⽇期，例如user:id:20200803；
2. value是Set集合，记录当天登录的⽤⼾ID。






![aggregation-demo.png](images%2Faggregation-demo.png)





在统计每天的新增⽤⼾时，我们只⽤计算每⽇⽤⼾Set和累计⽤⼾Set的差集就⾏。

下面借⼀个具体的例⼦来解释⼀下。

假设我们的⼿机App在2020年8⽉3⽇上线，那么，8⽉3⽇前是没有⽤⼾的。此时，累计⽤⼾Set是空集，当
天登录的⽤⼾ID会被记录到 key为user:id:20200803的Set中。所以，user:id:20200803这个Set中
的⽤⼾就是当天的新增⽤⼾。

然后，我们计算累计⽤⼾Set和user:id:20200803 Set的并集结果，结果保存在user:id这个累计⽤
⼾Set中，如下所⽰：

```shell
SUNIONSTORE user:id user:id user:id:20200803
```

此时，user:id这个累计⽤⼾Set中就有了8⽉3⽇的⽤⼾ID。等到8⽉4⽇再统计时，我们把8⽉4⽇登录的
⽤⼾ID记录到user:id:20200804 的Set中。接下来，我们执⾏SDIFFSTORE命令计算累计⽤⼾Set和
user:id:20200804 Set的差集，结果保存在key为user:new的Set中，如下所⽰：

```shell
SDIFFSTORE user:new user:id:20200804 user:id
```

可以看到，这个差集中的⽤⼾ID在user:id:20200804 的Set中存在，但是不在累计⽤⼾Set中。所以，
user:new这个Set中记录的就是8⽉4⽇的新增⽤⼾。

当要计算8⽉4⽇的留存⽤⼾时，我们只需要再计算user:id:20200803 和 user:id:20200804两个Set
的交集，就可以得到同时在这两个集合中的⽤⼾ID了，这些就是在8⽉3⽇登录，并且在8⽉4⽇留存的⽤
⼾。执⾏的命令如下：

```shell
SINTERSTORE user:id:remain user:id:20200803 user:id:20200804
```

当你需要对多个集合进⾏聚合计算时，Set类型会是⼀个⾮常不错的选择。不过，我要提醒你⼀下，这⾥有
⼀个潜在的⻛险。

Set的差集、并集和交集的计算复杂度较⾼，在数据量较⼤的情况下，如果直接执⾏这些计算，会导致Redis
实例阻塞。所以，我给你分享⼀个⼩建议：你可以从主从集群中选择⼀个从库，让它专⻔负责聚合计算，或
者是把数据读取到客⼾端，在客⼾端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的⻛险了。


# 3 排序统计

接下来，我们来看第二个场景：排序统计。

在电商网站上，商品评论通常按时间排序，最新的评论排在最前面。这个需求看起来很简单，用 List 或 Sorted Set 都可以实现，但它们在分页查询时的行为有很大差异。

## 3.1 List 的问题

假设我们用 List 保存商品评论，每来一条评论就用 `LPUSH` 插入到列表头部。查询时用 `LRANGE` 分页：

```shell
# 插入评论（最新的在最前面）
LPUSH product:1:comments "评论A"
LPUSH product:1:comments "评论B"
LPUSH product:1:comments "评论C"

# 分页查询：获取第1页（每页2条）
LRANGE product:1:comments 0 1
# 返回: "评论C", "评论B"
```

看起来没问题，但考虑这个场景：当用户正在看第 1 页时，又有新评论插入了。此时用户翻到第 2 页，`LRANGE product:1:comments 2 3`，会发现第 2 页的第一条就是刚才第 1 页的最后一条——**数据重复了**。

原因是：List 是按位置（index）排序的，新元素的插入会改变已有元素的位置。在频繁更新的场景下，List 的分页查询结果不稳定。

## 3.2 Sorted Set 的优势

Sorted Set（有序集合）按照元素的 **score 值**排序，而不是按插入位置。我们可以用评论的时间戳作为 score：

```shell
# 插入评论，score 为时间戳
ZADD product:1:comments 1596470400 "评论A"
ZADD product:1:comments 1596470500 "评论B"
ZADD product:1:comments 1596470600 "评论C"

# 按时间倒序获取第1页（最新的排前面）
ZREVRANGEBYSCORE product:1:comments +inf -inf LIMIT 0 2
# 返回: "评论C", "评论B"
```

即使在分页期间有新评论插入，由于查询是基于 score 范围的，**已有元素的相对顺序不会改变**，分页结果是稳定的。

```shell
# 记住第1页最后一条的 score（评论B 的时间戳 1596470500）
# 查询第2页时，从这个 score 之前开始
ZREVRANGEBYSCORE product:1:comments 1596470499 -inf LIMIT 0 2
```

## 3.3 List 与 Sorted Set 的排序能力对比

| 对比维度 | List | Sorted Set |
|---------|------|-----------|
| 排序方式 | 按插入位置 | 按 score 值 |
| 分页稳定性 | 不稳定（新增元素会导致位移） | 稳定（基于 score 范围查询） |
| 插入时间复杂度 | O(1)（LPUSH/RPUSH） | O(logN) |
| 范围查询 | LRANGE（按位置） | ZRANGEBYSCORE / ZREVRANGEBYSCORE（按 score 范围） |
| 适用场景 | 消息队列、不需要分页的简单列表 | 排行榜、分页评论、时间线 |

> **总结**：当需要对集合中的元素进行排序并支持稳定分页时，Sorted Set 是更好的选择。


# 4 二值状态统计

第三个场景是二值状态统计。所谓二值状态，就是每个元素只有两种状态：是/否、0/1、存在/不存在。

典型场景：
- 用户签到打卡：某用户在某天是否签到
- 用户是否已登录
- 商品是否已被浏览

这类数据的特点是：**状态值只有 0 和 1**，但需要统计的元素数量可能非常庞大（如千万级用户）。

## 4.1 Bitmap 基本原理

Redis 提供了 **Bitmap**（位图）数据类型，它本质上是一个由 bit 位组成的数组，每个 bit 位只能存储 0 或 1。

Bitmap 的底层实现其实就是 String 类型，一个 String 值最多可以存储 512MB，即 2^32 个 bit 位，足以覆盖 **42 亿**个二值状态。

关键命令：

```shell
# 设置第 offset 位的值为 1 或 0
SETBIT key offset value

# 获取第 offset 位的值
GETBIT key offset

# 统计值为 1 的 bit 位数量
BITCOUNT key [start end]

# 对多个 Bitmap 做位运算（AND/OR/XOR/NOT）
BITOP operation destkey key [key ...]

# 返回第一个值为 bit 的 bit 位的位置
BITPOS key bit [start end]
```

## 4.2 签到打卡场景

我们以签到打卡为例。假设有 1000 万用户，需要统计每天的签到情况以及连续签到天数。

**方案一：每天一个 Bitmap，每个 bit 位代表一个用户**

```shell
# 用户ID 1000 在 8月3日签到
SETBIT sign:20200803 1000 1

# 用户ID 2000 在 8月3日签到
SETBIT sign:20200803 2000 1

# 统计 8月3日总签到人数
BITCOUNT sign:20200803
```

内存开销分析：1000 万用户需要 10,000,000 bit ≈ **1.2MB**。一个月就是 1.2MB × 30 ≈ **36MB**。如果用 Set 存储用户 ID（每个 ID 占 8 字节），1000 万用户需要 80MB，Bitmap 方案节省了大约 55% 的内存。

**方案二：每个用户一个 Bitmap，每个 bit 位代表一天**

```shell
# 用户 1000 在一年中的第 215 天（8月3日）签到
SETBIT sign:user:1000 215 1

# 查看用户 1000 在第 215 天是否签到
GETBIT sign:user:1000 215

# 统计用户 1000 全年签到天数
BITCOUNT sign:user:1000
```

每个用户一年的 Bitmap 大小只有 365 bit ≈ **46 字节**，非常节省内存。

## 4.3 统计连续签到

要统计一个月内连续打卡的用户数，可以使用 `BITOP AND` 对多天的 Bitmap 取交集：

```shell
# 8月1日到8月3日连续签到的用户（3天的 Bitmap 做 AND 运算）
BITOP AND sign:consecutive sign:20200801 sign:20200802 sign:20200803

# 统计连续签到的用户数
BITCOUNT sign:consecutive
```

`BITOP AND` 的结果中，只有在三天都签到的用户对应的 bit 位才为 1。

## 4.4 Bitmap 的内存优势

| 统计方式 | 1000万用户/天 | 1000万用户/月 |
|---------|-------------|-------------|
| Set（存储用户ID） | ~80MB | ~2.4GB |
| Bitmap | ~1.2MB | ~36MB |
| 节省比例 | 98.5% | 98.5% |

> **注意**：Bitmap 适合用户 ID 是连续或较密集的整数的场景。如果用户 ID 非常稀疏（如 UUID），Bitmap 反而会浪费空间，此时 Set 或 HyperLogLog 更合适。


# 5 基数统计

最后一个场景是基数统计。**基数**（cardinality）是指一个集合中不重复元素的个数。

典型场景：
- 统计网页的独立访客数（UV）
- 统计 App 的日活跃用户数（DAU）
- 统计搜索词的去重数量

## 5.1 Set 和 Hash 的局限

用 Set 或 Hash 可以精确统计基数——把每个元素都存入集合，然后取集合大小（`SCARD` 或 `HLEN`）。

但问题是：当数据量达到千万甚至亿级时，Set/Hash 需要存储所有元素，**内存消耗巨大**。例如，统计一个网站的日 UV，假设有 1000 万独立访客，每个访客 ID 占 64 字节，Set 就需要约 640MB 内存。

## 5.2 HyperLogLog

Redis 提供了 **HyperLogLog**（HLL）数据结构，专门用于基数统计。它的核心特点是：

- **固定内存**：每个 HyperLogLog 只占 **12KB** 内存，无论统计的元素有多少
- **误差率**：标准误差为 **0.81%**，即统计 1000 万 UV 时，误差约在 ±8.1 万
- **支持合并**：多个 HLL 可以合并，用于统计跨时间段的基数

关键命令：

```shell
# 添加元素
PFADD key element [element ...]

# 获取基数估算值
PFCOUNT key [key ...]

# 合并多个 HyperLogLog
PFMERGE destkey sourcekey [sourcekey ...]
```

## 5.3 UV 统计实战

```shell
# 记录 8月3日的页面访问用户
PFADD page:uv:20200803 user1 user2 user3 user1  # user1 重复不影响
PFADD page:uv:20200803 user4 user5

# 查询 8月3日的 UV
PFCOUNT page:uv:20200803
# 返回: (integer) 5

# 记录 8月4日的访问
PFADD page:uv:20200804 user1 user3 user6 user7

# 统计两天的合计 UV（去重）
PFMERGE page:uv:total page:uv:20200803 page:uv:20200804
PFCOUNT page:uv:total
# 返回: (integer) 7  （可能有 ±0.81% 的误差）
```

## 5.4 HyperLogLog 原理简介

HyperLogLog 基于**概率统计**原理。核心思想是：

1. 对每个输入元素计算哈希值
2. 观察哈希值的二进制表示中，从最低位开始连续 0 的个数（记为 k）
3. 记录观察到的最大 k 值。如果最大 k = n，则估算基数约为 2^n

Redis 的 HLL 实现使用 **16384 个桶**（register），每个桶记录 6 bit，总占用 16384 × 6 / 8 = **12288 字节 ≈ 12KB**。多个桶的估算结果取调和平均，从而降低估算误差。

## 5.5 基数统计方案对比

| 方案 | 内存占用（1000万元素） | 精确度 | 支持去重 | 支持合并 |
|------|---------------------|--------|---------|---------|
| **Set** | ~640MB | 精确 | 是 | SUNIONSTORE |
| **Hash** | ~640MB | 精确 | 是（field 去重） | 不直接支持 |
| **Bitmap** | ~1.2MB | 精确 | 是（bit 位去重） | BITOP OR |
| **HyperLogLog** | **12KB** | 误差 ±0.81% | 是 | PFMERGE |

> **选型建议**：如果业务能接受约 1% 的误差，HyperLogLog 是大规模基数统计的最优方案。如果要求精确计数且数据量不大（< 百万级），使用 Set 或 Bitmap。


# 6 总结

| 统计模式 | 适用场景 | 推荐数据类型 | 关键命令 |
|---------|---------|------------|---------|
| **聚合统计** | 新增用户、留存用户、共同好友 | Set | SDIFFSTORE、SINTERSTORE、SUNIONSTORE |
| **排序统计** | 商品评论分页、排行榜、时间线 | Sorted Set | ZRANGEBYSCORE、ZREVRANGEBYSCORE |
| **二值状态统计** | 签到打卡、用户在线状态 | Bitmap | SETBIT、GETBIT、BITCOUNT、BITOP |
| **基数统计** | UV、DAU、去重计数 | HyperLogLog | PFADD、PFCOUNT、PFMERGE |

**选型决策要点**：

1. **需要聚合运算（交/并/差集）** → Set，注意在从库或客户端执行以避免阻塞主库
2. **需要排序 + 稳定分页** → Sorted Set（以时间戳或权重为 score）
3. **只需要记录是/否两种状态** → Bitmap（节省 98%+ 内存，但要求 ID 为连续整数）
4. **只需要统计去重后的数量** → HyperLogLog（12KB 固定内存，误差 ±0.81%）
5. **需要精确去重 + 查看具体元素** → Set 或 Hash（内存开销大，但功能完整）
