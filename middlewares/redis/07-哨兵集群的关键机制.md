
---
哨兵集群：哨兵挂了，主从库还能切换吗？
---

我们知道，通过哨兵机制可以实现主从库的⾃动切换。通过部署多个实例，就形成了⼀个哨兵集
群。哨兵集群中的多个实例共同判断，可以降低对主库下线的误判率。

但是，我们还是要考虑⼀个问题：如果有哨兵实例在运⾏时发⽣了故障，主从库还能正常切换吗？

实际上，⼀旦多个实例组成了哨兵集群，即使有哨兵实例出现故障挂掉了，其他哨兵还能继续协作完成主从
库切换的⼯作，包括判定主库是不是处于下线状态，选择新主库，以及通知从库和客⼾端。

如果你部署过哨兵集群的话就会知道，在配置哨兵的信息时，我们只需要⽤到下⾯的这个配置项，设置主库
的IP和端⼝，并没有配置其他哨兵的连接信息。

```shell
sentinel monitor <master-name> <ip> <redis-port> <quorum>
```

这些哨兵实例既然都不知道彼此的地址，⼜是怎么组成集群的呢？要弄明⽩这个问题，我们就需要学习⼀下
哨兵集群的组成和运⾏机制了。

# 1 基于pub/sub机制的哨兵集群组成

哨兵实例之间可以相互发现，要归功于Redis提供的pub/sub机制，也就是发布/订阅机制。

哨兵只要和主库建⽴起了连接，就可以在主库上发布消息了，⽐如说发布它⾃⼰的连接信息（IP和端⼝）。
同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和
订阅操作后，它们之间就能知道彼此的IP地址和端⼝。

除了哨兵实例，我们⾃⼰编写的应⽤程序也可以通过Redis进⾏消息的发布和订阅。所以，为了区分不同应
⽤的消息，Redis会以频道的形式，对这些消息进⾏分⻔别类的管理。所谓的频道，实际上就是消息的类
别。当消息类别相同时，它们就属于同⼀个频道。反之，就属于不同的频道。只有订阅了同⼀个频道的应
⽤，才能通过发布的消息进⾏信息交换。

在主从集群中，主库上有⼀个名为“__sentinel__:hello”的频道，不同哨兵就是通过它来相互发现，
实现互相通信的。

比如，在下图中，哨兵1把⾃⼰的IP（172.16.19.3）和端⼝（26579）发布
到“__sentinel__:hello”频道上，哨兵2和3订阅了该频道。那么此时，哨兵2和3就可以从这个频道直
接获取哨兵1的IP地址和端⼝号。

然后，哨兵2、3可以和哨兵1建⽴⽹络连接。通过这个⽅式，哨兵2和3也可以建⽴⽹络连接，这样⼀来，哨
兵集群就形成了。它们相互间可以通过⽹络连接进⾏通信，⽐如说对主库有没有下线这件事⼉进⾏判断和协商。





![pub-sub-form-sentinel-cluster.png](images%2Fpub-sub-form-sentinel-cluster.png)





哨兵除了彼此之间建⽴起连接形成集群外，还需要和从库建⽴连接。这是因为，在哨兵的监控任务中，它需
要对主从库都进⾏⼼跳判断，⽽且在主从库切换完成后，它还需要通知从库，让它们和新主库进⾏同步。

那么，哨兵是如何知道从库的IP地址和端⼝的呢？

这是由哨兵向主库发送INFO命令来完成的。就像下图所⽰，哨兵2给主库发送INFO命令，主库接受到这个
命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建⽴连
接，并在这个连接上持续地对从库进⾏监控。哨兵1和3可以通过相同的⽅法和从库建⽴连接。





![info-replication.png](images%2Finfo-replication.png)





你看，通过pub/sub机制，哨兵之间可以组成集群，同时，哨兵⼜通过INFO命令，获得了从库连接信息，
也能和从库建⽴连接，并进⾏监控了。

但是，哨兵不能只和主、从库连接。因为，主从库切换后，客⼾端也需要知道新主库的连接信息，才能向新
主库发送请求操作。所以，哨兵还需要完成把新主库的信息告诉客⼾端这个任务。

⽽且，在实际使⽤哨兵时，我们有时会遇到这样的问题：如何在客⼾端通过监控了解哨兵进⾏主从切换的过
程呢？⽐如说，主从切换进⾏到哪⼀步了？这其实就是要求，客⼾端能够获取到哨兵集群在监控、选主、切
换这个过程中发⽣的各种事件。

此时，我们仍然可以依赖pub/sub机制，来帮助我们完成哨兵和客⼾端间的信息同步。

# 2 基于pub/sub机制的客⼾端事件通知

从本质上说，哨兵就是⼀个运⾏在特定模式下的Redis实例，只不过它并不服务请求操作，只是完成监控、
选主和通知的任务。所以，每个哨兵实例也提供pub/sub机制，客⼾端可以从哨兵订阅消息。哨兵提供的消
息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。

频道有这么多，⼀下⼦全部学习容易丢失重点。下面是重要的频道汇总，涉及⼏个关键事件，包括主库下线判断、
新主库选定、从库重新配置。





![important-channels.png](images%2Fimportant-channels.png)





知道了这些频道之后，你就可以让客⼾端从哨兵这⾥订阅消息了。具体的操作步骤是，客⼾端读取哨兵的配
置⽂件后，可以获得哨兵的地址和端⼝，和哨兵建⽴⽹络连接。然后，我们可以在客⼾端执⾏订阅命令，来
获取不同的事件消息。

举个例⼦，你可以执⾏如下命令，来订阅“所有实例进⼊客观下线状态的事件”：

```shell
SUBSCRIBE +odown
```

当然，你也可以执⾏如下命令，订阅所有的事件：

```shell
PSUBSCRIBE *
```

当哨兵把新主库选择出来后，客⼾端就会看到下⾯的switch-master事件。这个事件表⽰主库已经切换了，
新主库的IP地址和端⼝信息已经有了。这个时候，客⼾端就可以⽤这⾥⾯的新主库地址和端⼝进⾏通信了。

```shell
switch-master <master name> <oldip> <oldport> <newip> <newport>
```

有了这些事件通知，客⼾端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中
发⽣的各个重要事件。这样，客⼾端就可以知道主从切换进⾏到哪⼀步了，有助于了解切换进度。

好了，有了pub/sub机制，哨兵和哨兵之间、哨兵和从库之间、哨兵和客⼾端之间就都能建⽴起连接了，再
加上我们上节课介绍主库下线判断和选主依据，哨兵集群的监控、选主和通知三个任务就基本可以正常⼯作
了。不过，我们还需要考虑⼀个问题：主库故障以后，哨兵集群有多个实例，那怎么确定由哪个哨兵来进⾏
实际的主从切换呢？


# 3 由哪个哨兵执⾏主从切换？

确定由哪个哨兵执⾏主从切换的过程，和主库“客观下线”的判断过程类似，也是⼀个“投票仲裁”的过
程。在具体了解这个过程前，我们再来看下，判断“客观下线”的仲裁过程。

哨兵集群要判定主库“客观下线”，需要有⼀定数量的实例都认为该主库已经“主观下线”了。接下来，
我介绍下具体的判断过程。

任何⼀个实例只要⾃⾝判断主库“主观下线”后，就会给其他实例发送is-master-down-by-addr命令。接
着，其他实例会根据⾃⼰和主库的连接情况，做出Y或N的响应，Y相当于赞成票，N相当于反对票。





![object-down-process.png](images%2Fobject-down-process.png)





⼀个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵
配置⽂件中的quorum配置项设定的。例如，现在有5个哨兵，quorum配置的是3，那么，⼀个哨兵需要3张
赞成票，就可以标记主库为“客观下线”了。这3张赞成票包括哨兵⾃⼰的⼀张赞成票和另外两个哨兵的赞成票。

此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由⾃⼰来执⾏主从切换，并让所有其他哨兵进⾏投
票。这个投票过程称为“Leader选举”。因为最终执⾏主从切换的哨兵称为Leader，投票过程就是确定Leader。

在投票过程中，任何⼀个想成为Leader的哨兵，要满⾜两个条件：第⼀，拿到半数以上的赞成票；第⼆，
拿到的票数同时还需要⼤于等于哨兵配置⽂件中的quorum值。以3个哨兵为例，假设此时的quorum设置为
2，那么，任何⼀个想成为Leader的哨兵只要拿到2张赞成票，就可以了。

这么说你可能还不太好理解，下面这张图展⽰了3个哨兵、quorum为2的选举过程。





![sentinel-cluster-leader-election.png](images%2Fsentinel-cluster-leader-election.png)





在T1时刻，S1判断主库为“客观下线”，它想成为Leader，就先给⾃⼰投⼀张赞成票，然后分别向S2和S3
发送命令，表⽰要成为Leader。

在T2时刻，S3判断主库为“客观下线”，它也想成为Leader，所以也先给⾃⼰投⼀张赞成票，再分别向S1
和S2发送命令，表⽰要成为Leader。

在T3时刻，S1收到了S3的Leader投票请求。因为S1已经给⾃⼰投了⼀票Y，所以它不能再给其他哨兵投赞
成票了，所以S1回复N表⽰不同意。同时，S2收到了T2时S3发送的Leader投票请求。因为S2之前没有投过
票，它会给第⼀个向它发送投票请求的哨兵回复Y，给后续再发送投票请求的哨兵回复N，所以，在T3时，
S2回复S3，同意S3成为Leader。

在T4时刻，S2才收到T1时S1发送的投票命令。因为S2已经在T3时同意了S3的投票请求，此时，S2给S1回
复N，表⽰不同意S1成为Leader。发⽣这种情况，是因为S3和S2之间的⽹络传输正常，⽽S1和S2之间的⽹
络传输可能正好拥塞了，导致投票请求传输慢了。

最后，在T5时刻，S1得到的票数是来⾃它⾃⼰的⼀票Y和来⾃S2的⼀票N。⽽S3除了⾃⼰的赞成票Y以外，
还收到了来⾃S2的⼀票Y。此时，S3不仅获得了半数以上的Leader赞成票，也达到预设的quorum值
（quorum为2），所以它最终成为了Leader。接着，S3会开始执⾏选主操作，⽽且在选定新主库后，会给
其他从库和客⼾端通知新主库的信息。

如果S3没有拿到2票Y，那么这轮投票就不会产⽣Leader。哨兵集群会等待⼀段时间（也就是哨兵故障转移
超时时间的2倍），再重新选举。这是因为，哨兵集群能够进⾏成功投票，很⼤程度上依赖于选举命令的正
常⽹络传播。如果⽹络压⼒较⼤或有短时堵塞，就可能导致没有⼀个哨兵能拿到半数以上的赞成票。所以，
等到⽹络拥塞好转之后，再进⾏投票选举，成功的概率就会增加。

需要注意的是，如果哨兵集群只有2个实例，此时，⼀个哨兵要想成为Leader，必须获得2票，⽽不是1票。
所以，如果有个哨兵挂掉了，那么，此时的集群是⽆法进⾏主从库切换的。因此，通常我们⾄少会配置3个
哨兵实例。这⼀点很重要，你在实际应⽤时可不能忽略了。

> **与 Raft 协议的相似性**：哨兵的 Leader 选举机制与分布式一致性协议 Raft 非常相似——每轮选举有一个 epoch（类似 Raft 的 term），每个哨兵在同一个 epoch 中只能投一次票，且遵循先到先得原则。如果本轮没有产生 Leader，则递增 epoch 重新选举。理解 Raft 有助于深入理解哨兵的选举行为。

# 4 哨兵的三个定时任务

哨兵集群的正常运行依赖于三个核心定时任务，它们各司其职，共同完成发现、通信和健康检测的工作。

## 4.1 每 10 秒：INFO 命令——拓扑发现

每个哨兵每隔 **10 秒**向已知的主库和从库发送 `INFO` 命令。通过主库返回的 `INFO replication` 输出，哨兵可以：

- 自动发现新加入的从库，无需手动配置
- 感知从库的在线状态、复制偏移量等信息
- 在主从切换后，确认新的拓扑结构是否生效

这是哨兵**感知集群拓扑变化**的基础机制。

## 4.2 每 2 秒：pub/sub——哨兵间信息交换

每个哨兵每隔 **2 秒**通过主库的 `__sentinel__:hello` 频道发布一条消息，内容包括：

```
<sentinel-ip>,<sentinel-port>,<sentinel-runid>,<sentinel-epoch>,
<master-name>,<master-ip>,<master-port>,<master-epoch>
```

其他哨兵订阅该频道后，可以获得：

- 发送方哨兵的连接信息（用于建立哨兵间的直接连接）
- 发送方对主库的判断信息（用于交叉验证主库状态）

如果收到的消息中主库信息与自身记录不一致，哨兵会根据 epoch 大小来决定是否更新自己的配置。**epoch 更大的配置优先**，这保证了切换后所有哨兵最终会收敛到同一份配置。

## 4.3 每 1 秒：PING 命令——健康检测

每个哨兵每隔 **1 秒**向所有已知的主库、从库和其他哨兵实例发送 `PING` 命令。这是哨兵判断实例是否存活的**最核心**的定时任务。

判断逻辑如下：

- 如果一个实例在 `down-after-milliseconds` 毫秒内没有返回有效回复（有效回复指 `+PONG`、`-LOADING`、`-MASTERDOWN`），该哨兵就将其标记为**主观下线（SDOWN）**
- 对于主库，当足够多的哨兵都认为其主观下线时，才会将其标记为**客观下线（ODOWN）**并触发故障转移

三个定时任务的协作关系：

| 定时任务 | 频率 | 目标 | 作用 |
|---------|------|------|------|
| INFO | 10 秒 | 主库、从库 | 拓扑发现，自动感知从库上下线 |
| pub/sub | 2 秒 | 主库的 `__sentinel__:hello` 频道 | 哨兵间互相发现、交换主库状态信息 |
| PING | 1 秒 | 所有实例（主库、从库、哨兵） | 健康检测，判断主观下线 |

# 5 网络分区与脑裂问题

在生产环境中，网络分区（network partition）是一个必须考虑的故障场景。如果主库与哨兵之间发生网络分区，但主库本身仍在正常运行并接受客户端写入，就可能出现**脑裂（split-brain）**问题。

## 5.1 脑裂的产生

考虑以下场景：

```
分区前:
  Client → Master ← Sentinel集群
              ↑
            Slave

分区后:
  [分区A]                    [分区B]
  Client → Master(旧)       Sentinel集群 → Slave(被提升为新Master)
                                            ↑
                                          Client(新)
```

1. 主库与哨兵之间发生网络隔离
2. 哨兵判定主库客观下线，选出新主库
3. 旧主库仍在运行，且分区 A 中的客户端继续向旧主库写入数据
4. 网络恢复后，旧主库被降级为从库，执行 `SLAVEOF` 清空自身数据并从新主库同步
5. **分区期间写入旧主库的数据全部丢失**

## 5.2 min-replicas 防护机制

Redis 提供了两个配置项来缓解脑裂带来的数据丢失风险：

```bash
# 主库至少需要 N 个从库处于连接状态才接受写入
min-replicas-to-write 1

# 从库的 ACK 延迟不超过该秒数才算"连接正常"
min-replicas-max-lag 10
```

**工作原理**：主库在每次执行写命令前，会检查当前与自己保持正常连接的从库数量。如果连接正常的从库数量少于 `min-replicas-to-write`，主库会**拒绝写入**并返回错误。

这样，当网络分区发生时，旧主库因为无法与从库正常通信，会自动停止接受写入，从而将分区期间的数据丢失控制在一个有限的时间窗口内（最多 `min-replicas-max-lag` 秒的数据）。

**配置建议**：

| 场景 | min-replicas-to-write | min-replicas-max-lag |
|------|----------------------|---------------------|
| 1 主 2 从 | 1 | 10 |
| 1 主 4 从 | 2 | 10 |
| 对数据丢失零容忍 | 从库数 / 2 | 5 |

> **注意**：`min-replicas-to-write` 设置过大会降低系统可用性——一旦从库故障数量超过阈值，主库将拒绝所有写入。需要在数据安全和可用性之间做权衡。

# 6 小结

本文介绍了哨兵集群正常运行所依赖的关键机制：

| 机制 | 核心原理 | 解决的问题 |
|------|---------|-----------|
| pub/sub 哨兵发现 | 通过主库的 `__sentinel__:hello` 频道交换信息 | 哨兵之间无需互相配置即可自动组网 |
| INFO 命令 | 定期向主库发送 INFO 获取从库列表 | 自动发现从库，无需手动配置从库地址 |
| 客户端事件通知 | 客户端订阅哨兵的 pub/sub 频道 | 客户端实时感知主从切换进度和结果 |
| Leader 选举 | 类 Raft 投票（epoch + 先到先得 + 多数派） | 确保只有一个哨兵执行主从切换，避免冲突 |
| 三个定时任务 | 1s PING + 2s pub/sub + 10s INFO | 健康检测、信息交换、拓扑发现各司其职 |
| min-replicas 防护 | 主库检查从库连接数决定是否接受写入 | 缓解网络分区导致的脑裂数据丢失 |

**生产实践要点**：

1. **哨兵至少部署 3 个实例**，且分布在不同机器（最好不同机架），避免哨兵集群自身出现单点故障
2. **所有哨兵的 `down-after-milliseconds` 配置必须一致**，否则会导致无法对主库故障形成共识，切换延迟甚至失败
3. **配置 `min-replicas-to-write` 和 `min-replicas-max-lag`** 来防范脑裂场景下的数据丢失
4. **客户端应订阅 `+switch-master` 频道**，以便在主从切换后第一时间获取新主库地址，避免持续向旧主库发送请求