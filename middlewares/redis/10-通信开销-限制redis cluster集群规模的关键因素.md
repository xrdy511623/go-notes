
---
通信开销：限制RedisCluster规模的关键因素
---

Redis Cluster能保存的数据量以及⽀撑的吞吐量，跟集群的实例规模密切相关。Redis官⽅给出了Redis
Cluster的规模上限，就是⼀个集群运⾏1000个实例。

那么，你可能会问，为什么要限定集群规模呢？其实，这⾥的⼀个关键因素就是，实例间的通信开销会随着
实例规模增加⽽增⼤，在集群超过⼀定规模时（⽐如800节点），集群吞吐量反⽽会下降。所以，集群的实
际规模会受到限制。

今天我们就来看看，集群实例间的通信开销是如何影响Redis Cluster规模的，以及如何降低实例间的通信开销。
掌握了今天的内容，我们就可以通过合理的配置来扩⼤Redis Cluster的规模，同时保持⾼吞吐量。


# 1 实例通信⽅法和对集群规模的影响

Redis Cluster在运⾏时，每个实例上都会保存Slot和实例的对应关系（也就是Slot映射表），以及⾃⾝的状
态信息。

为了让集群中的每个实例都知道其它所有实例的状态信息，实例之间会按照⼀定的规则进⾏通信。这个规则
就是Gossip协议。

Gossip协议的⼯作原理可以概括成两点。

⼀是，每个实例之间会按照⼀定的频率，从集群中随机挑选⼀些实例，把PING消息发送给挑选出来的实
例，⽤来检测这些实例是否在线，并交换彼此的状态信息。PING消息中封装了发送消息的实例⾃⾝的状态
信息、部分其它实例的状态信息，以及Slot映射表。

⼆是，⼀个实例在接收到PING消息后，会给发送PING消息的实例，发送⼀个PONG消息。PONG消息包含
的内容和PING消息⼀样。

下图显⽰了两个实例间进⾏PING、PONG消息传递的情况。





![redis-cluster-communicate-demo.png](images%2Fredis-cluster-communicate-demo.png)





Gossip协议可以保证在⼀段时间后，集群中的每⼀个实例都能获得其它所有实例的状态信息。

这样⼀来，即使有新节点加⼊、节点故障、Slot变更等事件发⽣，实例间也可以通过PING、PONG消息的传
递，完成集群状态在每个实例上的同步。

经过刚刚的分析，我们可以很直观地看到，实例间使⽤Gossip协议进⾏通信时，通信开销受到通信消息⼤⼩
和通信频率这两⽅⾯的影响。

消息越⼤、频率越⾼，相应的通信开销也就越⼤。如果想要实现⾼效的通信，可以从这两⽅⾯⼊⼿去调优。

接下来，我们就来具体分析下这两⽅⾯的实际情况。

⾸先，我们来看实例通信的消息⼤⼩。

## 1.1 Gossip消息⼤⼩

Redis实例发送的PING消息的消息体是由clusterMsgDataGossip结构体组成的，这个结构体的定义如下所⽰：


```C
typedef struct {
char nodename[CLUSTER_NAMELEN]; //40字节
uint32_t ping_sent; //4字节
uint32_t pong_received; //4字节
char ip[NET_IP_STR_LEN]; //46字节
uint16_t port; //2字节
uint16_t cport; //2字节
uint16_t flags; //2字节
uint32_t notused1; //4字节
} clusterMsgDataGossip;
```

其中，CLUSTER_NAMELEN和NET_IP_STR_LEN的值分别是40和46，分别表⽰，nodename和ip这两个字
节数组的⻓度是40字节和46字节，我们再把结构体中其它信息的⼤⼩加起来，就可以得到⼀个Gossip消息
的⼤⼩了，即104字节。

每个实例在发送⼀个Gossip消息时，除了会传递⾃⾝的状态信息，默认还会传递集群⼗分之⼀实例的状态信息。

所以，对于⼀个包含了1000个实例的集群来说，每个实例发送⼀个PING消息时，会包含100个实例的状态
信息，总的数据量是 10400字节，再加上发送实例⾃⾝的信息，⼀个Gossip消息⼤约是10KB。

此外，为了让Slot映射表能够在不同实例间传播，PING消息中还带有⼀个⻓度为 16,384 bit 的 Bitmap，这
个Bitmap的每⼀位对应了⼀个Slot，如果某⼀位为1，就表⽰这个Slot属于当前实例。这个Bitmap⼤⼩换算
成字节后，是2KB。我们把实例状态信息和Slot分配信息相加，就可以得到⼀个PING消息的⼤⼩了，⼤约是12KB。

PONG消息和PING消息的内容⼀样，所以，它的⼤⼩⼤约是12KB。每个实例发送了PING消息后，还会收到
返回的PONG消息，两个消息加起来有24KB。

虽然从绝对值上来看，24KB并不算很⼤，但是，如果实例正常处理的单个请求只有⼏KB的话，那么，实例
为了维护集群状态⼀致传输的PING/PONG消息，就要⽐单个业务请求⼤了。⽽且，每个实例都会给其它实
例发送PING/PONG消息。随着集群规模增加，这些⼼跳消息的数量也会越多，会占据⼀部分集群的⽹络通
信带宽，进⽽会降低集群服务正常客⼾端请求的吞吐量。

除了⼼跳消息⼤⼩会影响到通信开销，如果实例间通信⾮常频繁，也会导致集群⽹络带宽被频繁占⽤。那
么，Redis Cluster中实例的通信频率是什么样的呢？

## 1.2 实例间通信频率

Redis Cluster的实例启动后，默认会每秒从本地的实例列表中随机选出5个实例，再从这5个实例中找出⼀个
最久没有通信的实例，把PING消息发送给该实例。这是实例周期性发送PING消息的基本做法。

但是，这⾥有⼀个问题：实例选出来的这个最久没有通信的实例，毕竟是从随机选出的5个实例中挑选的，
这并不能保证这个实例就⼀定是整个集群中最久没有通信的实例。

所以，这有可能会出现，有些实例⼀直没有被发送PING消息，导致它们维护的集群状态已经过期了。

为了避免这种情况，Redis Cluster的实例会按照每100ms⼀次的频率，扫描本地的实例列表，如果发现有实
例最近⼀次接收 PONG消息的时间，已经⼤于配置项 cluster-node-timeout的⼀半了（cluster-nodetimeout/2），
就会⽴刻给该实例发送 PING消息，更新这个实例上的集群状态信息。

> **注意**：这里的 `cluster-node-timeout / 2` 是一个关键阈值。假设 `cluster-node-timeout` 设为 15 秒（默认值），那么当某实例超过 7.5 秒没有收到另一实例的 PONG 回复时，就会主动补发 PING。集群越大，这种补发越频繁。

当集群规模扩⼤之后，因为⽹络拥塞或是不同服务器间的流量竞争，会导致实例间的⽹络通信延迟增加。如
果有部分实例⽆法收到其它实例发送的PONG消息，就会引起实例之间频繁地发送PING消息，这⼜会对集群
⽹络通信带来额外的开销了。

我们来总结下单实例每秒会发送的PING消息数量，如下所⽰：

PING消息发送数量 = 1 + 10 × 实例数（最近⼀次接收PONG消息的时间超出 cluster-node-timeout / 2）

其中，1是指单实例常规按照每1秒发送⼀个PING消息，10是指每1秒内实例会执⾏10次检查，每次检查后
会给PONG消息超时的实例发送消息。

我来借助⼀个例⼦，带你分析⼀下在这种通信频率下，PING消息占⽤集群带宽的情况。

假设单个实例检测发现，每100毫秒有10个实例的PONG消息接收超时，那么，这个实例每秒就会发送101
个PING消息，约占1.2MB/s带宽。如果集群中有30个实例按照这种频率发送消息，就会占⽤36MB/s带宽，
这就会挤占集群中⽤于服务正常请求的带宽。

所以，我们要想办法降低实例间的通信开销，那该怎么做呢？

# 2 如何降低实例间的通信开销？

为了降低实例间的通信开销，从原理上说，我们可以减⼩实例传输的消息⼤⼩（PING/PONG消息、Slot分
配信息），但是，因为集群实例依赖PING、PONG消息和Slot分配信息，来维持集群状态的统⼀，⼀旦减⼩
了传递的消息⼤⼩，就会导致实例间的通信信息减少，不利于集群维护，所以，我们不能采⽤这种⽅式。

那么，我们能不能降低实例间发送消息的频率呢？我们先来分析⼀下。

经过刚才的学习，我们现在知道，实例间发送消息的频率有两个。

每个实例每1秒发送⼀条PING消息。这个频率不算⾼，如果再降低该频率的话，集群中各实例的状态可能
就没办法及时传播了。

每个实例每100毫秒会做⼀次检测，给PONG消息接收超过cluster-node-timeout/2的节点发送PING消
息。实例按照每100毫秒进⾏检测的频率，是Redis实例默认的周期性检查任务的统⼀频率，我们⼀般不
需要修改它。

那么，就只有cluster-node-timeout这个配置项可以修改了。

配置项 `cluster-node-timeout` 定义了集群实例被判断为故障的⼼跳超时时间，默认是 15 秒。如果 `cluster-node-timeout` 值比较小，那么在大规模集群中，就会比较频繁地出现 PONG 消息接收超时的情况，从而导致实例每秒要执行 10 次”给 PONG 消息超时的实例发送 PING 消息”这个操作。

所以，为了避免过多的⼼跳消息挤占集群带宽，我们可以调⼤cluster-node-timeout值，⽐如说调⼤到20秒
或25秒。这样⼀来，PONG消息接收超时的情况就会有所缓解，单实例也不⽤频繁地每秒执⾏10次⼼跳发送操作了。

当然，我们也不要把cluster-node-timeout调得太⼤，否则，如果实例真的发⽣了故障，我们就需要等待
cluster-node-timeout时⻓后，才能检测出这个故障，这⼜会导致实际的故障恢复时间被延⻓，会影响到集
群服务的正常使⽤。

为了验证调整cluster-node-timeout值后，是否能减少⼼跳消息占⽤的集群⽹络带宽，我给你提个⼩建议：
你可以在调整cluster-node-timeout值的前后，使⽤tcpdump命令抓取实例发送⼼跳信息⽹络包的情况。

例如，执⾏下⾯的命令后，我们可以抓取到192.168.10.3机器上的实例从16379端⼝发送的⼼跳⽹络包，并
把⽹络包的内容保存到r1.cap⽂件中：

```shell
tcpdump host 192.168.10.3 port 16379 -i ⽹卡名 -w /tmp/r1.cap
```

通过分析⽹络包的数量和⼤⼩，就可以判断调整cluster-node-timeout值前后，⼼跳消息占⽤的带宽情况了。


## 2.1 不同规模下的带宽开销估算

下表以 `cluster-node-timeout = 15s` 为默认值，估算不同集群规模下**单实例**每秒发送 PING 消息的带宽消耗（假设有 10% 的实例 PONG 超时）：

| 集群实例数 | 每条 PING 消息大小 | 常规 PING (1/s) | 超时补发 PING (10/s × 超时数) | 单实例总发送带宽 | 集群总带宽 |
|-----------|-------------------|----------------|------------------------------|----------------|-----------|
| 100 | ~3KB | 1条/s | ~10 × 10 = 100条/s | ~300KB/s | ~30MB/s |
| 300 | ~5KB | 1条/s | ~10 × 30 = 300条/s | ~1.5MB/s | ~450MB/s |
| 500 | ~8KB | 1条/s | ~10 × 50 = 500条/s | ~4MB/s | ~2GB/s |
| 1000 | ~12KB | 1条/s | ~10 × 100 = 1000条/s | ~12MB/s | ~12GB/s |

> 上表为最坏情况估算（10% PONG 超时率）。实际带宽消耗取决于网络质量和 `cluster-node-timeout` 设置。可以看到，**集群规模超过 300 节点后，Gossip 带宽开销就已经非常显著了**。

## 2.2 其他优化手段

除了调整 `cluster-node-timeout` 外，还有一些辅助手段可以降低通信开销或规避其影响：

**1. 合理规划集群分片数**

不要一味增加实例数。如果单实例内存足够（建议 2-6GB），优先考虑**增大单实例内存**而不是增加实例数。例如，保存 100GB 数据，用 20 个 5GB 实例比用 100 个 1GB 实例的 Gossip 开销要小得多。

**2. 使用独立网卡或 VLAN 隔离集群通信**

将集群内部的 Gossip 通信流量和客户端业务流量隔离到不同的网络接口或 VLAN 上，避免心跳消息与业务请求竞争带宽。Redis 的 `cluster-announce-bus-port` 配置项可以为集群总线指定独立端口。

**3. 多集群替代超大集群**

当业务数据量确实需要数百个实例时，可以考虑按业务维度拆分为**多个较小的集群**，每个集群控制在 200-300 实例以内。在应用层通过路由规则将请求分发到对应的集群。

**4. 监控 Gossip 带宽**

除了 `tcpdump` 抓包分析外，还可以通过以下方式监控集群通信状态：

```bash
# 查看集群整体状态
redis-cli cluster info

# 关注以下指标：
# cluster_stats_messages_ping_sent     - 发送的PING消息总数
# cluster_stats_messages_pong_sent     - 发送的PONG消息总数
# cluster_stats_messages_ping_received - 接收的PING消息总数
# cluster_stats_messages_pong_received - 接收的PONG消息总数
```

通过定期采集这些指标并计算增长速率，就可以实时了解集群的 Gossip 消息频率。


# 3 小结

| 主题 | 核心要点 |
|------|---------|
| Gossip 通信机制 | 每个实例通过 PING/PONG 消息携带自身状态 + 1/10 节点信息 + 槽位图（2KB）实现去中心化信息传播 |
| 消息大小 | 单条 PING/PONG ≈ 实例状态（104B × N/10）+ 槽位图（2KB），1000 节点时约 12KB/条 |
| 通信频率 | 常规每秒 1 次 + 每 100ms 检查 PONG 超时（> cluster-node-timeout/2）补发 |
| 带宽瓶颈 | 集群规模越大 → 超时概率越高 → 补发 PING 越多 → Gossip 带宽挤占业务带宽 |
| 核心调优 | 调大 `cluster-node-timeout`（如 20-25s），在故障检测速度与带宽开销之间取平衡 |
| 辅助手段 | 控制实例数（优先增大单实例内存）、网络隔离、多集群拆分、监控 cluster info 指标 |

**生产建议**：

1. **集群规模控制在 400-500 实例以内**。400-500 实例（200-250 主）× 8 万 QPS/实例 ≈ 1600-2000 万 QPS，已能满足绝大多数业务需求
2. **调整 `cluster-node-timeout` 到 20-25 秒**可有效降低 Gossip 带宽，但要接受故障检测延迟相应增大的代价
3. **定期监控 `cluster_stats_messages_*` 指标**，当 PING 发送速率异常增长时，说明集群通信压力增大，需要排查网络质量或考虑缩减规模