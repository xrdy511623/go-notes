
---
详解binlog日志、undo日志和redo日志
---

# 1 redo log 重做日志

为了避免更新操作时频繁的写磁盘，MySQL使用了WAL(write ahead log)技术，也就是先写日志，后写磁盘。
具体来说，当有一条记录需要更新时，InnoDB引擎就会先把记录写到redo log里面，并更新内存(buffer pool)，这个时候就算
更新完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新时机往往是在系统比较空闲的时候。
redo log日志是固定大小，顺序写入的，如果写满了会从头开始写，也就是会覆盖旧的日志。
也就是说 redo log 只会记录未刷盘的日志，已经刷入磁盘的数据都会从redo log 这个有限大小的日志文件里删除。
redo log重做日志主要功能就是在数据库异常重启后，可以根据它将之前提交的事务的修改记录恢复数据，这就是crash-safe，也就是崩溃恢复能力。
innodb_flush_log_at_trx_commit这个参数设置为1表示每次事务的redo log重做日志都直接持久化到磁盘，如此可以确保MySQL异常重启后数据不丢失。


# 2 binlog 归档日志





![binlog-pos.png](images%2Fbinlog-pos.png)





![binlog-detail.png](images%2Fbinlog-detail.png)





![binlog-detail-finish.png](images%2Fbinlog-detail-finish.png)





现在，我们来看一下上图的输出结果。
- 第一行 SET @@SESSION.GTID_NEXT='ANONYMOUS’你可以先忽略，后面文章我们会在介绍主备切换的时候再提到；
- 第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务；
- 第三行就是真实执行的语句了。可以看到，在真实执行的 delete 命令之前，还有一个“use ‘sexmsg’”命令。这条命令不是
- 我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，
- 不论当前的工作线程在哪个库里，都能够正确地更新到 sexmsg 库的表 t。 use 'sexmsg’命令之后的 delete 语句，就是我们输入
- 的 SQL 原文了。可以看到，binlog“忠实”地记录了 SQL 命令，甚至连注释也一并记录了。
- 最后一行是一个 COMMIT。你可以看到里面写着 xid=16。





![binlog-warning.png](images%2Fbinlog-warning.png)





可以看到，运行这条 delete 命令产生了一个 warning，原因是当前 binlog 设置的是 statement 格式，并且语句中有 limit，所以这个
命令可能是 unsafe 的。
为什么这么说呢？这是因为 delete 带 limit，很可能会出现主备数据不一致的情况。比如上面这个例子：
1. 如果 delete 语句使用的是索引 a，那么会根据索引 a 找到第一个满足条件的行，也就是说删除的是 a=4 这一行；
2. 但如果使用的是索引 t_modified，那么删除的就是 t_modified='2018-11-09’也就是 a=5 这一行。
   由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；
3. 而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。

那么，如果我把 binlog 的格式改为 binlog_format=‘row’， 是不是就没有这个问题了呢？我们先来看看这时候 binlog 中的内容吧。





![row-binlog.png](images%2Frow-binlog.png)





![row-binlog-more.png](images%2Frow-binlog-more.png)





可以看到，与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了
SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。
1. Table_map event，用于说明接下来要操作的表是 test 库的表 t;
2. Delete_rows event，用于定义删除的行为。 
其实，我们通过show binlog events 是看不到详细信息的，还需要借助 mysqlbinlog 工具，用下面这个命令解析和查看
binlog 中的内容。因为show binlog events的结果信息显示，这个事务的 binlog 是从 2201这个位置开始的，所以可以用
start-position 参数来指定从这个位置的日志开始解析。

```shell
sudo mysqlbinlog -vv mysql-bin.000003 --start-position=2201;
```





![parse-row-binlog.png](images%2Fparse-row-binlog.png)





![parse-row-binlog-finish.png](images%2Fparse-row-binlog-finish.png)





从这个图中，我们可以看到以下几个信息：
- server id 1，表示这个事务是在 server_id=1 的这个库上执行的。
- 每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32。
- Table_map event 跟在show binlog events结果图中看到的相同，显示了接下来要打开的表，map 到数字 88。现在我们这条
- SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 Table_map event、都会 map 到一个单独的数字，用于区分对不同表的操作。
- 我们在 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、 @2=4 这些值）。
- 从DELETE FROM 'test.t' WHERE@1=4，@2=4，@3=1541779200可以看出这个日志精确地记录了删除的是WHERE id=4,a=4, t_modified=1541779200
- (也就是’2018-11-10‘)这一行数据。
- binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把 binlog_row_image 设置为 MINIMAL，
- 则只会记录必要的信息，在这个例子里，就是只会记录 id=4 这个信息。
- 最后的 Xid event(Xid=27)，用于表示事务被正确地提交了。
  可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，
- 不会有主备删除不同行的问题。


## 2.1 为什么会有 mixed 格式的 binlog？

基于上面的信息，我们来讨论一个问题：为什么会有 mixed 这种 binlog 格式的存在场景？推论过程是这样的：
- 因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。
- 但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 
- 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。
- 这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。
- 所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句
- 是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。
  也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了主备数据不一致的风险。
  因此，如果你的线上 MySQL 设置的 binlog 格式是 statement 的话，那基本上就可以认为这是一个不合理的设置。你至少应该
- 把 binlog 的格式设置为 mixed。
  比如我们这个例子，设置为 mixed 后，就会记录为 row 格式；而如果执行的语句去掉 limit 1，就会记录为 statement 格式。


## 2.2 为什么建议将binlog格式设置为row?

现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，我来给你举一个可以直接看出来的好处：恢复数据。
接下来，我们就分别从 delete、insert 和 update 这三种 SQL 语句的角度，来看看数据恢复的问题。
通过上图你可以看出来，即使我执行的是 delete 语句，row格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条
delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了。
如果你是执行错了 insert 语句呢？那就更直接了。row 格式下，insert 语句的 binlog 里会记录所有的字段信息，这些信息可以用来
精确定位刚刚被插入的那一行。这时，你直接把 insert 语句转成 delete 语句，删除掉这被误插入的一行数据就可以了。
如果执行的是 update 语句的话，row格式的binlog 里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 update 语句的话，
只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了。


注意：
有人在重放 binlog 数据的时候，是这么做的：用 mysqlbinlog 解析出日志，然后把里面的 statement 语句直接拷贝出来执行。
你现在知道了，这个方法是有风险的。因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的。
所以，用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令：

```shell
mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;
```

这个命令的意思是，将 master.000001 文件里面从第 2738 字节到第 2973 字节中间这段内容解析出来，放到 MySQL 去执行。

与redo log重做日志是引擎层所独有的日志不同(InnoDB引擎)，binlog归档日志是server层的日志，它主要用于增量备份恢复数据以及主从同步。
binlog日志有三种格式，statement, row以及mixed
statement格式的binlog，记录的是执行的SQL语句，也就是主库执行了什么SQL语句，binlog就记录什么SQL语句。
其优点是因为只记录SQL语句，日志记录量较少，可以节约磁盘空间和网络IO。

缺点是对于如UUID()之类的非确定性函数，或者走不同索引会造成主从库执行结果不同，导致主从数据不一致，因此生产环境一般不使用。

row格式的binlog，记录的是每一行记录的增删改操作，若一条SQL语句修改了一千条记录，row格式的binlog便会分别记录一千条记录的修改。
其优点是主从复制安全，不会出现主从数据不一致的问题。
缺点是日志记录太多，比较消耗磁盘存储空间和网络IO。

sync_binlog这个参数设置为1，表示每次事务的binlog日志都持久化到磁盘，如此可以保证MySQL异常重启后binlog日志不丢失。


# 3 redo log重做日志与binlog归档日志的区别

redo log是InnoDB引擎所特有的，而binlog是MySQL的Server层实现的，所有引擎都可以使用。
redo log是物理日志，记录的是在某个数据页上做了什么修改；而binlog是逻辑日志，记录的是这个语句的原始逻辑，比如给id=2这一行的字段c加1。
redo log是循环写的，空间固定会用完，会有覆盖旧日志的问题；而binlog是追加写入的，写到一定大小后会切换到下一个日志，并不会覆盖以前的日志。


## 3.1 redo log重做日志与binlog归档日志结合使用与二阶段提交

下面以一个简单的update语句为例，看看整个操作流程。





![two-phase-commit-one.png](images%2Ftwo-phase-commit-one.png)





那么在两阶段提交的不同瞬间，MySQL如果发生异常重启，是如何保证数据完整性的？





![two-phase-commit-two.png](images%2Ftwo-phase-commit-two.png)





如果在图中时刻A的地方，也就是写入redo log处于prepare阶段之后，写binlog之前，发生了崩溃(crash)，
由于此时binlog还没写，redo log也还没提交，所以崩溃恢复时，这个事务会回滚。此时，binlog没写，所以也不会
传到备库(从库)，因此不会出现主从数据不一致的问题。

如果是在图中时刻B的地方，也就是binlog写完，redo log还没commit前发生了crash，那崩溃恢复的时候MySQL会怎么处理？
我们先来看一下崩溃恢复时的判断规则：
1 如果redo log里面的事务是完整的，也就是已经有了commit标识，则直接提交；
2 如果redo log里面的事务只有完整的prepare, 则判断对应的事务binlog是否存在并完整；
A 如果是，则提交事务；
B 否则，回滚事务。
这里，时刻B发生crash对应的就是2(a)的情况，崩溃恢复过程中事务会被提交。

那么，就有了以下一系列问题


### 3.1.1 追问1: MySQL是怎么知道binlog是完整的？

我们知道，一个事务的binlog是有完整格式的:
statement格式的binlog, 最后会有COMMIT;
row格式的binlog，最后会有一个XID的event。

另外，在MySQL5.6.2版本以后，还引入了binlog-checksum参数，用来验证binlog内容的正确性。对于binlog日志由于磁盘原因，
可能会在日志中间出错的情况，MySQL可以通过校验checksum的结果来发现。所以，MySQL还是有办法验证事务binlog的完整性的。


## 3.1.2 追问2: redo log和binlog是怎么关联起来的？

因为它们有一个共同的数据字段，叫作XID。崩溃恢复时，会按照顺序扫描redo log：
如果碰到既有prepare，又有commit的redo log，就直接提交。
如果碰到只有prepare，没有commit的redo log，就拿着XID去binlog找对应的事务，如果能找到完整的事务，则提交该事务，否则回滚事务。


## 3.1.3 追问3：处于prepare阶段的redo log加上完整的binlog，重启就能恢复，MySQL为什么要这样设计？
这跟主备(从)数据一致性有关。在时刻B，也就是binlog写完，redo log还没commit前发生了crash，此时binlog已经写入了，之后就会被从库
(或者用binlog恢复出来的库)使用。也就是说，之后从库会应用这个事务对数据的修改，那么显然主库上也要提交这个事务，否则会造成主从库数据不一致。


## 3.1.4 追问4：如果这样的话，为什么还要两阶段提交呢？干脆先写完redo log，再写binlog。崩溃恢复时，必须得两个日志都完整才可以。是不是一样的逻辑？

这主要与事务的持久性有关。
对于InnoDB引擎来说，如果redo log提交完成了，事务就不能回滚(如果这还允许回滚，就可能覆盖掉别的事务的更新)。而如果redo log直接提交，
然后binlog写入的时候失败，InnoDB又回滚不了，数据和binlog日志又不一致了，这会造成主从数据不一致。
两阶段提交就是为了给所有人一个机会，当每个人都说ok时，再一起提交。


## 3.1.5 追问5: 不引入两个日志，也就没有两阶段提交的必要了。只用binlog来支持崩溃恢复，又能支持归档，不就可以了？

不行，因为binlog不支持崩溃恢复。
历史原因是，InnoDB引擎并不是MySQL的原生存储引擎。MySQL的原生引擎是MyISAM，设计之初就没有支持崩溃恢复。
InnoDB在作为MySQL的插件加入MySQL引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。
InnoDB在接入了MySQL后，发现既然binlog没有崩溃恢复能力，那就用InnoDB原有的redo log好了。
另外，从实现上来说，binlog是无法支持崩溃恢复的。
redo log 和 binlog 有一个很大的区别就是，一个是循环写，一个是追加写。也就是说 redo log 只会记录未刷盘的日志，
已经刷入磁盘的数据都会从 redo log 这个有限大小的日志文件里删除。binlog 是追加日志，保存的是全量的日志。
当数据库 crash 后，想要恢复未刷盘但已经写入 redo log 和 binlog 的数据到内存时，binlog 是无法恢复的。
虽然 binlog 拥有全量的日志，但没有一个标志让 InnoDB 判断哪些数据已经刷盘，哪些数据还没有。
举个例子，binlog 记录了两条日志：
给 ID=2 这一行的 c 字段加1
给 ID=2 这一行的 c 字段加1
在记录1刷盘后，记录2未刷盘时，数据库 crash。重启后，只通过 binlog 数据库无法判断这两条记录哪条已经写入磁盘，
哪条没有写入磁盘，不管是两条都恢复至内存，还是都不恢复，对 ID=2 这行数据来说，都不对。
但 redo log 不一样，只要刷入磁盘的数据，都会从 redo log 中抹掉，数据库重启后，直接把 redo log 中的数据都
恢复至内存就可以了。这就是为什么 redo log 具有 crash-safe 的能力，而 binlog 不具备。

这样的话，那我优化一下binlog的内容，让它来记录数据页的更改可以吗？
可以是可以，但是这不就是又做了一个redo log出来吗？既然有现成的redo log，何必再做重复工作？


## 3.1.6 追问6: 那能不能反过来，只用redo log，不用binlog？

如果只是从崩溃恢复的角度看当然是可以的，你可以把binlog关掉，这样就没有两阶段提交了，但系统仍然是crash-safe的。
但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog都是开着的，因为它有着redo log无法替代的功能，
那就是归档和支撑MySQL高可用。
首先说归档。redo log是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log也就起不到归档的作用。
再来看MySQL的高可用。我们知道，MySQL高可用的基础，就是binlog复制，备库或者说从库就是靠复制binlog来实现与主库数据一致的，
没了binlog，就没有了MySQL的高可用，读写分离支撑更高的并发也就无从谈起了。
此外，很多公司的异构系统(比如一些数据分析系统)，这些系统就靠消费MySQL的binlog来更新自己的数据。如果关掉binlog，这些下游系统就没法输入了。
所以，由于现在包括MySQL高可用在内的很多系统机制都依赖于binlog，所以redo log还无法取代它。你看，发展生态是多么的重要。


## 3.1.7 追问7：redo log一般设置多大？

redo log太小的话，会导致它很快被写满，然后不得不强行刷redo log，这样WAL机制的能力就发挥不出来了。
所以，如果是现在常见的几个Tb的话，就不要太小气了，直接将redo log设置成4个文件，每个文件1Gb。


## 3.1.8 追问8：正常运行中的实例，数据写入后的最终落盘，是从redo log更新过来的还是从buffer pool更新过来的？

这个问题涉及到了”redo log里面到底是什么“的问题。
实际上，redo log并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在”数据最终落盘，是由redo log更新过去“的情况。

1 如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，成为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与
redo log毫无关系。

2 在崩溃恢复场景中，InnoDB如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让redo log更新内存内容。更新完成后，
内存页变成脏页，就回到了第一种情况的状态。


## 3.1.9 追问9： redo log buffer是什么？是先修改内存，还是先写redo log文件？

在一个事务的更新过程中，日志是要写多次的。譬如下面这个事务：

```sql
begin;
insert into t1 ...
insert into t2 ...
commit;
```

这个事务是要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没commit的时候就直接写到redo log文件里。
所以redo log buffer就是一块内存，是用来先存redo log日志的。也就是说，在执行第一个insert的时候，数据的内存被修改了，redo log buffer也写入了日志。
但是，真正把日志写到redo log文件(文件名是ib_logfile+数字)，是在执行commit语句的时候做的。
单独执行一个更新语句的时候，InnoDB会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是压缩到了一个语句里完成而已。


# 4 如何解决刷脏页导致的MySQL性能下降问题？

当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

以下四种情况会引发数据库的 flush 过程。
当InnoDB 的 redo log 写满了，这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。





![redo-log-process.png](images%2Fredo-log-process.png)





checkpoint 可不是随便往前修改一下位置就可以的。比如上图中，把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志
（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。

- 第二种场景是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，
就要先将脏页写到磁盘。 你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿 redo log 出来应用 
不就行了？这里其实是从性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：
   - 一种是内存里存在，内存里就肯定是正确的结果，直接返回；
   - 另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。 这样的效率最高。

- 第三种场景是 MySQL 认为系统“空闲”的时候。
- 第四种场景是 MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

接下来，我们看一下上面四种场景对性能的影响。
其中，第三种情况是属于 MySQL 空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。所以这里，我们
主要来分析一下前两种场景下的性能问题。
第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须
堵住。如果你从监控上看，这时候更新数会跌为 0。
第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：
- 第一种是，还没有使用的；
- 第二种是，使用了并且是干净页；
- 第三种是，使用了并且是脏页。
  InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。
  而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接
- 释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。
  所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：
1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；
2. redo log日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。

所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。


## 4.1 InnoDB 刷脏页的控制策略

接下来，我们来看看 InnoDB 脏页的控制策略，以及和这些策略相关的参数。
首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。
这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 
这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：

```shell
fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest
```

其实，因为没能正确地设置 innodb_io_capacity 参数，而导致的性能问题也比比皆是。之前，就曾有其他公司的开发负责人找我看一个库的性能
问题，说 MySQL 的写入速度很慢，TPS 很低，但是数据库主机的 IO 压力并不大。经过一番排查，发现罪魁祸首就是这个参数的设置出了问题。
他的主机磁盘用的是 SSD，但是 innodb_io_capacity 的值设置的是 300。于是，InnoDB 认为这个系统的能力就这么差，所以刷脏页刷得特别慢，
甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。
InnoDB 的刷盘速度要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。
InnoDB 会根据这两个因素先单独算出两个数字。参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。
InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的
逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。
要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。
其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码：


```sql
select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
select @a/@b;
```

接下来，我们再看一个有趣的策略。
一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：
在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好也是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以
继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。
在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。
找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机
IO 就意味着系统性能的大幅度提升。
而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，
而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。
在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。


# 5 undo log(回滚日志)

前面的 redo log + binlog 解决的是"提交后如何持久化、如何复制、如何崩溃恢复提交结果"。
undo log 解决的是另外两个核心问题：

1. 事务原子性：事务失败时，如何把已经改过的数据撤销回去；
2. MVCC 一致性读：普通 SELECT 如何读到"历史版本"而不是被并发事务污染的数据。


## 5.1 undo log 到底记录了什么

undo log 不是"把整行完整备份一份"，它记录的是"把本次变更反向执行所需的信息"。
根据操作类型不同，InnoDB 内部将 undo log 分为两大类：**insert undo** 和 **update undo**，这两类 undo 的记录内容、
存储位置和生命周期都不同，理解这个区别非常重要。

### 5.1.1 insert undo

当事务执行 INSERT 操作时，产生的是 insert undo。它记录的是插入记录的主键值，回滚时只需根据主键值将这条记录删除即可。

insert undo 有一个重要特性：**它只对当前事务自身可见**。因为一条新插入的记录在事务提交之前，对其他事务是不可见的（其他事务
通过 MVCC 读不到未提交的插入），所以 insert undo 不需要提供给其他事务做历史版本回溯。这意味着 **insert undo 在事务提交后
就可以立即释放**，不需要等待 purge 线程来清理。

### 5.1.2 update undo

当事务执行 UPDATE 或 DELETE 操作时，产生的是 update undo。它记录的是被修改行的旧版本数据（修改前的字段值），
回滚时需要用这些旧值把记录恢复回去。

与 insert undo 不同，update undo **在事务提交后不能立即释放**，因为其他事务的一致性读（快照读）可能还需要通过这些旧版本数据
来构建历史快照。只有当系统中不存在任何需要引用该 undo 版本的活跃 ReadView 时，purge 线程才会异步清理这些 update undo。

注意：这里说的 DELETE 操作，在 InnoDB 内部并不是真正地物理删除记录，而是执行一个 "delete mark" 操作，即把记录的删除标志位
设置为1，表示这条记录已被标记删除。真正的物理删除是由 purge 线程在后续异步完成的。因此 DELETE 产生的也是 update undo。

### 5.1.3 两类 undo 的对比

| 维度 | insert undo | update undo |
|------|------------|-------------|
| 触发操作 | INSERT | UPDATE / DELETE |
| 记录内容 | 插入记录的主键值 | 被修改列的旧值 |
| 是否服务 MVCC | 否 | 是 |
| 提交后能否立即释放 | 是 | 否，需等 purge |
| 存放位置 | insert undo segment | update undo segment |

这个区别直接影响到生产环境的性能表现：大量 INSERT 操作对 undo 空间的压力远小于大量 UPDATE 操作，因为 insert undo 提交即释放，
而 update undo 会持续堆积直到 purge 清理。


### 5.1.4 隐藏列与版本链

在 InnoDB 中，聚簇索引（主键索引）的每条记录除了用户定义的列之外，还有几个隐藏列：

- `DB_TRX_ID`（6字节）：最后一次修改该行的事务 ID；
- `DB_ROLL_PTR`（7字节）：回滚指针，指向该行对应的 undo log 记录；
- `DB_ROW_ID`（6字节）：隐藏主键，只有在表没有显式定义主键时才会生成。

每次 UPDATE 或 DELETE 操作都会产生新的 undo 记录，并通过 `DB_ROLL_PTR` 串起来形成"版本链"。
我们用一个具体例子来说明这条版本链是怎么形成的。

假设有一张表：

```sql
CREATE TABLE account (
    id INT PRIMARY KEY,
    name VARCHAR(20),
    balance INT
) ENGINE=InnoDB;

INSERT INTO account VALUES (1, 'Alice', 1000);
```

插入完成后（假设该 INSERT 事务的 trx_id = 100），聚簇索引中这行记录的状态是：

```
┌────┬───────┬─────────┬────────────┬──────────────┐
│ id │ name  │ balance │ DB_TRX_ID  │ DB_ROLL_PTR  │
├────┼───────┼─────────┼────────────┼──────────────┤
│ 1  │ Alice │ 1000    │ 100        │ → insert undo│
└────┴───────┴─────────┴────────────┴──────────────┘
```

现在事务 A（trx_id = 200）执行：

```sql
UPDATE account SET balance = 800 WHERE id = 1;
```

InnoDB 会：
1. 将当前行的旧值（name='Alice', balance=1000, trx_id=100）写入一条 update undo 记录；
2. 在聚簇索引中原地更新这行记录，将 balance 改为 800，将 DB_TRX_ID 改为 200；
3. 将 DB_ROLL_PTR 指向步骤1中新写入的 undo 记录。

此时版本链变成：

```
聚簇索引当前记录:
┌────┬───────┬─────────┬────────────┬──────────────────┐
│ 1  │ Alice │  800    │ 200        │ DB_ROLL_PTR ─┐   │
└────┴───────┴─────────┴────────────┴──────────────┼───┘
                                                   ↓
                                    undo log (update undo):
                                    ┌──────────────────────┐
                                    │ name=Alice           │
                                    │ balance=1000         │
                                    │ trx_id=100           │
                                    │ roll_ptr → insert    │
                                    │           undo       │
                                    └──────────────────────┘
```

如果接着事务 B（trx_id = 300）再次执行：

```sql
UPDATE account SET balance = 500 WHERE id = 1;
```

版本链会继续增长：

```
聚簇索引当前记录:
┌────┬───────┬─────────┬────────────┬──────────────────┐
│ 1  │ Alice │  500    │ 300        │ DB_ROLL_PTR ─┐   │
└────┴───────┴─────────┴────────────┴──────────────┼───┘
                                                   ↓
                                    undo log (update undo):
                                    ┌──────────────────────┐
                                    │ name=Alice           │
                                    │ balance=800          │
                                    │ trx_id=200           │
                                    │ roll_ptr ────────┐   │
                                    └──────────────────┼───┘
                                                       ↓
                                    undo log (update undo):
                                    ┌──────────────────────┐
                                    │ name=Alice           │
                                    │ balance=1000         │
                                    │ trx_id=100           │
                                    │ roll_ptr → insert    │
                                    │           undo       │
                                    └──────────────────────┘
```

这条版本链既服务回滚（事务失败时沿链逆向恢复），也服务 MVCC 的历史版本可见性判断（快照读时沿链查找可见版本）。
版本链越长，一致性读需要回溯的距离就越远，查询性能也就越差——这正是长事务危害性的根源。


## 5.2 事务回滚是如何依赖 undo 的

以事务 T 为例：

```sql
BEGIN;
UPDATE account SET balance = balance - 100 WHERE id = 1;  -- 产生 update undo 记录①
UPDATE account SET balance = balance + 100 WHERE id = 2;  -- 产生 update undo 记录②
-- 这里发生异常
ROLLBACK;
```

回滚时，InnoDB 会按该事务产生 undo 记录的逆序执行补偿动作：

1. 根据 undo 记录②，撤销第二条 UPDATE，将 id=2 的 balance 恢复；
2. 根据 undo 记录①，撤销第一条 UPDATE，将 id=1 的 balance 恢复；
3. 释放锁，结束事务。

这就是"逻辑上的原子性"落到存储引擎层的实现路径。

这里有一个容易被忽视但非常重要的细节：**undo 页本身的变更也会写 redo log**。也就是说，redo log 会记录"向 undo 页写入了
一条 undo 记录"这个操作。这保证了即使在写 undo 的过程中发生 crash，重启后 redo log 也能恢复 undo 页到崩溃前的状态，
然后 InnoDB 再根据恢复后的 undo 来回滚那些处于活跃状态的未提交事务。因此 undo 自己也具备崩溃恢复能力。

整个崩溃恢复的流程是：
1. 先通过 redo log 前滚（redo），将所有数据页（包括 undo 页）恢复到崩溃前的状态；
2. 然后检查哪些事务在崩溃时还没有提交（处于活跃状态）；
3. 对这些未提交的事务，通过 undo log 进行回滚，撤销它们的修改。

这就是为什么说 redo 保证持久性，undo 保证原子性，两者配合才能实现完整的崩溃恢复。


## 5.3 MVCC 如何使用 undo 版本链

### 5.3.1 ReadView 是什么

在 READ COMMITTED / REPEATABLE READ 下，普通 SELECT 是快照读，InnoDB 通过 ReadView（读视图）来判断版本链上的
哪个版本对当前事务可见。

ReadView 本质上是一个"事务可见性快照"，它在创建时记录了当前系统中事务的活跃状态。一个 ReadView 包含以下四个关键字段：

| 字段 | 含义 |
|------|------|
| `creator_trx_id` | 创建该 ReadView 的事务自身的 trx_id |
| `m_ids` | 创建 ReadView 时，系统中所有**活跃（未提交）**事务的 trx_id 列表 |
| `min_trx_id` | `m_ids` 中的最小值，即活跃事务中最小的 trx_id |
| `max_trx_id` | 创建 ReadView 时，系统应该分配给下一个事务的 trx_id（即当前最大 trx_id + 1） |

注意 `max_trx_id` 不是 `m_ids` 中的最大值，而是全局事务 ID 的下一个待分配值。比如现在有 trx_id 为 3、5、8 的三个活跃事务，
那么 `min_trx_id = 3`，而 `max_trx_id` 可能是 9（取决于最近分配过的最大 trx_id）。


### 5.3.2 可见性判断算法

当一个事务执行快照读时，会拿到记录的 `DB_TRX_ID`（记为 `trx_id`），然后按照以下规则判断该版本是否对当前 ReadView 可见：

**规则1**：如果 `trx_id == creator_trx_id`，说明这条记录是当前事务自己修改的，**可见**。

**规则2**：如果 `trx_id < min_trx_id`，说明这条记录在 ReadView 创建之前就已经提交了，**可见**。

**规则3**：如果 `trx_id >= max_trx_id`，说明这条记录是在 ReadView 创建之后才开始的事务修改的，**不可见**。

**规则4**：如果 `min_trx_id <= trx_id < max_trx_id`，则需要进一步判断 `trx_id` 是否在 `m_ids` 列表中：
- 如果在 `m_ids` 中，说明修改这条记录的事务在 ReadView 创建时还处于活跃状态（未提交），**不可见**；
- 如果不在 `m_ids` 中，说明修改这条记录的事务在 ReadView 创建时已经提交了，**可见**。

如果当前版本不可见，就沿着 `DB_ROLL_PTR` 找到 undo log 中的上一个版本，重复上述判断，直到找到可见的版本为止。
如果沿着版本链一直到头都没有找到可见的版本，说明这条记录对当前事务完全不可见（相当于这条记录还不存在）。

用伪代码表示这个算法：

```
function is_visible(trx_id, ReadView):
    if trx_id == ReadView.creator_trx_id:
        return true                          // 规则1: 自己改的，可见
    if trx_id < ReadView.min_trx_id:
        return true                          // 规则2: 在ReadView之前已提交，可见
    if trx_id >= ReadView.max_trx_id:
        return false                         // 规则3: ReadView之后才开始，不可见
    if trx_id in ReadView.m_ids:
        return false                         // 规则4a: 创建ReadView时还活跃，不可见
    else:
        return true                          // 规则4b: 创建ReadView时已提交，可见
```

### 5.3.3 RC 与 RR 的 ReadView 生成时机差异

ReadView 的可见性判断算法在 RC 和 RR 两种隔离级别下是完全一样的，**唯一的区别在于 ReadView 的生成时机**：

- **READ COMMITTED（RC）**：每次执行 SELECT 语句时都会重新生成一个新的 ReadView。因此，同一个事务内两次 SELECT 可能
读到不同的结果（能读到其间其他事务已提交的修改）。

- **REPEATABLE READ（RR）**：只在事务中第一次执行 SELECT 语句时生成 ReadView，后续的 SELECT 复用同一个 ReadView。
因此，同一个事务内多次 SELECT 总是能读到一致的快照。

这个区别非常关键，它解释了为什么 RR 能实现可重复读，而 RC 不能。

### 5.3.4 一个完整的 MVCC 实战例子

我们用一个具体的并发场景来验证上面的可见性判断算法。

假设表 account 中有一行记录 (id=1, name='Alice', balance=1000)，该记录是由 trx_id=100 的事务插入并提交的。

```
时间线：
    T1: 事务A(trx_id=200) BEGIN;
    T2: 事务B(trx_id=300) BEGIN;
    T3: 事务C(trx_id=400) BEGIN;
    T4: 事务C UPDATE account SET balance=500 WHERE id=1;
    T5: 事务C COMMIT;
    T6: 事务A 执行 SELECT balance FROM account WHERE id=1;  ← 分析这个读取
    T7: 事务B UPDATE account SET balance=300 WHERE id=1;
    T8: 事务A 再次执行 SELECT balance FROM account WHERE id=1;  ← 分析这个读取
```

在 T6 时刻，事务A第一次执行 SELECT，生成 ReadView：
- `creator_trx_id = 200`
- `m_ids = [200, 300]`（事务A自己和事务B都处于活跃状态，事务C已在T5提交）
- `min_trx_id = 200`
- `max_trx_id = 401`

此时 id=1 这行记录的版本链是：

```
当前记录: balance=500, trx_id=400
    ↓ (roll_ptr)
undo: balance=1000, trx_id=100
```

判断过程：
1. 当前版本 trx_id=400，满足 `min_trx_id(200) <= 400 < max_trx_id(401)`，
   检查 400 是否在 m_ids[200, 300] 中 → 不在 → 说明 trx_id=400 的事务在 ReadView 创建时已提交 → **可见**！
2. 所以事务A在 T6 读到的 balance = **500**。

在 T8 时刻，事务A再次执行 SELECT：
- **RR 隔离级别下**：复用 T6 时刻创建的 ReadView（m_ids = [200, 300]）
- 此时版本链变成了：

```
当前记录: balance=300, trx_id=300
    ↓ (roll_ptr)
undo: balance=500, trx_id=400
    ↓ (roll_ptr)
undo: balance=1000, trx_id=100
```

判断过程：
1. 当前版本 trx_id=300，满足 `min_trx_id(200) <= 300 < max_trx_id(401)`，
   检查 300 是否在 m_ids[200, 300] 中 → 在 → **不可见**，沿版本链继续找；
2. 上一个版本 trx_id=400，同上面的分析 → 400 不在 m_ids 中 → **可见**！
3. 所以事务A在 T8 读到的 balance = **500**，与 T6 一致，实现了可重复读。

- **RC 隔离级别下**：T8 时刻会重新生成一个新的 ReadView
- 新的 ReadView：`m_ids = [200]`（此时只有事务A自己活跃，事务B在 T7 可能已提交也可能未提交，取决于具体时序）
- 假设事务B在 T7 已经提交，那么新 ReadView 的 `m_ids = [200]`
- 判断当前版本 trx_id=300：300 不在 m_ids[200] 中 → **可见**
- 所以事务A在 T8 读到的 balance = **300**，与 T6 的 500 不一致，这就是"不可重复读"。

### 5.3.5 追问1：快照读一定不会加锁吗？

普通 SELECT 确实不加锁，但需要注意两点：
1. `SELECT ... LOCK IN SHARE MODE` 和 `SELECT ... FOR UPDATE` 不是快照读，而是当前读，会加锁且总是读最新已提交版本；
2. 在 Serializable 隔离级别下，普通 SELECT 会被自动转化为 `SELECT ... LOCK IN SHARE MODE`，也就退化成了当前读。

### 5.3.6 追问2：MVCC 能完全解决幻读吗？

严格来说，MVCC 的快照读只能解决"快照读层面的幻读"。但如果事务中混合使用了快照读和当前读，仍然可能出现幻读。例如：

```sql
-- 事务A (RR)
BEGIN;
SELECT * FROM account WHERE id > 5;              -- 快照读，假设返回0行
-- 此时事务B插入id=10并提交
UPDATE account SET balance = 0 WHERE id = 10;     -- 当前读！能看到事务B插入的行
SELECT * FROM account WHERE id > 5;              -- 快照读，现在返回1行(id=10)
COMMIT;
```

这里第二次 SELECT 之所以能看到 id=10，是因为事务A的 UPDATE 语句对 id=10 这行做了修改（当前读），这行记录的 trx_id
变成了事务A自己的 trx_id，后续的快照读根据规则1（`trx_id == creator_trx_id`）判断为可见。
这就是为什么 InnoDB 在 RR 隔离级别下仍然需要 gap lock 来防止幻读——MVCC 的快照读无法覆盖所有场景。


## 5.4 undo 的物理存储结构

了解 undo log 的物理存储结构，有助于理解高并发场景下的性能瓶颈。

### 5.4.1 Undo Tablespace → Rollback Segment → Undo Segment → Undo Page → Undo Record

InnoDB 的 undo 存储是一个多层结构：

```
Undo Tablespace（undo 表空间）
  └── Rollback Segment（回滚段，简称 rseg）
        └── Undo Segment（undo 段，也叫 undo slot）
              └── Undo Page（undo 页）
                    └── Undo Record（undo 记录）
```

**Undo Tablespace（undo 表空间）**

在 MySQL 5.6 及之前，undo log 默认存储在系统表空间（ibdata1）中，这会导致 ibdata1 不断膨胀且无法收缩。
从 MySQL 5.6 开始支持独立的 undo tablespace，MySQL 8.0 开始默认使用独立 undo tablespace（默认2个）。

独立 undo tablespace 的优势是：当 undo 空间膨胀后，可以通过 `ALTER UNDO TABLESPACE ... SET INACTIVE` 来触发截断
（truncate），回收磁盘空间。而系统表空间中的 undo 是无法收缩的。

**Rollback Segment（回滚段）**

每个 undo tablespace 中包含若干个 rollback segment。由参数 `innodb_rollback_segments` 控制每个 undo tablespace 中的
回滚段数量，默认值为 128。

**Undo Segment（undo slot）**

每个 rollback segment 中包含 1024 个 undo slot。一个活跃事务在执行写操作时，需要占用 undo slot：
- 如果事务只有 INSERT 操作，需要 1 个 undo slot（insert undo segment）；
- 如果事务只有 UPDATE/DELETE 操作，需要 1 个 undo slot（update undo segment）；
- 如果事务既有 INSERT 又有 UPDATE/DELETE，需要 2 个 undo slot。

因此，系统能同时支持的最大写事务并发数 = undo tablespace 数量 × 128（rollback segment）× 1024（undo slot）。
以 MySQL 8.0 默认配置（2个 undo tablespace，128 个 rollback segment）为例：
最大并发写事务数 = 2 × 128 × 1024 = **262144**。

在绝大多数业务场景下这个数量足够，但如果遇到 "too many active concurrent transactions" 错误，说明并发写事务已经
耗尽了可用的 undo slot，就需要增加 undo tablespace 或调大 `innodb_rollback_segments`。


## 5.5 undo 的生命周期：写入、保留、purge

undo 不是事务提交后立刻物理删除，两类 undo 的生命周期有明显差异：

### 5.5.1 insert undo 的生命周期

```
事务执行 INSERT → 写入 insert undo → 事务提交 → insert undo 立即可释放
```

因为新插入的记录在事务提交前对其他事务不可见，所以提交后没有任何 ReadView 需要引用 insert undo，
可以直接将占用的 undo segment 标记为可复用。

### 5.5.2 update undo 的生命周期

```
事务执行 UPDATE/DELETE → 写入 update undo → 事务提交
    → update undo 进入 history list，按提交顺序排列
    → purge 线程检查：是否还有活跃 ReadView 引用此 undo？
        → 有引用：保留
        → 无引用：purge 清理，回收空间
```

这里的 history list 就是一个按事务提交顺序排列的 update undo 链表。purge 线程会从 history list 的尾部
（最早提交的事务）开始清理，逐步向头部推进。`SHOW ENGINE INNODB STATUS` 中的 `History list length` 就是这个链表的长度。

### 5.5.3 DELETE 操作的两阶段处理

前面提到 DELETE 在 InnoDB 内部不是真正的物理删除，这里详细展开：

阶段一（delete mark）：事务执行 DELETE 时，只是将记录的 `delete_flag` 标记为1，此时记录仍然存在于聚簇索引和二级索引中。
这个操作会产生 update undo 记录（记录了被标记删除行的旧值）。

阶段二（真正删除）：事务提交后，由 purge 线程在确认没有 ReadView 引用后，才真正将记录从聚簇索引和二级索引中物理删除，
并将空间标记为可复用。

之所以采用两阶段处理，正是因为 MVCC 的需要——如果在 DELETE 时立即物理删除，那么其他正在进行快照读的事务就无法通过
版本链找到这条被删除记录的历史版本了。


## 5.6 长事务风险：History List Length 持续增长

如果存在长事务（尤其长时间不提交的 RR 事务），会引发一系列连锁问题：

### 5.6.1 为什么长事务会导致 undo 堆积？

以一个具体场景来说明：

```
T1: 事务X（RR）BEGIN; SELECT ... （生成 ReadView，min_trx_id=100）
T2: 事务Y(trx_id=150) 执行大量 UPDATE 并 COMMIT
T3: 事务Z(trx_id=200) 执行大量 UPDATE 并 COMMIT
...
T100: 过了30分钟，事务X仍然没有提交
```

因为事务X在T1生成的 ReadView 仍然有效（`min_trx_id=100`），purge 线程在清理 update undo 时，
不能清理任何 `trx_id >= 100` 的 undo 记录（因为事务X可能还会读到它们）。这意味着事务Y、事务Z以及
之后所有事务产生的 update undo 都无法被 purge，全部堆积在 history list 中。

### 5.6.2 长事务造成的具体危害

1. **undo 表空间膨胀**：大量 update undo 无法清理，undo tablespace 文件持续增长。如果 undo 存储在系统表空间（ibdata1）中，
则 ibdata1 膨胀后无法收缩，即使后续 purge 完成也不能释放磁盘空间。

2. **查询性能下降**：一致性读需要沿版本链回溯到可见版本，版本链越长，回溯距离越远。在极端情况下，一条简单的
SELECT 语句可能需要遍历数十万条 undo 记录才能找到可见版本，导致查询时间从毫秒级退化到秒级甚至分钟级。

3. **purge 滞后引发的雪崩效应**：当长事务终于提交后，purge 线程需要清理大量积压的 undo 记录。purge 本身会消耗
CPU 和 IO 资源，如果积压量过大，purge 的速度可能跟不上新的 undo 产生速度，导致 history list length 持续居高不下。

4. **对二级索引的影响**：被 delete mark 的记录由于无法被 purge 物理删除，会导致二级索引中存在大量"已标记删除但仍占空间"
的记录，影响索引扫描的效率。

常见现象是 `History list length` 长时间居高不下，健康状态下这个值通常应该在几百到几千，如果达到几十万甚至更高就需要警惕了。


## 5.7 线上排查与监控

### 5.7.1 定位长事务

```sql
-- 查看当前所有活跃事务，按开始时间排序，最早的排前面
SELECT trx_id, trx_state, trx_started,
       TIMESTAMPDIFF(SECOND, trx_started, NOW()) AS running_seconds,
       trx_rows_locked,
       trx_rows_modified,
       trx_query
FROM information_schema.innodb_trx
ORDER BY trx_started;
```

输出示例与解读：

```
trx_id: 421553081243
trx_state: RUNNING
trx_started: 2024-01-15 10:05:32
running_seconds: 1847
trx_rows_locked: 0
trx_rows_modified: 0
trx_query: NULL
```

这里需要注意的关键点：
- `running_seconds` 很大（1847秒，约30分钟）说明这是一个长事务；
- `trx_rows_modified = 0` 说明这个事务没有做任何修改，很可能是开了事务后执行了一次 SELECT 就再也没有操作（但事务一直没提交）；
- `trx_query = NULL` 说明该事务当前没有在执行任何 SQL，处于空闲状态。

这种"开了事务但不提交也不关闭"的情况在业务代码中非常常见，比如事务中间调用了外部 RPC 而长时间未返回，
或者用了连接池但没有正确释放连接。

### 5.7.2 监控 History List Length

```sql
-- 方式一：通过 SHOW ENGINE INNODB STATUS 查看
SHOW ENGINE INNODB STATUS\G
```

在输出中找到 TRANSACTIONS 段：

```
------------
TRANSACTIONS
------------
Trx id counter 421553082000
Purge done for trx's n:o < 421553081900 undo n:o < 0 state: running but idle
History list length 58623
```

关键指标解读：
- `Purge done for trx's n:o < 421553081900`：purge 已经清理到 trx_id = 421553081900 之前的 undo；
- `History list length 58623`：当前 history list 中有 58623 条未清理的 update undo 记录，这个值偏高，
正常情况下应该在几百到几千。

```sql
-- 方式二：MySQL 8.0+ 通过 innodb_metrics 查看（更方便做监控采集）
SELECT name, count
FROM information_schema.innodb_metrics
WHERE name = 'trx_rseg_history_len';
```

```sql
-- 方式三：查看 undo tablespace 使用情况（MySQL 8.0+）
SELECT TABLESPACE_NAME, FILE_NAME, AUTOEXTEND_SIZE
FROM information_schema.FILES
WHERE FILE_TYPE = 'UNDO LOG';
```

### 5.7.3 治理思路

**事前预防**：

1. **缩短事务**：避免在事务内执行外部 RPC、用户交互、文件IO等耗时操作。事务应该只包含必要的数据库操作，
"开事务 → 读写数据 → 立即提交"是最佳实践；

2. **大批量写入拆分**：将一个 UPDATE/DELETE 10万行的大事务拆成每次 1000 行的小批次，每批次独立提交。
这样每个小事务的 undo 可以被及时 purge：

```sql
-- 不推荐：一个大事务
DELETE FROM logs WHERE create_time < '2024-01-01';

-- 推荐：分批删除
REPEAT
    DELETE FROM logs WHERE create_time < '2024-01-01' LIMIT 1000;
UNTIL ROW_COUNT() = 0 END REPEAT;
```

3. **设置长事务告警**：对运行超过一定时间（如60秒）的事务进行监控报警：

```sql
-- 可以用这个查询做定时巡检
SELECT trx_id, trx_started, trx_query
FROM information_schema.innodb_trx
WHERE TIMESTAMPDIFF(SECOND, trx_started, NOW()) > 60;
```

4. **MySQL 5.7+ 可以通过 `kill` 命令杀掉长事务对应的连接**：

```sql
-- 先找到长事务对应的线程 ID
SELECT trx_mysql_thread_id
FROM information_schema.innodb_trx
WHERE TIMESTAMPDIFF(SECOND, trx_started, NOW()) > 300;

-- 然后 kill 掉
KILL <thread_id>;
```

**事后调优**：

5. **调大 purge 线程数**：`innodb_purge_threads` 默认值为4（MySQL 8.0），如果 purge 跟不上写入速度可以适当调大，
但一般不超过核心数的一半；

6. **使用独立 undo tablespace + 自动截断**（MySQL 8.0+）：

```sql
-- 查看 undo tablespace 配置
SELECT @@innodb_undo_tablespaces;  -- 默认2
-- 开启自动截断
SET GLOBAL innodb_undo_log_truncate = ON;
-- 设置截断触发阈值（超过此大小时触发截断，默认 1GB）
SET GLOBAL innodb_max_undo_log_size = 1073741824;
```


## 5.8 undo、redo、binlog 三者分工

把三个日志放在一起对比：

| 维度 | undo log | redo log | binlog |
|------|----------|----------|--------|
| 所属层级 | InnoDB 引擎层 | InnoDB 引擎层 | MySQL Server 层 |
| 日志类型 | 逻辑日志（记录反向操作） | 物理日志（记录数据页修改） | 逻辑日志（记录SQL或行变更） |
| 写入方式 | 随事务操作产生 | 顺序追加写，循环覆盖 | 顺序追加写，不覆盖 |
| 核心作用 | 回滚 + MVCC | crash-safe | 复制 + 归档 |
| ACID 对应 | 原子性（A）+ 隔离性（I） | 持久性（D） | — |
| 事务提交后 | update undo 保留至 purge | 刷盘后可覆盖 | 永久保留（除非手动清理） |

对应关系：

1. 原子性（A）：主要靠 undo——事务失败时通过 undo 逆向补偿，撤销所有已执行的修改；
2. 隔离性（I）：主要靠 undo + 锁——MVCC 利用 undo 版本链提供一致性读，锁机制保证写-写互斥；
3. 持久性（D）：主要靠 redo——已提交事务的修改通过 redo log 保证在 crash 后可恢复；
4. 复制/归档：主要靠 binlog——主从同步和增量备份都依赖 binlog；
5. 主从一致提交点：靠 redo + binlog 的两阶段提交——保证 redo 和 binlog 在逻辑上的一致性。

一句话总结：
redo 关注"提交结果不能丢"，undo 关注"未提交结果能撤销 + 已提交历史能回溯"，binlog 关注"变更可以被复制和回放"。


## 5.9 追问汇总

### 5.9.1 追问1：undo log 自身会不会丢失？

不会。因为 undo 页本身的修改也会记录到 redo log 中。所以 undo log 的持久性是由 redo log 来保证的。
崩溃恢复时，先通过 redo log 恢复 undo 页，再用恢复出来的 undo 来回滚未提交事务。

### 5.9.2 追问2：大事务为什么需要格外警惕？

一个修改了100万行的事务，会产生100万条 update undo 记录。在事务执行过程中（尚未提交），这些 undo 记录既不能
被 purge，也不能被释放。如果此时事务回滚，InnoDB 需要逐条应用这100万条 undo 做逆向补偿，回滚时间可能比执行时间
还要长。同时，在回滚期间，这些记录上持有的锁也不会释放，会阻塞其他事务。

所以大事务的风险是双重的：正常提交时 purge 压力大，异常回滚时恢复时间长。

### 5.9.3 追问3：为什么说 RC 隔离级别对 undo 的压力更小？

在 RC 下，每次 SELECT 都生成新的 ReadView，这意味着旧的 ReadView 会被快速丢弃。一旦系统中没有引用某个
undo 版本的 ReadView 了，purge 线程就可以清理该 undo。

而在 RR 下，ReadView 在事务第一次 SELECT 时生成并持续到事务结束。一个长时间运行的 RR 事务会"钉住"一个很早的
ReadView，导致该 ReadView 之后的所有 update undo 都无法被清理。

这也是为什么很多互联网公司的生产环境选择 RC 而非 RR 作为默认隔离级别的原因之一——RC 对 undo 更友好，
purge 更及时，undo 表空间膨胀的风险更低。

### 5.9.4 追问4：只读事务会影响 purge 吗？

会。即使一个事务只执行了 SELECT（没有任何写操作），只要它在 RR 隔离级别下生成了 ReadView 且一直不提交，
就会阻止 purge 清理在该 ReadView 之后提交的所有 update undo。这就是为什么"开了事务不提交"即使没做任何
写操作也是有害的。

### 5.9.5 追问5：innodb_undo_log_truncate 是怎么回收空间的？

MySQL 8.0 支持 undo tablespace 的在线截断（truncate）。其工作原理是：
1. 当某个 undo tablespace 的大小超过 `innodb_max_undo_log_size`（默认1GB）时，触发截断；
2. InnoDB 将该 undo tablespace 标记为 inactive，不再向其中分配新的 undo segment；
3. 等待该 tablespace 中所有活跃的 undo segment 都不再被引用后，将其文件截断为初始大小；
4. 截断完成后重新标记为 active，恢复正常使用。

注意，截断过程需要至少有 2 个 undo tablespace，这样一个被截断时另一个可以继续服务。这也是 MySQL 8.0 默认配置
`innodb_undo_tablespaces = 2` 的原因。
