
---
索引详解
---

# 1 MySQL索引使用的是什么数据结构，为什么不使用B树、哈希索引或跳表？
MySQL索引使用的是B+树的数据结构，只在叶子节点存储行数据，非叶子节点存储的是索引值，同样的存储空间，B+树能够
存储更多的数据，使得整棵树更加扁平，树的高度(深度)更低，IO查询效率比B树更高，因为B树所有节点都会存储行数据。
另外，B+树的叶子节点是按照索引值顺序排列的，且有前后指针相连组成有序链表，这样非常便于范围查询，这是B树所不能比的。
哈希索引对于等值查询效率是最优的，因为时间复杂度仅为O(1)，但是它无法适应范围查询。
相对于跳表，B+树是一种多路平衡树，其每个节点可以包含多个子节点，16k的数据页三层就可以存储约2000万条数据，查询最多只需要
3次磁盘IO，而跳表是链表结构，一条数据一个节点，如果最底层要存储2000万条数据，且每次查询都要能达到二分查找的效果，
2000万大概是2的24次方左右，也就是跳表高度大概为24层，最坏情况下，这24层数据会分散在不同的数据页里，也就是查询一次’
数据需要24次磁盘IO。因此存放同样量级的数据，B+树的高度比跳表低很多，IO查询效率明显更优。
而针对写操作，B+树需要拆分合并索引数据页，跳表则独立插入，并根据随机函数确定层数，没有旋转和维持平衡的开销，因此跳表
的写入性能会比B+树要好。
Redis的zset(有序集合)使用跳表而不是B+树，一是Redis读写数据都是操作内存，因此也不存在磁盘IO了，所以层高就不再是跳表
的劣势了。而跳表插入数据时，是根据随机函数确定层数的，没有类似B+树那样的旋转和维持平衡的开销，因此跳表的写入性能会比
B+树要好，而且B+树的节点分裂、合并、平衡维护较复杂，使用跳表可以同时降低开发和维护的复杂性，所以Redis的有序集合会
使用跳表而不是B+树。

# 2 索引树查找过程

比如说我们需要查找一个id=6 的行数据，因为在非叶子节点中存放的是页号和该页最小的id，所以我们从顶层开始对比，首先看
页号10 中的目录，有[id=1,页号=20],[id=5,页号=30],说明左侧节点最小id为1，右侧节点最小id 是5；6>5,那按照二分
法查找的规则，肯定就往右侧节点继续查找，找到页号30的节点后，发现这个节点还有子节点（非叶子节点），那就继续比对，
同理，6>5&&6<7,所以找到了页号60，找到页号60之后，发现此节点为叶子节点（数据节点），于是将此页数据加载至内存进行
一一对比，结果找到了id=6 的数据行。
从上述的过程中发现，我们为了查找id=6 的数据，总共查询了三个页，如果三个页都在磁盘中（未提前加载至内存），那么最多
需要经历三次的磁盘IO。





![index-search.png](images%2Findex-search.png)





需要注意的是，图中的页号只是个示例，实际情况下并不是连续的，在磁盘中存储也不一定是顺序的。


# 3 聚簇索引与二级索引

前面第2节演示的索引树查找过程，用的是主键 id 来查找的。但在实际业务中，我们经常需要用非主键字段来查询，比如按 name、
phone、order_no 这些字段查询。那这些字段上的索引和主键索引有什么区别呢？这就涉及到 InnoDB 中两种最核心的索引类型：
**聚簇索引（Clustered Index）**和**二级索引（Secondary Index）**。

理解这两者的存储结构差异，是理解回表、覆盖索引、索引设计等一切后续内容的基础。

## 3.1 聚簇索引

聚簇索引就是主键索引。在 InnoDB 中，表数据本身就是按照主键的顺序存放在聚簇索引的 B+ 树中。也就是说，
**聚簇索引的叶子节点存储的是完整的行数据**。

```
聚簇索引（主键索引）

              ┌─────────────┐
              │  [5] [10]   │               ← 非叶子节点（存主键值+页号）
              └──┬────┬──┬──┘
           ┌─────┘    │  └─────┐
           ↓          ↓        ↓
    ┌──────────┐ ┌──────────┐ ┌──────────┐
    │ id=1 整行 │ │ id=5 整行 │ │ id=10整行 │  ← 叶子节点（存完整行数据）
    │ id=3 整行 │ │ id=7 整行 │ │ id=12整行 │
    │ id=4 整行 │ │ id=9 整行 │ │ id=15整行 │
    └────┬─────┘ └────┬─────┘ └────┬─────┘
         └──→ 双向链表 ←──┘→ 双向链表 ←──┘     ← 叶子节点之间有双向指针
```

关键点：
- 叶子节点存的不只是主键值，而是**整行数据**（所有字段的值）
- 一张 InnoDB 表只有一棵聚簇索引树，表数据就存在这棵树中
- 叶子节点之间通过双向链表连接，便于范围查询

## 3.2 二级索引

二级索引也叫非聚簇索引、辅助索引，就是我们在非主键字段上创建的索引。与聚簇索引不同，
**二级索引的叶子节点存储的是索引列的值 + 对应的主键值**，而不是完整行数据。

假设我们在 name 字段上创建了一个索引 `idx_name`：

```sql
CREATE INDEX idx_name ON user(name);
```

那么这棵二级索引 B+ 树的结构是：

```
二级索引（idx_name）

              ┌───────────────┐
              │ [Jack] [Tom]  │              ← 非叶子节点（存索引值+页号）
              └──┬─────┬──┬───┘
           ┌─────┘     │  └─────┐
           ↓           ↓        ↓
    ┌───────────┐ ┌───────────┐ ┌───────────┐
    │Alice,id=3 │ │Jack, id=1 │ │Tom,  id=5 │  ← 叶子节点（存索引值+主键值）
    │Bob,  id=9 │ │Jerry,id=7 │ │Wang, id=12│
    │Emma, id=4 │ │Kate, id=15│ │Zoe,  id=10│
    └─────┬─────┘ └─────┬─────┘ └─────┬─────┘
          └──→ 双向链表 ←──┘→ 双向链表 ←──┘
```

关键点：
- 叶子节点只存**索引列的值和主键值**，不存完整行数据
- B+ 树按索引列的值排序，索引列相同时按主键排序
- 正因为不存完整行数据，所以二级索引比聚簇索引小得多

## 3.3 回表查询

理解了两种索引的存储结构，就能理解什么是"回表"了。

当我们通过二级索引查询时，如果需要返回的字段不全在二级索引中，就必须拿到主键值后，再到聚簇索引中查找完整行数据。
这个过程就叫做**回表（Back to Table）**。

以一个具体例子来说明：

```sql
-- 表结构
CREATE TABLE user (
    id INT PRIMARY KEY,
    name VARCHAR(20),
    age INT,
    phone VARCHAR(20),
    INDEX idx_name(name)
);

-- 查询语句
SELECT id, name, age, phone FROM user WHERE name = 'Alice';
```

这条 SQL 的执行过程：

```
步骤1: 在二级索引 idx_name 上查找 name='Alice'
        ↓
        找到 name='Alice', id=3
        ↓
步骤2: 拿 id=3 到聚簇索引上查找（回表）
        ↓
        找到 id=3 的完整行: (id=3, name='Alice', age=25, phone='138xxxx')
        ↓
步骤3: 返回结果
```

回表的代价在于：每找到一条符合条件的二级索引记录，就要做一次聚簇索引的 B+ 树查找。如果符合条件的记录很多，
回表次数就很多，每次回表都是一次随机 IO（因为主键值不连续，对应的数据页分散在磁盘的不同位置），这就是回表
影响查询性能的根本原因。

这也是为什么优化器在判断回表代价过大时（比如需要回表的行数占全表比例很高），宁愿选择全表扫描而不走二级索引——
因为全表扫描是顺序 IO，反而比大量随机 IO 的回表更快。

## 3.4 为什么 InnoDB 必须有主键？

InnoDB 的表数据是存放在聚簇索引中的，而聚簇索引是按主键组织的，所以 InnoDB 必须有主键。
如果建表时没有显式定义主键，InnoDB 会按以下策略自动选择或生成：

1. 如果表中有 **NOT NULL 的唯一索引**，InnoDB 会选择第一个这样的唯一索引作为聚簇索引；
2. 如果连 NOT NULL 的唯一索引都没有，InnoDB 会自动生成一个隐藏的 6 字节的 `DB_ROW_ID` 列作为聚簇索引。

但是，自动生成的 `DB_ROW_ID` 有一个问题：它对用户不可见，无法在查询中使用，而且所有没有主键的表会共享一个
全局的 row_id 计数器，高并发写入时可能成为瓶颈。所以，**永远应该显式定义主键**。

## 3.5 聚簇索引与二级索引的对比

| 维度 | 聚簇索引（主键索引） | 二级索引（非主键索引） |
|------|---------------------|----------------------|
| 叶子节点内容 | 完整行数据 | 索引列值 + 主键值 |
| 每张表有几棵 | 有且仅有 1 棵 | 可以有多棵 |
| 数据排序依据 | 按主键排序 | 按索引列排序 |
| 查询完整行是否需要回表 | 不需要 | 通常需要（除非覆盖索引） |
| 占用空间 | 大（包含所有数据） | 小（只有索引列+主键） |

从这个对比可以看出：
- 主键越小，二级索引就越小（因为每个二级索引叶子节点都存了主键值）——这就是为什么推荐用自增整数做主键
- 二级索引越多，写入时需要维护的 B+ 树就越多——这就是为什么建议单表索引数量不要过多
- 如果查询的字段都在二级索引中，就不需要回表——这就是"覆盖索引"的原理


# 4 为什么说单表数据量建议在千万以下，最多不要超过两千万？

我们知道，MySQL单个数据页的大小为16kb，B+ 树只有叶子节点才存实际的数据，非叶子节点是用来存放索引数据和指针的。
所以，同样一个16K 的页，非叶子节点里的每条数据都指向新的页，而新的页有两种可能
- 如果是叶子节点，那么里面就是实际的一行行的数据。
- 如果是非叶子节点的话，那么就会继续指向新的页。





![index-store.png](images%2Findex-store.png)





假设
- 非叶子节点内指向其他页的数量为 x
- 叶子节点内能容纳的数据行数为 y
- B+ 数的层数为 z
  那么总的数据量Total = x^(z-1) *y 也就是说总数会等于 x 的z-1 次方与Y 的乘积。


## 3.1 X=?
索引数据页有File Header(38 byte)、Page Header (56 Byte)、Infimum + Supermum（26 byte）、
File Trailer（8byte）,再加上页目录，大概1k 左右，我们就当做它就是1K,那整个页的大小是16K,剩下 15k用于存数据，
在索引页中主要记录的是主键与页号，主键我们假设是Bigint(8 byte),而页号也是固定的（4Byte）,那么索引页中的一条
数据也就是12byte; 所以x=15*1024/12≈1280 行。

## 3.2 Y=?
叶子节点和非叶子节点的结构是一样的，同理，能放数据的空间也是15k；但是叶子节点中存放的是真正的行数据，这个影响的因素
就会多很多，比如，字段的类型，字段的数量；每行数据占用空间越大，页中所放的行数量就会越少；这边我们暂时按一条行数据1k
来算，那一页就能存下15条，Y≈15。
根据上述的公式，Total =x^(z-1) y，已知 x=1280,y=15
假设B+ 树是两层，那就是Z =2， Total = （1280 ^1 ）15 = 19200
假设B+ 树是三层，那就是Z =3， Total = （1280 ^2） *15 = 24576000 （约2.45kw）
这就是为什么建议单表数据量最大行数为2000w的原因！一般B+ 数的层级最多也就是3层，试想一下，如果是4层，除了查询的时候
磁盘IO次数会增加，而且这个Total 值会是多少，大概应该是3百多亿吧，也不太合理，所以，3层应该是比较合理的一个值。


## 3.3 到这里难道就完了？
不，我们刚刚在说Y 的值时候假设的是1K ，那比如我实际当行的数据占用空间不是1K ,而是5K,那么单个数据页最多只能放下3条数据
同样，还是按照Z=3 的值来计算，那Total = （1280 ^2） *3 = 4915200 （近500w）
所以，在保持相同的层级（相似查询性能）的情况下，在行数据大小不同的情况下，其实这个最大建议值也是不同的，而且影响查询性能
的还有很多其他因素，比如，MySQL 为了提高性能，会将表的索引装载到内存中。在InnoDB buffer size 足够的情况下，其能完成
全加载进内存，查询不会有问题。但是，当单表数据到达某个量级的上限时，导致内存无法存储其索引，使得之后的 SQL 查询会产生磁盘
IO，从而导致性能下降，所以增加硬件配置（比如把内存当磁盘使），可能会带来立竿见影的性能提升哈。


## 3.4 总结
- MySQL 的表数据是以页的形式存放的，页在磁盘中不一定是连续的。
- 页的空间是16K,并不是所有的空间都是用来存放数据的，会有一些固定的信息，如，页头，页尾，页码，校验码等等。
- 在B+ 树中，叶子节点和非叶子节点的数据结构是一样的，区别在于，叶子节点存放的是实际的行数据，而非叶子节点存放的是主键和页号。
- 索引结构不会影响单表最大行数，2kw也只是推荐值，超过了这个值可能会导致B+树层级更高，影响查询性能。


# 4 为什么要使用自增主键索引？
从性能角度看，使用有业务逻辑的字段做主键，往往不容易保证有序插入，这样写数据成本相对较高。
而自增主键的插入数据模式，正符合递增插入的场景，每次插入一条新记录，都是追加操作，都不涉及挪动其他的记录，也不会触发叶子节点的分裂，
可大幅降低维护索引树有序性的成本。

而从存储角度看，由于每个非主键索引的叶子节点上都是主键的值。显然，主键长度越小，普通索引的叶子节点也就越小，普通索引所占用的空间也就越小。

因此，从性能和存储空间方面考量，自增主键往往是更合理的选择。

## 4.1 那有什么场景适合用业务字段直接做主键？
只有一个索引；
该索引必须是唯一索引。
这就是典型的KV场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。

## 4.2 联合索引、最左前缀原则与索引设计

### 4.2.1 联合索引在 B+ 树中的排列方式

要理解最左前缀原则，首先必须理解联合索引在 B+ 树中是怎么排列的。

假设我们建了一个联合索引 `(a, b, c)`：

```sql
CREATE INDEX idx_a_b_c ON t(a, b, c);
```

这棵 B+ 树的叶子节点中，记录的排列顺序是：**先按 a 排序，a 相同再按 b 排序，b 相同再按 c 排序**。

```
联合索引 idx_a_b_c 的叶子节点排列（按 a → b → c 依次排序）：

(a=1, b=1, c=1, id=10)
(a=1, b=1, c=3, id=22)
(a=1, b=2, c=1, id=5)
(a=1, b=3, c=2, id=18)
(a=2, b=1, c=1, id=7)
(a=2, b=1, c=5, id=30)
(a=2, b=3, c=2, id=12)
(a=3, b=1, c=1, id=15)
...
```

观察这个排列，可以得出关键结论：
- **a 列是全局有序的**（1,1,1,1,2,2,2,3...）
- **b 列是在 a 相同时局部有序的**，但全局来看是无序的
- **c 列是在 a 和 b 都相同时局部有序的**，全局也是无序的

### 4.2.2 最左前缀原则的本质

理解了上面的排列方式，最左前缀原则就不需要死记硬背了，完全可以推理出来：

**能命中索引的情况：**

| 查询条件 | 能否命中索引 | 原因 |
|---------|------------|------|
| `WHERE a=1` | 能，全部命中 | a 是全局有序的，可以二分查找 |
| `WHERE a=1 AND b=2` | 能，全部命中 | a 有序定位后，b 在 a=1 的范围内也是有序的 |
| `WHERE a=1 AND b=2 AND c=3` | 能，全部命中 | a→b→c 依次有序 |
| `WHERE a=1 AND c=3` | 部分命中（只用到 a） | a 有序可定位，但跳过了 b，c 在 a=1 的范围内不是有序的 |
| `WHERE a=1 AND b>2` | 能，命中 a 和 b | a 等值定位后，b 有序可做范围扫描 |
| `WHERE a>1 AND b=2` | 部分命中（只用到 a） | a 做范围扫描后，b 在不同 a 值间无序 |

**不能命中索引的情况：**

| 查询条件 | 能否命中索引 | 原因 |
|---------|------------|------|
| `WHERE b=2` | 不能 | b 在全局是无序的，没法二分查找 |
| `WHERE b=2 AND c=3` | 不能 | 同上，缺少最左列 a |
| `WHERE c=3` | 不能 | c 在全局是无序的 |

**一个容易混淆的点**：`WHERE a=1 AND c=3` 不是完全不走索引，而是只用到了 a 这一列的索引来缩小扫描范围，
然后 c=3 在扫描过程中作为过滤条件（如果支持索引下推则在引擎层过滤，否则在 Server 层过滤）。

另外，MySQL 优化器会自动调整 WHERE 中条件的顺序，所以 `WHERE b=2 AND a=1` 和 `WHERE a=1 AND b=2`
效果完全相同，不必纠结书写顺序。

### 4.2.3 范围查询对联合索引的影响

对联合索引 `(a, b, c)`，如果 a 列使用了范围查询（>、<、BETWEEN、LIKE 'xx%'），那么 b 和 c 列就无法
利用索引的有序性了。原因还是回到排列方式：a 做范围扫描后，扫描范围内的 b 值是无序的。

```sql
-- a 等值 + b 范围 + c 等值
WHERE a=1 AND b>2 AND c=3    -- 命中 a 和 b，c 只能做过滤

-- a 范围 + b 等值
WHERE a>1 AND b=2             -- 只命中 a，b 只能做过滤

-- a LIKE 前缀 + b 等值
WHERE a LIKE 'abc%' AND b=2   -- 只命中 a 的前缀匹配，b 只能做过滤
```

所以联合索引设计的一个核心原则是：**等值查询的字段放前面，范围查询的字段放后面**。

### 4.2.4 联合索引的设计方法论

在实际项目中，给一张表设计联合索引时，可以按以下步骤：

**第一步：收集高频查询**

先梳理业务中最常用的查询 SQL，找出 WHERE 条件中出现频率最高的字段组合。

**第二步：按区分度排列**

在等值查询的字段中，区分度高的字段放在前面。区分度 = COUNT(DISTINCT column) / COUNT(*)，
越接近 1 区分度越高。

```sql
-- 计算各字段的区分度
SELECT
    COUNT(DISTINCT status) / COUNT(*) AS status_selectivity,
    COUNT(DISTINCT user_id) / COUNT(*) AS user_id_selectivity,
    COUNT(DISTINCT created_date) / COUNT(*) AS date_selectivity
FROM orders;
```

如果 user_id 的区分度是 0.95，status 是 0.05，那么 `(user_id, status)` 优于 `(status, user_id)`。

**第三步：等值在前，范围在后**

```sql
-- 假设高频查询是
SELECT * FROM orders WHERE user_id=100 AND status=1 AND created_at > '2024-01-01';

-- 应该建索引 (user_id, status, created_at)
-- 而不是 (created_at, user_id, status)
```

**第四步：考虑索引复用，减少索引数量**

如果已经有了 `(a, b, c)`，就不需要再单独建 `(a)` 或 `(a, b)` 的索引了。但 `(b)` 或 `(b, c)`
还是需要单独建的（如果有相应的查询需求）。

调整字段顺序，尽量让一个联合索引服务多个查询场景，减少索引的总数量。


## 4.3 覆盖索引

### 4.3.1 什么是覆盖索引

覆盖索引并不是一种特殊的索引类型，而是一种**索引使用方式**：当一个查询所需的所有字段都包含在某个索引中时，
就不需要回表到聚簇索引去获取完整行数据了，这时就说这个索引"覆盖"了这个查询。

在 EXPLAIN 的 Extra 列中，如果出现 **Using index**，就说明使用了覆盖索引。

### 4.3.2 覆盖索引实战

假设有一张 student 表：

```sql
CREATE TABLE student (
    id INT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(20),
    age INT,
    gender TINYINT,
    address VARCHAR(100),
    INDEX idx_name_age(name, age)
);
```

我们来看几条 SQL 的区别：

```sql
-- 查询1：覆盖索引，不需要回表
-- idx_name_age 的叶子节点包含 name、age、id（主键），刚好满足 SELECT 的需求
EXPLAIN SELECT id, name, age FROM student WHERE name = '张三' AND age > 20;
-- Extra: Using index  ✓

-- 查询2：需要回表
-- 需要 gender 字段，但 idx_name_age 中没有 gender
EXPLAIN SELECT id, name, age, gender FROM student WHERE name = '张三' AND age > 20;
-- Extra: 无 Using index  ✗（需要回表拿 gender）

-- 查询3：需要回表
-- SELECT * 返回所有字段，idx_name_age 显然无法覆盖
EXPLAIN SELECT * FROM student WHERE name = '张三' AND age > 20;
-- Extra: 无 Using index  ✗（需要回表拿 gender, address 等）
```

### 4.3.3 利用覆盖索引优化的常见场景

**场景1：COUNT 优化**

```sql
-- 如果在 status 上有索引，优化器会优先选择较小的二级索引进行扫描
-- 因为二级索引比聚簇索引小得多（不包含完整行数据），扫描更快
SELECT COUNT(*) FROM orders WHERE status = 1;
```

**场景2：只查 ID**

```sql
-- 任何二级索引的叶子节点都包含主键 id
-- 所以通过二级索引查 id 总是覆盖索引，不需要回表
SELECT id FROM orders WHERE user_id = 100;
```

**场景3：针对高频查询专门设计覆盖索引**

```sql
-- 假设有一个高频查询
SELECT user_id, order_no, amount FROM orders WHERE user_id = 100 AND status = 1;

-- 可以设计联合索引来覆盖这个查询
CREATE INDEX idx_uid_status_no_amount ON orders(user_id, status, order_no, amount);

-- 这样 user_id、status 用于定位，order_no、amount 用于覆盖返回值
-- 虽然索引变宽了，但消除了回表，在高频场景下收益很大
```

### 4.3.4 覆盖索引的局限性

1. 索引列不能太多，否则索引会变得很宽，写入和存储成本增加；
2. 前缀索引无法用于覆盖索引（因为系统不确定前缀是否截断了完整信息）；
3. 覆盖索引只能覆盖特定的查询模式，不同的查询可能需要不同的覆盖索引；
4. 如果查询使用了 `SELECT *`，除非索引包含了所有字段（不现实），否则一定需要回表。

这也是为什么 **`SELECT *` 是 SQL 优化的第一个要改的坏习惯**——它会让覆盖索引完全失去作用。


## 4.4 什么是索引下推？
假设现在有一张市民表，建立了一个(name, age)的联合索引，如果现在有一个需求: 检索出表中名字第一个字是张，而且年龄是10岁的
所有男孩，那么SQL语句是这样写的：

```sql
select * from tuser where name like '张 %' and age=10 and ismale=1;
```

你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。
然后呢？
当然是判断其他条件是否满足。
在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。
而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉
不满足条件的记录，减少回表次数。

下面这两幅图，是这两个过程的执行流程图。





![without-index-pushdown.png](images%2Fwithout-index-pushdown.png)





![with-index-pushdown.png](images%2Fwith-index-pushdown.png)





在这两个图里面，每一个虚线箭头表示回表一次。
第一张图中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把name 
第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。
第二张图跟第一张图的区别是，InnoDB 在 (name,age) 联合索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，
直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。


## 4.5 页分裂与页合并

在前面第1节中提到"B+树需要拆分合并索引数据页"，这里详细展开。理解页分裂和页合并，有助于理解为什么自增主键写入
更快、为什么需要重建索引。

### 4.5.1 页分裂

当向一个已经满了的数据页中插入新记录时，InnoDB 需要申请一个新的数据页，并把部分数据挪到新页中，这就是页分裂。

以主键索引为例，假设一个数据页已满（存了 id=1,2,3,4,5,6,7），此时要插入 id=4.5 的记录（非自增场景）：

```
分裂前：
┌──────────────────────────┐
│ Page A: 1,2,3,4,5,6,7   │  ← 已满
└──────────────────────────┘

分裂后：
┌─────────────────┐   ┌─────────────────┐
│ Page A: 1,2,3,4 │ → │ Page B: 4.5,5,6,7│  ← 新申请的页
└─────────────────┘   └─────────────────┘
```

页分裂的代价：
1. **性能开销**：需要申请新页、拷贝数据、更新父节点的指针，涉及多次 IO
2. **空间浪费**：分裂后两个页的利用率都只有约 50%，产生了大量空间碎片
3. **影响有序性**：新分裂出的页在磁盘上不一定是连续的，会增加后续范围查询的随机 IO

这就解释了为什么推荐使用**自增主键**：自增主键的插入总是追加在最后一个数据页的末尾，只有当前页满了才会
申请新页，不会触发中间页的分裂。而随机主键（如 UUID）的插入位置是随机的，频繁触发页分裂，写入性能差很多。

### 4.5.2 页合并

当相邻的两个数据页由于大量删除操作，利用率都很低时（默认阈值是页大小的 50% 以下，由
`MERGE_THRESHOLD` 控制），InnoDB 会尝试将两个页合并为一个页，释放多余的页。

```
合并前：
┌──────────────┐   ┌──────────────┐
│ Page A: 1,3  │ → │ Page B: 5,7  │    ← 两个页利用率都很低
└──────────────┘   └──────────────┘

合并后：
┌──────────────────────────┐
│ Page A: 1,3,5,7          │    ← 合并为一个页，Page B 释放
└──────────────────────────┘
```

### 4.5.3 为什么需要重建索引

频繁的插入、删除操作会导致：
- 大量页分裂产生的半满页（空间碎片）
- 删除记录后留下的"空洞"（被 delete mark 但未物理删除的记录占位）
- 数据页在磁盘上不连续（影响范围查询的顺序 IO 性能）

重建索引（`ALTER TABLE t ENGINE=InnoDB` 或 `OPTIMIZE TABLE t`）的过程会创建一个全新的 B+ 树，
把数据按顺序紧凑地插入，消除碎片，让每个页的利用率接近 100%。重建后索引更小、查询更快。

注意：对主键索引的重建需要用 `ALTER TABLE t ENGINE=InnoDB`，不能用 `ALTER TABLE t DROP PRIMARY KEY`
再重建，因为 InnoDB 的聚簇索引不能被删除（表数据就存在里面）。


# 5 索引选择和实践

# 5 索引选择和实践
## 5.1 普通索引和唯一索引应该如何选择？
普通索引和唯一索引在查询性能上没有明显的差异，但在更新性能上，普通索引不需要判断冲突，可直接在change buffer中修改，
相较于唯一索引需要将数据页读入内存的随机IO明显更优。

MySQL更新数据的过程是这样的：
当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，
InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据
页的时候，再将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。
需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，
也会被写入到磁盘上。
将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台
线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。
显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要
占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。

那么，什么条件下可以使用 change buffer 呢？
对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。这就意味着，每次对唯一索引的修改，都需要直接查询磁盘
中已有的数据来确认是否存在冲突。 如果使用 Change Buffer 暂存这些变更，则在数据最终写回磁盘之前，无法保证唯一性约束。
比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入
到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。
因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。
change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size
来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。
理解了 change buffer 的机制后，那么我们再一起来看看如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。
第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：
- 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；
- 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。

这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。
但，这不是我们关注的重点。
第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：
- 对于唯一索引来说，需要将数据页从磁盘读入内存，判断到没有冲突，插入这个值，语句执行结束；
- 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。
将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的
提升是会很明显的。
之前我就碰到过一件事儿，有个 DBA 的同学跟我反馈说，他负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统
处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引
改成了唯一索引。

## 5.2 change buffer 的使用场景
通过上面的分析，我们清楚了使用 change buffer 对更新过程的加速作用，也清楚了 change buffer 只限于用在普通索引的场景下，而
不适用于唯一索引。那么，现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？
因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 
之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。
因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是
账单类、日志类的系统。
反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个
数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，
change buffer 反而起到了副作用。


## 5.3 普通索引和唯一索引选择总结
对于普通索引和唯一索引应该怎么选择的问题。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。
如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。
在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新性能提升还是很明显的。
特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，
那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。

如果某次写入使用了 change buffer 机制，之后主机异常重启，是否会丢失 change buffer 和数据？
这个问题的答案是不会丢失。虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，
change buffer 也能找回来。
在merge 的过程是否会把数据直接写回磁盘？
merge 的执行流程是这样的：
1. 从磁盘读入数据页到内存（老版本的数据页）；
2. 从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；
3. 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。
到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，
之后各自刷回自己的物理数据，就是另外一个过程了。


## 5.4 MySQL优化器选错索引怎么办？
MySQL 选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。
既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息。
所以在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。
如果还是选错索引，可以采用 force index 强行选择一个索引。MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，
然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再
评估其他索引的执行代价。  
第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。

## 5.5 如何给字符串字段创建索引？
有四种思路:
1. 直接创建完整索引，这样可能比较占用存储空间，而且相同的数据页能存的索引值就越少，B+树的叉数就越少，整个B+树越高，搜索效率越低；
2. 创建前缀索引，节省空间，但由于系统并不确定前缀索引的定义是否截断了完整信息，所以会增加查询扫描次数，并且不能使用覆盖索引。
但定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本，至于长度具体定多少合适，则取决于索引前缀的区分度，区分度
越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。

首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：

```sql
select count(distinct email) as L from SUser;
```

然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：

```sql
select 
  count(distinct left(email,4)）as L4,
  count(distinct left(email,5)）as L5,
  count(distinct left(email,6)）as L6,
  count(distinct left(email,7)）as L7,
from SUser;
```

当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于
L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。

3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
4. 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。


# 6 索引进阶

## 6.1 索引合并（Index Merge）

通常情况下，MySQL 一条查询只会使用一个索引。但在某些场景下，优化器会同时使用多个索引分别查找，
然后将结果合并，这就是索引合并（Index Merge）。

在 EXPLAIN 的 type 列显示 `index_merge`，Extra 列会显示具体的合并策略。

### 6.1.1 三种合并策略

**intersection（交集）**：对多个索引的查询结果取交集，常见于 AND 条件。

```sql
-- 假设 idx_a 和 idx_b 分别是 a 和 b 列的独立索引
SELECT * FROM t WHERE a = 1 AND b = 2;
-- 优化器可能分别走 idx_a 和 idx_b，然后对两个结果集取交集
-- Extra: Using intersect(idx_a, idx_b); Using where
```

**union（并集）**：对多个索引的查询结果取并集，常见于 OR 条件。

```sql
SELECT * FROM t WHERE a = 1 OR b = 2;
-- 优化器分别走 idx_a 和 idx_b，然后对两个结果集取并集
-- Extra: Using union(idx_a, idx_b); Using where
```

**sort-union（排序并集）**：先对各索引查询结果按主键排序，再合并，常见于 OR + 范围条件。

```sql
SELECT * FROM t WHERE a > 10 OR b > 20;
-- Extra: Using sort_union(idx_a, idx_b); Using where
```

### 6.1.2 索引合并的利弊

索引合并虽然能让 OR 条件也利用索引，但它并不总是最优选择：
- 需要在多棵索引树上分别查找，再做合并运算，CPU 开销不小
- 如果两个索引返回的结果集很大，合并本身就很耗时

如果发现查询频繁触发 index_merge，通常意味着应该建一个联合索引来替代多个单列索引，让查询只走一棵索引树。

```sql
-- 与其依赖 index merge
SELECT * FROM t WHERE a = 1 AND b = 2;  -- intersect(idx_a, idx_b)

-- 不如直接建联合索引
CREATE INDEX idx_a_b ON t(a, b);
SELECT * FROM t WHERE a = 1 AND b = 2;  -- 直接走 idx_a_b，更高效
```


## 6.2 自适应哈希索引（Adaptive Hash Index, AHI）

InnoDB 有一个内部优化机制：当它监测到某些索引值被频繁访问时，会在内存中自动为这些热点数据建立一个哈希索引，
这就是自适应哈希索引（AHI）。

### 6.2.1 工作原理

- AHI 是 InnoDB **自动维护**的，不需要也不能由用户手动创建
- 它是在 buffer pool 中构建的内存结构，不会持久化到磁盘
- AHI 建立在 B+ 树索引之上，是对 B+ 树热点查询路径的加速
- 使用哈希索引后，等值查询可以从 O(log n) 的 B+ 树查找加速到 O(1) 的哈希查找

### 6.2.2 适用场景与限制

AHI 只对**等值查询**有效（如 `WHERE id = 100`），对范围查询无效。
它在以下场景效果最好：
- 数据存在明显的热点访问模式（少量数据被高频查询）
- 等值查询占比很高

但 AHI 也有负面影响：
- 维护 AHI 本身需要消耗 CPU 和内存
- 在高并发写入场景下，AHI 的维护开销可能反而拖慢性能
- AHI 的哈希表有锁竞争问题（MySQL 8.0 已优化为分区锁）

### 6.2.3 监控与调优

```sql
-- 查看 AHI 的状态
SHOW ENGINE INNODB STATUS\G
-- 在输出中找 INSERT BUFFER AND ADAPTIVE HASH INDEX 段
-- 关注 hash searches/s 和 non-hash searches/s 的比例

-- 如果 AHI 命中率低或导致锁竞争，可以关闭
SET GLOBAL innodb_adaptive_hash_index = OFF;
```

一般来说，保持 AHI 的默认开启即可。只有在通过监控明确发现 AHI 成为瓶颈时（如 `SHOW ENGINE INNODB STATUS`
中看到大量的 AHI 锁等待），才考虑关闭它。


## 6.3 索引的统计信息与 Cardinality

MySQL 优化器选择使用哪个索引，核心依据是**代价估算（Cost-Based Optimization）**，而代价估算的关键输入
就是索引的统计信息，其中最重要的是 **Cardinality（基数）**。

### 6.3.1 什么是 Cardinality

Cardinality 表示索引中不同值的数量估计。例如一个 gender 列只有 'M' 和 'F' 两个值，那它的 Cardinality 约等于 2；
而一个 user_id 列如果有 100 万个不同值，Cardinality 就约等于 100 万。

```sql
-- 查看索引的 Cardinality
SHOW INDEX FROM orders;
```

Cardinality 越高，说明索引的区分度越好，优化器越倾向于使用这个索引。

### 6.3.2 Cardinality 是怎么统计的

InnoDB 的 Cardinality 不是精确计算的，而是**采样估算**的。具体过程是：
1. 随机选取若干个数据页（由 `innodb_stats_persistent_sample_pages` 控制，默认 20 页）
2. 统计这些页中索引列的不同值数量
3. 按比例推算出整个索引的 Cardinality

因为是采样，所以 Cardinality 是一个近似值，可能与真实值有偏差。在以下情况偏差可能较大：
- 数据分布极不均匀（如某个值占了 90% 的行）
- 采样页数太少
- 表刚做了大量 DML 操作但还没更新统计信息

### 6.3.3 当统计信息不准确时

如果 EXPLAIN 的 rows 估算与实际差距很大，或者优化器选了一个明显不合理的索引，很可能是统计信息过时了。

```sql
-- 手动触发统计信息更新
ANALYZE TABLE orders;
```

`ANALYZE TABLE` 会重新采样并更新统计信息，通常可以解决优化器选错索引的问题。
在生产环境中，建议：
- 对于频繁 DML 的表，定期执行 `ANALYZE TABLE`
- 调大 `innodb_stats_persistent_sample_pages`（如设为 40 或更高）以提高采样精度
- 关注 EXPLAIN 中 rows 的估算值，如果与实际差距过大就需要更新统计信息