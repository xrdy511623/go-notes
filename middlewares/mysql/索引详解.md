
---
索引详解
---

# 1 MySQL索引使用的是什么数据结构，为什么不使用B树、哈希索引或跳表？
MySQL索引使用的是B+树的数据结构，只在叶子节点存储行数据，非叶子节点存储的是索引值，同样的存储空间，B+树能够
存储更多的数据，使得整棵树更加扁平，树的高度(深度)更低，IO查询效率比B树更高，因为B树所有节点都会存储行数据。
另外，B+树的叶子节点是按照索引值顺序排列的，且有前后指针相连组成有序链表，这样非常便于范围查询，这是B树所不能比的。
哈希索引对于等值查询效率是最优的，因为时间复杂度仅为O(1)，但是它无法适应范围查询。
相对于跳表，B+树是一种多路平衡树，其每个节点可以包含多个子节点，16k的数据页三层就可以存储约2000万数据，查询最多只需要
3次磁盘IO，而跳表是联表结构，一条数据一个节点，如果最底层要存储2000万数据，且每次查询都要能达到二分查找的效果，
2000万大概是2的24次方左右，也就是跳表高度大概为24层，最坏情况下，这24层数据会分散在不同的数据页里，也就是查询一次’
数据需要24次磁盘IO。因此存放同样量级的数据，B+树的高度比跳表低很多，IO查询效率明显更优。
而针对写操作，B+树需要拆分合并索引数据页，跳表则独立插入，并根据随机函数确定层数，没有旋转和维持平衡的开销，因此跳表
的写入性能会比B+树要好。
Redis的zset(有序集合)使用跳表而不是B+树，一是Redis读写数据都是操作内存，因此也不存在磁盘IO了，所以层高就不再是跳表
的劣势了。而跳表插入数据时，是根据随机函数确定层数的，没有类似B+树那样的旋转和维持平衡的开销，因此跳表的写入性能会比
B+树要好，所以Redis得有序集合会使用跳表而不是B+树。

# 2 索引树查找过程

比如说我们需要查找一个id=6 的行数据，因为在非叶子节点中存放的是页号和该页最小的id，所以我们从顶层开始对比，首先看
页号10 中的目录，有[id=1,页号=20],[id=5,页号=30],说明左侧节点最小id为1，右侧节点最小id 是5；6>5,那按照二分
法查找的规则，肯定就往右侧节点继续查找，找到页号30的节点后，发现这个节点还有子节点（非叶子节点），那就继续比对，
同理，6>5&&6<7,所以找到了页号60，找到页号60之后，发现此节点为叶子节点（数据节点），于是将此页数据加载至内存进行
一一对比，结果找到了id=6 的数据行。
从上述的过程中发现，我们为了查找id=6 的数据，总共查询了三个页，如果三个页都在磁盘中（未提前加载至内存），那么最多
需要经历三次的磁盘IO。





![index-search.png](images%2Findex-search.png)





需要注意的是，图中的页号只是个示例，实际情况下并不是连续的，在磁盘中存储也不一定是顺序的。


# 3 为什么说单表数据量建议在千万以下，最多不要超过两千万？

我们知道，MySQL单个数据页的大小为16kb，B+ 树只有叶子节点才存实际的数据，非叶子节点是用来存放索引数据和指针的。
所以，同样一个16K 的页，非叶子节点里的每条数据都指向新的页，而新的页有两种可能
- 如果是叶子节点，那么里面就是实际的一行行的数据。
- 如果是非叶子节点的话，那么就会继续指向新的页。





![index-store.png](images%2Findex-store.png)





假设
- 非叶子节点内指向其他页的数量为 x
- 叶子节点内能容纳的数据行数为 y
- B+ 数的层数为 z
  那么总的数据量Total = x^(z-1) *y 也就是说总数会等于 x 的z-1 次方与Y 的乘积。


## 3.1 X=?
索引数据页有File Header(38 byte)、Page Header (56 Byte)、Infimum + Supermum（26 byte）、
File Trailer（8byte）,再加上页目录，大概1k 左右，我们就当做它就是1K,那整个页的大小是16K,剩下 15k用于存数据，
在索引页中主要记录的是主键与页号，主键我们假设是Bigint(8 byte),而页号也是固定的（4Byte）,那么索引页中的一条
数据也就是12byte; 所以x=15*1024/12≈1280 行。

## 3.2 Y=?
叶子节点和非叶子节点的结构是一样的，同理，能放数据的空间也是15k；但是叶子节点中存放的是真正的行数据，这个影响的因素
就会多很多，比如，字段的类型，字段的数量；每行数据占用空间越大，页中所放的行数量就会越少；这边我们暂时按一条行数据1k
来算，那一页就能存下15条，Y≈15。
根据上述的公式，Total =x^(z-1) y，已知 x=1280,y=15
假设B+ 树是两层，那就是Z =2， Total = （1280 ^1 ）15 = 19200
假设B+ 树是三层，那就是Z =3， Total = （1280 ^2） *15 = 24576000 （约2.45kw）
这就是为什么建议单表数据量最大行数为2000w的原因！一般B+ 数的层级最多也就是3层，试想一下，如果是4层，除了查询的时候
磁盘IO次数会增加，而且这个Total 值会是多少，大概应该是3百多亿吧，也不太合理，所以，3层应该是比较合理的一个值。


## 3.3 到这里难道就完了？
不，我们刚刚在说Y 的值时候假设的是1K ，那比如我实际当行的数据占用空间不是1K ,而是5K,那么单个数据页最多只能放下3条数据
同样，还是按照Z=3 的值来计算，那Total = （1280 ^2） *3 = 4915200 （近500w）
所以，在保持相同的层级（相似查询性能）的情况下，在行数据大小不同的情况下，其实这个最大建议值也是不同的，而且影响查询性能
的还有很多其他因素，比如，MySQL 为了提高性能，会将表的索引装载到内存中。在InnoDB buffer size 足够的情况下，其能完成
全加载进内存，查询不会有问题。但是，当单表数据到达某个量级的上限时，导致内存无法存储其索引，使得之后的 SQL 查询会产生磁盘
IO，从而导致性能下降，所以增加硬件配置（比如把内存当磁盘使），可能会带来立竿见影的性能提升哈。


## 3.4 总结
- MySQL 的表数据是以页的形式存放的，页在磁盘中不一定是连续的。
- 页的空间是16K,并不是所有的空间都是用来存放数据的，会有一些固定的信息，如，页头，页尾，页码，校验码等等。
- 在B+ 树中，叶子节点和非叶子节点的数据结构是一样的，区别在于，叶子节点存放的是实际的行数据，而非叶子节点存放的是主键和页号。
- 索引结构不会影响单表最大行数，2kw也只是推荐值，超过了这个值可能会导致B+树层级更高，影响查询性能。


# 4 为什么要使用自增主键索引？
从性能角度看，使用有业务逻辑的字段做主键，往往不容易保证有序插入，这样写数据成本相对较高。
而自增主键的插入数据模式，正符合递增插入的场景，每次插入一条新记录，都是追加操作，都不涉及挪动其他的记录，也不会触发叶子节点的分裂，
可大幅降低维护索引树有序性的成本。

而从存储角度看，由于每个非主键索引的叶子节点上都是主键的值。显然，主键长度越小，普通索引的叶子节点也就越小，普通索引所占用的空间也就越小。

因此，从性能和存储空间方面考量，自增主键往往是更合理的选择。

## 4.1 那有什么场景适合用业务字段直接做主键？
只有一个索引；
该索引必须是唯一索引。
这就是典型的KV场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。

## 4.2 在建立联合索引时，如何安排索引内的字段顺序？
评估标准是索引的使用频率。第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。通常来说，
查询最频繁的字段应该放在最左边。

## 4.3 什么是索引下推？
假设现在有一张市民表，建立了一个(name, age)的联合索引，如果现在有一个需求: 检索出表中名字第一个字是张，而且年龄是10岁的
所有男孩，那么SQL语句是这样写的：

```sql
select * from tuser where name like '张 %' and age=10 and ismale=1;
```

你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。
然后呢？
当然是判断其他条件是否满足。
在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。
而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉
不满足条件的记录，减少回表次数。

下面这两幅图，是这两个过程的执行流程图。





![without-index-pushdown.png](images%2Fwithout-index-pushdown.png)





![with-index-pushdown.png](images%2Fwith-index-pushdown.png)





在这两个图里面，每一个虚线箭头表示回表一次。
第一张图中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把name 
第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。
第二张图跟第一张图的区别是，InnoDB 在 (name,age) 联合索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，
直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。


## 4.4 为什么需要重建索引？
索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的
利用率最高，也就是索引更紧凑、更省空间。

# 5 索引选择和实践
## 5.1 普通索引和唯一索引应该如何选择？
普通索引和唯一索引在查询性能上没有明显的差异，但在更新性能上，普通索引不需要判断冲突，可直接在change buffer中修改，
相较于唯一索引需要将数据页读入内存的随机IO明显更优。

MySQL更新数据的过程是这样的：
当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，
InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据
页的时候，再将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。
需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，
也会被写入到磁盘上。
将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台
线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。
显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要
占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。
那么，什么条件下可以使用 change buffer 呢？
对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中
是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用
change buffer 了。
因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。
change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size
来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。
理解了 change buffer 的机制后，那么我们再一起来看看如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。
第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：
- 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；
- 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。

这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。
但，这不是我们关注的重点。
第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：
- 对于唯一索引来说，需要将数据页从磁盘读入内存，判断到没有冲突，插入这个值，语句执行结束；
- 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。
将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的
提升是会很明显的。
之前我就碰到过一件事儿，有个 DBA 的同学跟我反馈说，他负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统
处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引
改成了唯一索引。

## 5.2 change buffer 的使用场景
通过上面的分析，我们清楚了使用 change buffer 对更新过程的加速作用，也清楚了 change buffer 只限于用在普通索引的场景下，而
不适用于唯一索引。那么，现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？
因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 
之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。
因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是
账单类、日志类的系统。
反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个
数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，
change buffer 反而起到了副作用。


## 5.3 普通索引和唯一索引选择总结
对于普通索引和唯一索引应该怎么选择的问题。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。
如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。
在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。
特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，
那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。

如果某次写入使用了 change buffer 机制，之后主机异常重启，是否会丢失 change buffer 和数据？
这个问题的答案是不会丢失。虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，
change buffer 也能找回来。
在merge 的过程是否会把数据直接写回磁盘？
merge 的执行流程是这样的：
1. 从磁盘读入数据页到内存（老版本的数据页）；
2. 从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；
3. 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。
到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，
之后各自刷回自己的物理数据，就是另外一个过程了。


## 5.4 MySQL优化器选错索引怎么办？
MySQL 选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。
既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息。
所以在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。
如果还是选错索引，可以采用 force index 强行选择一个索引。MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，
然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再
评估其他索引的执行代价。  
第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。

## 5.5 如何给字符串字段创建索引？
有四种思路:
1. 直接创建完整索引，这样可能比较占用存储空间，而且相同的数据页能存的索引值就越少，B+树的叉数就越少，整个B+树越高，搜索效率越低；
2. 创建前缀索引，节省空间，但由于系统并不确定前缀索引的定义是否截断了完整信息，所以会增加查询扫描次数，并且不能使用覆盖索引。
但定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本，至于长度具体定多少合适，则取决于索引前缀的区分度，区分度
越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。

首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：

```sql
select count(distinct email) as L from SUser;
```

然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：

```sql
select 
  count(distinct left(email,4)）as L4,
  count(distinct left(email,5)）as L5,
  count(distinct left(email,6)）as L6,
  count(distinct left(email,7)）as L7,
from SUser;
```

当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于
L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。

3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
4. 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。