
---
垃圾回收和逃逸分析详解
---

# 1 Go的垃圾回收

## 1.1 常用的垃圾回收算法
引用计数:对每个对象维护一个引用计数，当引用该对象的对象被销毁时，引用计数减1，当引用计数为0时回收该对象。
优点: 对象可以很快被回收，不会出现内存耗尽或达到某个阈值时才回收。
缺点: 不能很好地处理循环引用，而且实时维护引用计数也有一定的代价。
代表语言: Python、Php、Swift

标记清除: 从根对象开始遍历所有引用的对象，引用的对象标记为被引用，没有标记的对象被回收。
优点: 解决了引用计数的缺点；
缺点: 需要STW，即暂时停止程序运行；
代表语言: Go

分代收集: 按照对象生命周期的长短划分不同的代空间，生命周期长的放入老年代，而短的放入新生代，不同代
有不同的回收算法和回收频率。
优点: 回收性能好
缺点: 算法复杂
代表语言: Java

## 1.2 垃圾回收的原理
简单来说，垃圾回收的核心就是标记出哪些内存还在使用中(即被引用到),哪些内存不再使用了(即未被引用)，
把未被引用的内存回收，以供后续的内存分配使用。

## 1.3 三色标记算法
三色只是为了叙述方便而抽象出来的一种说法，实际上对象并没有颜色之分，这里的三色对应了垃圾回收过程中对象的三种状态。

灰色: 对象还在标记队列中等待(标记队列用于存放待标记的对象)；
黑色: 对象已被标记，该对象不会在本次GC中被清理；
白色: 对象未被标记，该对象会在本次GC中被清理。

过程:
a 首先，程序创建的对象都标记为白色；
b gc开始：扫描所有可到达的对象，标记为灰色；
c 从灰色对象中找到其引用对象标记为灰色，把灰色对象本身标记为黑色；
d 监视对象中的内存修改，并持续上一步的操作，直到灰色标记的对象不存在；
e 此时，gc 回收白色对象；
f 最后，将所有黑色对象变为白色，并重复以上所有过程。

下面用一个案例加以说明:
假定当前内存中有A~F共6个对象，根对象a,b本身为栈上分配的局部变量，根对象a,b分别引用了对象A，B, 而
B对象又引用了对象D，则GC开始前对象的状态如下:
白色对象: A,B,C,D,E,F
灰色对象: 空
黑色对象: 空

初始状态下所有对象都是白色对象
接着开始扫描根对象a, b
由于根对象引用了对象A,B，所以A,B会变成灰色对象。接下来开始分析灰色对象，对于A,它没有引用其他对象，
所以很快变成黑色对象，而B引用了D，所以B变为黑色对象的同时，D会变为灰色对象。

此时对象的状态如下:
白色对象: C,E,F
灰色对象: D
黑色对象: A,B

现在灰色对象只剩下D对象，由于D没有引用其他对象，所以D也转为黑色对象，此时灰色对象全部消失，标记过程结束。

最终，黑色对象(A,B,D)会被保留下来，白色对象会被回收。

## 1.4 STW(stop the world)
对于垃圾回收来说，在回收过程中也需要监视内存中的对象修改，否则在内存回收过程中指针传递会引起内存引用关系的变化，
如果错误地回收了还在使用的内存，那么结果将是灾难性的。

Go中的STW就是停止所有的goroutine，专心做垃圾回收，待垃圾回收结束后再恢复goroutine。
STW时间的长短会直接影响应用的执行，时间过长对于一些Web应用来说是不可接受的，这是其受到诟病的主要原因。

## 1.5 垃圾回收优化
为了缩短STW的时间，Go也在不断地优化垃圾回收算法。

### 1.5.1 写屏障
我们知道STW的目的是防止GC扫描时内存引用变化而停止所有goroutine，而写屏障就是让goroutine和GC同时运行的手段。
虽然写屏障不能完全消除STW，但是可以大大缩短STW的时间。

写屏障类似一种开关，在GC的特定时机开启，开启后指针传递时会标记指针，即本轮不回收，下次GC时再确定。
GC过程中新分配的内存会被立即标记，用的正是写屏障技术，即GC过程中分配的内存不会在本轮GC中回收。

### 1.5.2 辅助GC(Mutator Assist)
为了防止内存分配过快，在GC执行过程中，如果goroutine需要分配内存，那么该goroutine会参与一部分GC的工作，
即帮助GC做一部分工作，这个机制叫做辅助GC。

## 1.6 垃圾回收的触发时机

### 1.6.1 内存分配量达到阈值触发GC
每次内存分配时都会检查当前内存分配量是否已达阈值，如果达到阈值则立即启动GC。
阈值=上次GC内存分配量 * 内存增长率

内存增长率由环境变量GOGC控制，默认为100，即每当内存扩大一倍时启动GC。

### 1.6.2 定期触发GC
默认情况下，最长2分钟触发一次GC，这个间隔在src/runtime/proc.go:forcegcperiod变量中被声明。

### 1.6.3 手动触发
程序代码中也可以使用runtime.GC()来手动触发GC，主要用于GC的性能测试和统计。

## 1.7 GC性能优化
GC性能与对象数量负相关，对象越多GC性能越差，对程序影响越大。
所以GC性能优化的思路之一就是减少对象分配的次数，比如对象复用或使用大对象组合多个小对象，等等。

另外，由于内存逃逸现象会产生一些隐式的内存分配，也有可能成为GC的负担。

# 2 Go语言的逃逸分析

逃逸分析是指由编译器决定内存的位置，不需要程序员指定。在函数中申请一个新的对象：
如果分配在栈中，则函数执行结束后可自动将内存回收；
如果分配在堆中，则函数执行结束后由GC(垃圾回收)处理。

## 2.1 逃逸策略
在函数中申请新的对象时，编译器会根据该对象是否被函数外部引用来决定是否逃逸；
如果函数外部没有引用，则优先放到栈中；
如果函数外部存在引用，则一定放到堆中。

注意，对于仅在函数内部使用的变量，也有可能放到堆中，比如内存占用超过栈的存储空间的变量。

## 2.2 逃逸场景

a 如果函数或方法的返回值存在被外部引用的情况，那么该返回值会发生逃逸。典型的场景是
函数或方法返回了一个局部变量指针。

![pointer-escape.png](escape-analyse%2F01-pointer-escape%2Fpointer-escape.png)

**注意** 
./main.go:16:17: new(StudentDetail) does not escape 这行并不是说函数对象new(StudentDetail)
又没有逃逸了，这段输出的意思是在内联优化之后，RegisterStudent 函数的逻辑已经完全内联到 main 中，因此在 main 中
直接分配的 new(StudentDetail) 对象没有从 main 的作用域逃逸（从整个程序的角度来看，仍然是逃逸到堆上）。
换句话说，main 函数内联后逃逸行为没有改变，只是内存分配位置的描述从 RegisterStudent 转移到 main。

由此可以看出，虽然函数传递指针可以减少底层值的复制，提高效率，但是如果复制的数据量小，由于指针
传递会产生逃逸，则可能会将对象内存分配到堆上，给GC增加负担，所以传递指针不一定就是高效的。

b 当栈空间不足以存放当前对象(譬如切片长度大于10000时)或无法判断当前切片长度时会将对象分配到堆中。
![stack-deficiency-escape.png](escape-analyse%2F02-stack-deficiency-escape%2Fstack-deficiency-escape.png)

c 当编译器很难确定参数的具体类型时，也会产生逃逸，譬如函数的参数类型为interface类型时。
![interface-variable-escape.png](escape-analyse%2F03-interface-variable-escape%2Finterface-variable-escape.png)

**注意**
[]interface {}{...} does not escape
这一行表明，为了调用 fmt.Println，编译器在内部构造了一个 []interface{} 切片（因为 fmt.Println 可以接受可变数量的参数）。
这个切片是一个临时变量，生命周期局限于函数内部，因此它没有逃逸，仍然分配在栈上。
但是变量 s 确实发生了逃逸，因为它的值需要存储在堆上，以便满足 interface{} 参数的需求。
而内部创建的 []interface{} 切片没有发生逃逸，因为它是临时的，存储在栈上。


d 闭包引用对象逃逸
即使外层函数已经执行完毕，内部函数仍然可以访问并修改其引用的外层函数变量，所以外层函数定义的变量，其生命周期已经超出了
外层函数的作用域，因此外层函数变量会逃逸到堆上。

![closure-escape.png](escape-analyse%2F04-closure-escape%2Fclosure-escape.png)

## 2.3 如何做逃逸分析
通过编译参数-gcflags=-m可以查看编译过程中的逃逸分析过程

```shell
go build -gcflags=-m
```
输出:

```shell
# go-notes/gc/escape-analyse/01-pointer-escape
./main.go:8:6: can inline RegisterStudent
./main.go:15:6: can inline main
./main.go:16:17: inlining call to RegisterStudent
./main.go:8:22: leaking param: name
./main.go:9:10: new(StudentDetail) escapes to heap
./main.go:16:17: new(StudentDetail) does not escape

```

## 2.4 函数或方法应该返回值类型还是指针类型？

```golang
package performance

type Person struct {
	id   int
	age  int
	name string
}

type Item struct {
	id  int
	val [40960]int
}

func newPersonValueSlice(n int) []Person {
	s := make([]Person, n)
	for i := 0; i < n; i++ {
		s[i] = Person{}
	}
	return s
}

func newPersonPointerSlice(n int) []*Person {
	s := make([]*Person, n)
	for i := 0; i < n; i++ {
		s[i] = &Person{}
	}
	return s
}

func newItemValueSlice(n int) []Item {
	s := make([]Item, n)
	for i := 0; i < n; i++ {
		s[i] = Item{
			i,
			[40960]int{},
		}
	}
	return s
}

func newItemPointerSlice(n int) []*Item {
	s := make([]*Item, n)
	for i := 0; i < n; i++ {
		s[i] = &Item{
			i,
			[40960]int{},
		}
	}
	return s
}
```

```golang
func BenchmarkNewPersonValueSlice(b *testing.B) {
	newPersonValueSlice(10000)
}

func BenchmarkNewPersonPointerSlice(b *testing.B) {
	newPersonPointerSlice(10000)
}

func BenchmarkNewItemValueSlice(b *testing.B) {
	newItemValueSlice(10000)
}

func BenchmarkNewItemPointerSlice(b *testing.B) {
	newItemPointerSlice(10000)
}

```

```shell
go test -bench=Slice$ -benchmem .
goos: darwin
goarch: arm64
pkg: go-notes/gc/performance
BenchmarkNewPersonValueSlice-8          1000000000               0.0000275 ns/op               0 B/op          0 allocs/op
BenchmarkNewPersonPointerSlice-8        1000000000               0.0002953 ns/op               0 B/op          0 allocs/op
BenchmarkNewItemValueSlice-8                   1        2007900792 ns/op        3276881920 B/op        1 allocs/op
BenchmarkNewItemPointerSlice-8          1000000000               0.6230 ns/op          3 B/op          0 allocs/op
PASS
ok      go-notes/gc/performance 14.224s
```

根据逃逸策略，使用指针会使逃逸对象将变量分配在堆上，给gc带来压力；而使用值类型则大概率会将变量分配到栈上，而栈上
的对象会随着栈销毁而被回收，不会给gc带来压力，且在栈上进行小对象的拷贝性能很好，因此如果函数或方法返回的对象
是小对象时，返回值类型比指针类型性能要好很多，在上面这个案例中，返回值类型的切片比返回指针类型的切片性能提升
10倍以上。

那么，什么情况下函数或方法应该返回指针呢？
两种情况
一是函数或方法返回的是大对象，根据逃逸策略分析，大对象占用内存较大，在栈中无法存储，必然会逃逸到堆上，如此它和
指针对象一样都会给gc带来压力，其原先在栈上的优势便没了，而且值类型如果是大对象拷贝开销会很大，而指针类型则不存在
这个问题，其拷贝的不过是一个指针，开销要小很多，因此此时返回指针类型，性能明显更优；

```shell
./main.go:9:11: make([]Item, n) escapes to heap
./main.go:20:11: make([]*Item, n) escapes to heap
./main.go:22:10: &Item{...} escapes to heap
./main.go:31:11: make([]int, 10000, 10000) escapes to heap
./main.go:38:11: make([]int, 10000, 10000) escapes to heap
./main.go:39:19: make([]Item, n) escapes to heap
./main.go:40:21: make([]*Item, n) escapes to heap
./main.go:40:21: &Item{...} escapes to heap
```

二是函数或方法中对返回的对象进行了修改，并且修改后的对象需要在函数或方法外被感知到时，必须使用指针。如果返回值类型，
其修改的是对象副本，函数或方法外无法感知到修改。

# 3 Go 内存分配器

理解 GC 之前，有必要先了解 Go 的内存分配器，因为 GC 的性能瓶颈本质上来自堆分配，而分配器决定了堆分配的效率。

## 3.1 三级分配体系

Go 的内存分配器基于 TCMalloc（Thread-Caching Malloc）设计，采用三级结构：

```
goroutine → mcache → mcentral → mheap → OS
```

**mcache（per-P 缓存）**
每个 P（逻辑处理器）拥有一个 mcache，分配时无需加锁。mcache 中缓存了各种 size class 的 mspan。
大部分小对象分配在这一层完成，速度极快。

**mcentral（全局中心缓存）**
当 mcache 中某个 size class 的 span 耗尽时，向 mcentral 申请。mcentral 按 size class 分组管理 span，
操作需要加锁，但锁粒度较小（每个 size class 一把锁）。

**mheap（全局堆）**
当 mcentral 也没有可用 span 时，向 mheap 申请。mheap 管理所有 span 的分配与回收，
必要时向操作系统申请内存（mmap）。大对象（>32KB）直接从 mheap 分配。

## 3.2 对象大小分类

Go 将对象按大小分为三类，采用不同的分配策略：

| 类别 | 大小范围 | 分配方式 |
|------|---------|---------|
| Tiny | <16B 且不含指针 | Tiny Allocator 合并分配 |
| Small | 16B ~ 32KB | mcache → mcentral → mheap |
| Large | >32KB | 直接从 mheap 分配 |

## 3.3 Tiny Allocator

对于小于 16 字节且不含指针的对象（如 bool、小 int），Go 使用 Tiny Allocator 将多个小对象
合并到同一个 16 字节的内存块中，极大减少了内存碎片和分配次数。

```go
// 例如以下三个变量可能被合并到同一个 16B 块中
var a int8  // 1B
var b int16 // 2B
var c int32 // 4B
// 总共 7B，Tiny Allocator 将它们放在同一个 16B 块
```

注意：如果对象包含指针，则不能使用 Tiny Allocator，因为 GC 需要精确知道指针位置。

## 3.4 Size Class

Go 定义了 67 个 size class（可在 `runtime/sizeclasses.go` 查看），将对象大小映射到最近的 class：

```
// 部分 size class 示例
class  bytes/obj  bytes/span  objects
  1        8       8192       1024
  2       16       8192        512
  3       24       8192        341
  4       32       8192        256
  ...
 66    28672      57344          2
 67    32768      32768          1
```

这种分桶策略以少量内部碎片为代价，换取了快速的内存分配。

## 3.5 为什么堆分配比栈分配慢

- **栈分配**：移动栈指针即可（一条 CPU 指令），函数返回时自动回收
- **堆分配**：查找合适的 size class → 从 mcache 获取 span → 可能回退到 mcentral/mheap（加锁）→ 分配的对象需要 GC 追踪和回收

这就是逃逸分析的价值所在：尽量让对象留在栈上，避免堆分配的开销。

# 4 写屏障演进

前面 1.5.1 提到了写屏障的基本概念，这里深入分析其演进过程。

## 4.1 Go 1.5: Dijkstra 插入屏障

Go 1.5 引入了并发 GC，使用 Dijkstra 风格的插入写屏障（insertion write barrier）：

```
// 伪代码：当发生指针写入时
writePointer(slot, ptr):
    shade(ptr)      // 将新引用的对象标记为灰色
    *slot = ptr
```

**核心思想**：当一个指针被写入某个对象的字段时，将被指向的对象标记为灰色，确保不会漏扫。

**局限**：插入屏障仅在堆上生效，栈上的指针写入不触发屏障（因为栈操作非常频繁，加屏障代价太高）。
因此在标记结束前，需要 **STW 重新扫描所有 goroutine 的栈**，确保栈上的新引用没有遗漏。

## 4.2 Go 1.8: 混合写屏障

Go 1.8 引入了混合写屏障（Hybrid Write Barrier），结合了 Dijkstra 插入屏障和 Yuasa 删除屏障：

```
// 伪代码：混合写屏障
writePointer(slot, ptr):
    shade(*slot)    // 将旧的被引用对象标记为灰色（删除屏障部分）
    shade(ptr)      // 将新的被引用对象标记为灰色（插入屏障部分）
    *slot = ptr
```

**关键改进**：
1. GC 开始时，将栈上所有可达对象标记为黑色（无需后续重新扫描）
2. 栈上新创建的对象直接标记为黑色
3. 堆上被删除或被添加的引用都会触发屏障

**效果**：完全消除了标记阶段的栈重新扫描，STW 时间从毫秒级降低到微秒级（通常 <100μs）。

## 4.3 当前 GC 的 STW 阶段

Go 当前的 GC 只在两个极短的阶段需要 STW：
1. **Mark Setup**（标记准备）：开启写屏障，极短
2. **Mark Termination**（标记终止）：关闭写屏障，清理状态，极短

整个并发标记阶段和并发清扫阶段都不需要 STW。

# 5 GC Pacer（并发标记节奏控制）

## 5.1 Pacer 的作用

GC Pacer 负责在 **CPU 开销** 和 **内存开销** 之间找到平衡：
- GC 太频繁 → CPU 浪费在 GC 上，吞吐量下降
- GC 太稀疏 → 内存持续增长，可能 OOM

Pacer 的目标是控制 GC 在堆大小达到目标值时恰好完成标记工作。

## 5.2 GOGC 调优

`GOGC` 控制 GC 触发阈值，表示堆增长百分比：

```
目标堆大小 = 上次 GC 后存活堆大小 × (1 + GOGC/100)
```

| GOGC 值 | 效果 |
|---------|------|
| 100（默认） | 堆翻倍时触发 GC |
| 50 | 堆增长 50% 时触发，GC 更频繁，内存占用更低 |
| 200 | 堆增长 200% 时触发，GC 更少，但内存占用更高 |
| off | 关闭 GC（需配合 GOMEMLIMIT 使用） |

```go
// 运行时动态调整
import "runtime/debug"

old := debug.SetGCPercent(50)  // 设置 GOGC=50，返回旧值
debug.SetGCPercent(-1)          // 关闭 GC
```

## 5.3 GOMEMLIMIT（Go 1.19+）

Go 1.19 引入了软内存上限 `GOMEMLIMIT`，这是 Go GC 调优的重大改进：

```bash
# 环境变量设置
GOMEMLIMIT=1GiB ./myapp
```

```go
// 运行时设置
import "runtime/debug"
debug.SetMemoryLimit(1 << 30)  // 1 GiB
```

**GOMEMLIMIT 的价值**：
- 解决了 GOGC 无法控制内存上限的问题
- 允许 `GOGC=off` + `GOMEMLIMIT` 的组合，让 GC 只在接近内存上限时触发
- 适合容器化部署（容器有明确的内存限制）

**推荐配置模式**：
```bash
# 容器环境：关闭按比例触发，仅在接近限制时 GC
GOGC=off GOMEMLIMIT=800MiB ./myapp  # 容器限制 1GiB，留 200MiB 余量

# 普通环境：保留默认 GOGC，加上安全上限
GOMEMLIMIT=2GiB ./myapp
```

注意：GOMEMLIMIT 是**软限制**，极端情况下 Go 会超出限制以避免 OOM 引发的频繁 GC（GC thrashing）。

# 6 GC 诊断工具链

## 6.1 GODEBUG=gctrace=1

最直接的 GC 观测手段：

```bash
GODEBUG=gctrace=1 ./myapp
```

输出格式：
```
gc 1 @0.012s 2%: 0.012+1.2+0.005 ms clock, 0.096+0.5/1.0/0+0.040 ms cpu, 4->4->2 MB, 4 MB goal, 0 MB stacks, 0 MB globals, 8 P
```

各字段含义：
```
gc 1          第 1 次 GC
@0.012s       程序启动后 0.012s
2%            GC 占用 CPU 时间百分比
0.012+1.2+0.005 ms clock  STW清扫终止 + 并发标记 + STW标记终止（wall clock）
0.096+0.5/1.0/0+0.040 ms cpu  对应的 CPU 时间
4->4->2 MB    GC开始堆大小 -> GC结束堆大小 -> 存活堆大小
4 MB goal     目标堆大小
8 P           使用的 P 数量
```

## 6.2 go tool pprof 内存分析

```bash
# 在代码中导入 net/http/pprof（仅需 import 即可）
import _ "net/http/pprof"

# 采集堆内存 profile
go tool pprof http://localhost:6060/debug/pprof/heap

# 常用 pprof 命令
(pprof) top           # 查看内存分配最多的函数
(pprof) list funcName # 查看某函数的逐行分配
(pprof) web           # 在浏览器中查看调用图
```

**四种内存 profile 类型**：

| 类型 | 含义 | 适用场景 |
|------|------|---------|
| alloc_objects | 历史分配对象总数 | 找出 GC 压力来源 |
| alloc_space | 历史分配总字节数 | 找出内存大户 |
| inuse_objects | 当前在用对象数 | 排查内存泄漏 |
| inuse_space | 当前在用字节数 | 排查内存泄漏 |

```bash
# 指定 profile 类型
go tool pprof -alloc_objects http://localhost:6060/debug/pprof/heap
go tool pprof -inuse_space http://localhost:6060/debug/pprof/heap
```

## 6.3 runtime.ReadMemStats

在代码中直接获取 GC 指标：

```go
var m runtime.MemStats
runtime.ReadMemStats(&m)

fmt.Printf("HeapAlloc = %d MiB\n", m.HeapAlloc/1024/1024)   // 堆上已分配字节
fmt.Printf("HeapObjects = %d\n", m.HeapObjects)               // 堆上对象数量
fmt.Printf("NumGC = %d\n", m.NumGC)                           // GC 总次数
fmt.Printf("PauseTotalNs = %d ms\n", m.PauseTotalNs/1e6)      // GC 暂停总时间
fmt.Printf("LastGCPauseNs = %d μs\n", m.PauseNs[(m.NumGC+255)%256]/1e3) // 最近一次 GC 暂停
```

完整的诊断示例见 `performance/gc_trace_demo_test.go`。

# 7 GC 优化实战技巧

## 7.1 Ballast（压舱石）技巧

通过持有一个大的不被引用的 byte 数组来提高 GC 触发阈值，减少 GC 频率：

```go
func main() {
    // 分配 10GB 的 ballast（虚拟内存，不占物理内存）
    ballast := make([]byte, 10<<30)
    _ = ballast

    // 应用逻辑...
}
```

**原理**：GOGC=100 时，目标堆大小 = 存活堆 × 2。如果存活堆很小（如 10MB），则 20MB 时就触发 GC。
有了 10GB ballast 后，存活堆 ≈ 10GB，目标堆 ≈ 20GB，GC 频率大幅下降。

**注意**：
- Go 1.19 之后，推荐使用 `GOMEMLIMIT` + `GOGC=off` 替代 ballast 技巧
- ballast 使用的是虚拟内存，操作系统不会立即分配物理内存（lazy allocation）
- 完整示例见 `performance/ballast_test.go`

## 7.2 sync.Pool 对象复用

`sync.Pool` 是减少 GC 压力的利器，通过复用对象避免频繁的堆分配：

```go
var bufPool = sync.Pool{
    New: func() interface{} {
        return new(bytes.Buffer)
    },
}

func process(data []byte) {
    buf := bufPool.Get().(*bytes.Buffer)
    defer func() {
        buf.Reset()
        bufPool.Put(buf)
    }()
    buf.Write(data)
    // 使用 buf...
}
```

**适用场景**：
- 频繁创建和销毁的临时对象（如 buffer、编解码器）
- 请求级别的临时资源

**注意**：sync.Pool 中的对象在 GC 时可能被清除（不保证持久性），不要用它做持久缓存。

完整的性能对比见 `performance/sync_pool_test.go`。

## 7.3 runtime.SetFinalizer 的影响

`runtime.SetFinalizer` 会为对象注册一个清理函数，在 GC 回收对象时调用：

```go
f, _ := os.Open("file.txt")
runtime.SetFinalizer(f, func(f *os.File) {
    f.Close()
})
```

**GC 影响**：
- 带 Finalizer 的对象至少需要**两个 GC 周期**才能被回收：
  - 第一个周期：发现对象不可达，将其移入 finalizer 队列
  - 第二个周期：Finalizer 执行后，对象才真正被回收
- 大量 Finalizer 会拖慢 GC 性能

**建议**：优先使用 `defer` 显式释放资源，仅在需要安全网时使用 Finalizer。

## 7.4 预分配与复用模式

减少 GC 压力的通用策略：

```go
// 1. 预分配切片
s := make([]int, 0, expectedSize)  // 避免多次扩容导致的分配

// 2. 复用切片（截断而非重建）
s = s[:0]  // 保留底层数组，长度归零

// 3. 结构体预分配字段
type Request struct {
    buf [1024]byte  // 内嵌数组避免额外堆分配
    // ...
}

// 4. 字符串拼接使用 strings.Builder
var b strings.Builder
b.Grow(estimatedSize)  // 预分配
for _, s := range items {
    b.WriteString(s)
}
result := b.String()
```

# 8 逃逸分析补充场景

## 8.1 sync.Pool 的 interface{} 逃逸

sync.Pool 的 Get/Put 参数类型为 `interface{}`，因此放入 Pool 的对象必然逃逸到堆上：

```go
pool.Put(myObj)  // myObj 逃逸：需要装箱为 interface{}
```

这不是 sync.Pool 的缺陷，而是设计取舍——Pool 无法消除逃逸，但能通过复用减少分配次数。

详见 `escape-analyse/06-sync-pool/main.go`。