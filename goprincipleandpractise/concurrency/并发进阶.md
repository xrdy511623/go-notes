
---
并发进阶
---

本文聚焦Go并发的**编排层**——如何用goroutine + channel + sync原语组合出生产级并发模式，
以及如何用atomic实现无锁操作、用`-race`检测数据竞争。

> 前置知识：
> - goroutine调度原理 → [GMP模型](../gmp/GMP模型.md)
> - channel内部机制 → [channel详解](../channel/channel详解.md)
> - 锁与原子操作性能对比 → [锁详解](../lock/go语言中的锁详解.md)
> - sync包源码分析 → [sync目录](../sync/)
> - context生命周期管理 → [context详解](../context/context详解.md)


# 1 并发模式

## 1.1 Pipeline（流水线）

Pipeline将处理流程拆分为多个阶段，每个阶段是一个goroutine，通过channel串联：

```
数据源 → [阶段1] → channel → [阶段2] → channel → [阶段3] → 结果
```

```go
// 生成器：将一组值发送到channel
func generator(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for _, n := range nums {
            out <- n
        }
    }()
    return out
}

// 阶段：对每个值做平方运算
func square(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            out <- n * n
        }
    }()
    return out
}

// 串联
func main() {
    ch := generator(2, 3, 4)
    result := square(square(ch)) // 两次平方 = 四次方
    for v := range result {
        fmt.Println(v) // 16, 81, 256
    }
}
```

Pipeline的核心规则：
- 每个阶段的goroutine在**输入channel关闭且排空**后退出
- 每个阶段负责**close自己的输出channel**
- 用`defer close(out)`确保异常情况下也能关闭

**带context取消的Pipeline**：

```go
func generator(ctx context.Context, nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for _, n := range nums {
            select {
            case out <- n:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}
```

完整可运行代码见 [pattern/pipeline.go](pattern/pipeline.go)。


## 1.2 Fan-out / Fan-in

Fan-out：多个goroutine从**同一个channel**读取，实现并行处理。
Fan-in：将多个channel的结果**汇聚到一个channel**。

```
              ┌→ [worker1] ─┐
数据源 → ch ──┼→ [worker2] ─┼→ merge → 结果
              └→ [worker3] ─┘
```

```go
// Fan-out: 启动n个worker消费同一个channel
func fanOut(in <-chan int, workers int) []<-chan int {
    outs := make([]<-chan int, workers)
    for i := 0; i < workers; i++ {
        outs[i] = processStage(in) // 多个goroutine读同一个in
    }
    return outs
}

// Fan-in: 将多个channel合并为一个
func fanIn(channels ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    merged := make(chan int)

    for _, ch := range channels {
        wg.Add(1)
        go func(c <-chan int) {
            defer wg.Done()
            for v := range c {
                merged <- v
            }
        }(ch)
    }

    go func() {
        wg.Wait()
        close(merged)
    }()
    return merged
}
```

适用场景：
- CPU密集型处理（如图像处理、数据转换）
- I/O密集型处理（如批量HTTP请求、数据库查询）

完整代码见 [pattern/fanout.go](pattern/fanout.go)。


## 1.3 Worker Pool

Worker Pool是Fan-out模式的工程化版本，核心特点是**固定goroutine数量**，防止资源耗尽：

```go
func workerPool(ctx context.Context, jobs <-chan Job, results chan<- Result, workers int) {
    var wg sync.WaitGroup
    for i := 0; i < workers; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            for job := range jobs {
                select {
                case results <- process(job):
                case <-ctx.Done():
                    return
                }
            }
        }(i)
    }
    go func() {
        wg.Wait()
        close(results)
    }()
}
```

**Worker Pool vs 无限创建goroutine**：

| 维度 | Worker Pool | 无限goroutine |
|------|-----------|--------------|
| 内存 | 固定（workers × goroutine栈） | 不可控（可能OOM） |
| 调度 | GMP高效调度少量G | 大量G竞争，调度开销增大 |
| 背压 | 天然限流（jobs channel满则阻塞） | 无限制，可能压垮下游 |
| 适用 | 生产环境 | 快速原型/任务数已知且少 |

性能对比见 [pattern/workerpool_test.go](pattern/workerpool_test.go)。


## 1.4 errgroup实战

`golang.org/x/sync/errgroup` 是 `sync.WaitGroup` + `error` + `context` 的组合。
源码分析见 [sync/errgroup源码分析.md](../sync/errgroup源码分析.md)，此处聚焦实战模式。

**模式1：基本用法——首个错误返回**

```go
g, ctx := errgroup.WithContext(context.Background())

for _, url := range urls {
    g.Go(func() error {
        return fetch(ctx, url)
    })
}

if err := g.Wait(); err != nil {
    // 只返回第一个错误，ctx已被取消
    log.Fatal(err)
}
```

**模式2：限制并发度（Go 1.20+）**

```go
g, ctx := errgroup.WithContext(ctx)
g.SetLimit(10) // 最多10个goroutine同时运行

for _, url := range urls {
    g.Go(func() error {
        return fetch(ctx, url)
    })
}
```

`SetLimit`内部通过一个带缓冲的信号量channel实现，相当于内置的Worker Pool。

**模式3：收集所有错误**

errgroup只返回第一个错误。需要收集全部错误时，用channel或mutex手动聚合：

```go
g, ctx := errgroup.WithContext(ctx)
var (
    mu   sync.Mutex
    errs []error
)

for _, task := range tasks {
    g.Go(func() error {
        if err := process(ctx, task); err != nil {
            mu.Lock()
            errs = append(errs, fmt.Errorf("task %s: %w", task.ID, err))
            mu.Unlock()
            // 不return err——避免触发ctx取消影响其他task
        }
        return nil
    })
}

g.Wait()
if len(errs) > 0 {
    return errors.Join(errs...) // Go 1.20+ 多错误包装
}
```

完整代码见 [pattern/errgroup_patterns.go](pattern/errgroup_patterns.go)。


## 1.5 Or-done模式

任一goroutine完成即返回结果，常用于同时请求多个副本、取最快响应：

```go
func orDone(ctx context.Context, channels ...<-chan int) <-chan int {
    switch len(channels) {
    case 0:
        c := make(chan int)
        close(c)
        return c
    case 1:
        return channels[0]
    }

    orCh := make(chan int, 1)
    go func() {
        defer close(orCh)
        select {
        case v := <-channels[0]:
            orCh <- v
        case v := <-channels[1]:
            orCh <- v
        case <-ctx.Done():
        }
    }()
    return orCh
}
```

更通用的版本可递归合并任意数量的channel，但实践中通常配合`context`即可：

```go
ctx, cancel := context.WithCancel(context.Background())
defer cancel()

result := make(chan string, 1)
for _, replica := range replicas {
    go func(addr string) {
        resp, err := fetch(ctx, addr)
        if err == nil {
            select {
            case result <- resp:
            default:
            }
        }
    }(replica)
}

fastest := <-result
cancel() // 取消其他还在进行的请求
```


# 2 原子操作

## 2.1 atomic包全景

`sync/atomic`提供了硬件级别的原子操作，是最底层的同步原语：

| 操作 | 函数 | 语义 |
|------|------|------|
| 加 | `AddInt64(&x, delta)` | x += delta，返回新值 |
| 读 | `LoadInt64(&x)` | 原子读取，保证看到完整值 |
| 写 | `StoreInt64(&x, val)` | 原子写入 |
| 交换 | `SwapInt64(&x, new)` | 写入new，返回旧值 |
| CAS | `CompareAndSwapInt64(&x, old, new)` | x==old时写入new，返回是否成功 |

**为什么需要原子读写？**

在64位值的非原子读写中，32位CPU可能产生**撕裂读**（torn read）——
读到高32位是新值、低32位是旧值的混合状态。atomic保证读写的完整性。

```go
var counter int64

// 并发安全的自增
func increment() {
    atomic.AddInt64(&counter, 1)
}

// 并发安全的读取
func getCount() int64 {
    return atomic.LoadInt64(&counter)
}
```

## 2.2 atomic.Value

`atomic.Value`用于原子地存取任意类型的值，最典型的场景是**配置热更新**：

```go
var config atomic.Value // 存储 *Config 类型

// 初始化
config.Store(&Config{
    MaxConn: 100,
    Timeout: 30 * time.Second,
})

// 读取（无锁，极快）
func getConfig() *Config {
    return config.Load().(*Config)
}

// 更新（写入频率低，可以用锁保护写入顺序）
func updateConfig(newCfg *Config) {
    config.Store(newCfg)
}
```

**约束**：
- `Store`的值类型必须与首次`Store`的类型一致，否则panic
- 不能存nil
- 适合读多写少场景（读无锁，写有内存屏障开销）

## 2.3 类型化原子操作（Go 1.19+）

Go 1.19引入了类型安全的原子类型，消除了`int64`指针操作的繁琐：

```go
// 旧API：需要传指针，类型不安全
var old int64
atomic.AddInt64(&old, 1)

// 新API：方法调用，类型安全
var counter atomic.Int64
counter.Add(1)
val := counter.Load()
```

完整的类型化原子类型：

| 类型 | 方法 |
|------|------|
| `atomic.Bool` | `Load`, `Store`, `Swap`, `CompareAndSwap` |
| `atomic.Int32` | `Load`, `Store`, `Add`, `Swap`, `CompareAndSwap` |
| `atomic.Int64` | `Load`, `Store`, `Add`, `Swap`, `CompareAndSwap` |
| `atomic.Uint32` | `Load`, `Store`, `Add`, `Swap`, `CompareAndSwap` |
| `atomic.Uint64` | `Load`, `Store`, `Add`, `Swap`, `CompareAndSwap` |
| `atomic.Uintptr` | `Load`, `Store`, `Add`, `Swap`, `CompareAndSwap` |
| `atomic.Pointer[T]` | `Load`, `Store`, `Swap`, `CompareAndSwap` |

推荐在新代码中统一使用类型化API。

## 2.4 选型指南：atomic vs mutex vs channel

```
需要同步？
  │
  ├─ 通信/传递数据 → channel
  │
  ├─ 保护共享状态 →
  │    │
  │    ├─ 简单计数器/标志位/指针 → atomic
  │    │   (Add, Store, Load, CAS)
  │    │
  │    ├─ 读多写少的配置/状态 → atomic.Value
  │    │
  │    ├─ 复杂状态（多字段/条件判断） → Mutex/RWMutex
  │    │
  │    └─ 读多写少 + 复杂状态 → RWMutex
  │
  └─ 并发编排（等待/限流/一次性初始化） → sync包
       (WaitGroup, Once, Pool, errgroup)
```

性能参考（详细基准见 [lock/performance/atomic-replace-mutex/](../lock/performance/atomic-replace-mutex/)）：

| 操作 | atomic | Mutex | 差距 |
|------|--------|-------|------|
| 高竞争累加 | ~32 ns/op | ~62 ns/op | atomic快约1.95x |

**经验法则**：能用atomic就不用mutex，能用mutex就不用channel（从性能角度）。
但代码可读性也很重要——如果atomic的CAS循环让代码变得难以理解，mutex可能是更好的选择。

更多原子操作基准见 [performance/atomic_ops_test.go](performance/atomic_ops_test.go)。


# 3 数据竞争检测

## 3.1 什么是数据竞争

**数据竞争**（data race）在以下条件**同时满足**时发生：
1. 两个或更多goroutine**并发访问**同一内存位置
2. 至少有一个是**写操作**
3. 没有使用同步机制（锁、atomic、channel）

```go
// 经典数据竞争
var counter int

go func() { counter++ }() // goroutine 1: 读-改-写
go func() { counter++ }() // goroutine 2: 读-改-写
// 没有同步 → 数据竞争
```

**数据竞争 vs 竞态条件**：

| | 数据竞争 (Data Race) | 竞态条件 (Race Condition) |
|--|---------------------|-------------------------|
| 定义 | 并发无同步访问同一内存 | 程序结果依赖于执行顺序 |
| 检测 | `-race` 可精确检测 | 需要逻辑分析，工具无法检测 |
| 修复 | 加同步（atomic/锁/channel） | 调整逻辑顺序 |

可以没有数据竞争但有竞态条件（比如两个goroutine通过channel通信，但业务逻辑依赖消息顺序）。

## 3.2 -race原理

Go的`-race`标志基于Google的**ThreadSanitizer（TSan）**算法：

**编译期**：对每个内存访问插入检测代码（instrumentation）。

**运行时**：维护一个**shadow memory**，记录每个内存位置最近的访问信息：
- 哪个goroutine访问的
- 是读还是写
- 逻辑时间戳（vector clock）

```
原始代码                    插桩后
─────────                  ─────────
counter++         →        raceWrite(&counter)
                           counter++
```

**happens-before关系**：TSan通过分析同步原语（channel发送/接收、mutex Lock/Unlock、
atomic操作）建立happens-before关系图。如果两个访问之间没有happens-before关系，
且至少一个是写，则报告数据竞争。

**开销**：
- 内存：约5-10倍（shadow memory）
- CPU：约2-20倍（检测代码）
- 不建议在生产环境开启，但**CI中必须开启**

## 3.3 常见竞争模式

### 模式1：未保护的共享变量

```go
// 有竞争
var total int
for i := 0; i < 100; i++ {
    go func() { total++ }()
}

// 修复：用atomic
var total atomic.Int64
for i := 0; i < 100; i++ {
    go func() { total.Add(1) }()
}
```

### 模式2：map并发读写

```go
// 有竞争——map不是goroutine安全的
m := make(map[string]int)
go func() { m["a"] = 1 }()
go func() { _ = m["a"] }()

// 修复方案1：sync.Mutex
// 修复方案2：sync.Map（读多写少场景）
// 修复方案3：每个goroutine操作自己的map，最后merge
```

map的并发写甚至会触发`fatal error: concurrent map writes`，这不是panic，**无法recover**。

### 模式3：slice并发append

```go
// 有竞争——append可能触发扩容，修改底层数组指针
var s []int
for i := 0; i < 100; i++ {
    go func(v int) { s = append(s, v) }(i)
}

// 修复：预分配+索引写入（各写各的位置无竞争）
s := make([]int, 100)
for i := 0; i < 100; i++ {
    go func(idx int) { s[idx] = idx }(i)
}
```

### 模式4：用time.Sleep做"同步"

```go
// 错误：time.Sleep不建立happens-before关系
go func() { data = generateData() }()
time.Sleep(time.Second) // "等一下应该够了吧？"
process(data)           // 数据竞争！

// 正确：用channel/WaitGroup确保完成
done := make(chan struct{})
go func() {
    data = generateData()
    close(done)
}()
<-done
process(data)
```

完整的竞争示例和`-race`检测见 [trap/race_examples_test.go](trap/race_examples_test.go)。

## 3.4 实践

**开发阶段**：

```bash
# 运行测试时开启race检测
go test -race ./...

# 运行程序时开启race检测
go run -race main.go

# 编译带race检测的二进制
go build -race -o myapp
```

**CI集成**（推荐配置）：

```yaml
# GitHub Actions
- name: Test with race detection
  run: go test -race -count=1 ./...
```

**注意事项**：
- `-race`只能检测**运行时实际发生的**竞争，不能检测理论上可能的竞争
- 因此测试覆盖率越高，race检测越有效
- `-race`与`-cover`可以同时使用：`go test -race -cover ./...`
- race检测到竞争时程序会直接**exit(66)**，不是panic，无法recover

**解读race报告**：

```
==================
WARNING: DATA RACE
Read at 0x00c000126010 by goroutine 7:    ← 读操作的位置
  main.main.func1()
      /path/to/file.go:15 +0x3c

Previous write at 0x00c000126010 by goroutine 6:  ← 写操作的位置
  main.main.func2()
      /path/to/file.go:12 +0x50

Goroutine 7 (running) created at:           ← goroutine 7的创建位置
  main.main()
      /path/to/file.go:14 +0x84

Goroutine 6 (finished) created at:          ← goroutine 6的创建位置
  main.main()
      /path/to/file.go:11 +0x5c
==================
```

关键信息：**两个goroutine**、**内存地址**、**读/写操作**、**源码位置**。


# 4 总结

| 主题 | 核心要点 |
|------|---------|
| Pipeline | 每阶段一个goroutine + in/out channel，defer close输出channel |
| Fan-out/Fan-in | 多worker消费同一channel，WaitGroup等待后close合并channel |
| Worker Pool | 固定goroutine数量，天然背压，生产环境首选 |
| errgroup | WaitGroup + error + context 三合一，SetLimit内置限流 |
| Or-done | 取最快结果，配合context取消其余 |
| atomic | 硬件级同步，适合简单计数器/标志位/指针 |
| atomic.Value | 无锁配置热更新，读极快，写有屏障开销 |
| 类型化atomic | Go 1.19+ 推荐，类型安全，方法调用 |
| 选型 | channel传数据、atomic简单状态、mutex复杂状态 |
| 数据竞争 | 并发无同步访问同一内存，至少一个写 |
| -race | TSan算法，shadow memory + happens-before，CI必开 |
| 常见竞争 | 共享变量、map并发、slice并发、time.Sleep"同步" |
