
---
claude code token消耗优化
---

# 1 背景

claude code无疑是编码这个垂直领域内最强大的AI Coding Agent，但如果使用不当，其消耗token的速度是惊人的，这意味着，它
掏空我们钱包的速度会非常可怕，所以研究如何尽可能地降低token消耗，提高我们使用它完成任务的性价比，是很有必要的。


# 1 订阅计划与 API 限制的动态平衡

开发者在 Claude Code 中的操作受限于特定的计划配额。这些限额通常以 5 小时为窗口进行动
态滚动更新，采用令牌桶算法进行管理，这意味着容量是持续补充的，而非在固定时间点重置。


| 计划级别   | 5小时窗口内Token配额(估计) | 适用场景与性能特征          |
|--------|------------------|--------------------|
| Pro  | 44,000 Tokens          | 个人开发、中小型重构与日常调试任务。 |
| Max 5x | 88,000 Tokens          | 职业开发者、高强度的模块开发与系统设计。 |
| Max 20x | 220,000 Tokens             | 核心架构师、涉及大规模代码库的近乎自主的开发任务。 |
| API    | 基于余额，无固定窗口限制             | 具有可预测高容量需求的企业级自动化工作流 |




# 2 token消耗优化最佳实践

Claude Code 的“强大”来自它会把代码、命令输出、会话历史、CLAUDE.md、技能（skills）、MCP 工具、定义等持续装进上下文窗口；
而 token 花费（以及上下文占用）通常随这些内容在多轮对话中线性累积。因此，“不牺牲能力”前提下减少token消耗，本质是做 Context Engineering：
把上下文拆成“必须常驻”和“按需加载”，并把高噪声/大体量数据交给外部工具预处理，只把可支持推理的最小证据集交给模型。


一个可落地的优先级顺序（从“对效果最安全”到“更激进”）：
1) 先治输入端的“常驻膨胀”：精简 CLAUDE.md、减少/延迟 MCP 工具定义、用 skills 替代“永远加载”的长
说明、利用 Claude Code 的工具搜索阈值设置。

2) 再治理输入端的“过程噪声”：用 hooks 过滤日志/测试输出；把探索/检索/跑命令的详细过程交给
subagents；保持主对话只承载决策与变更要点。

3) 最后治输出端的“无效冗长”：默认要求“拆分分/补丁/最小解释”，把长报告写入文件或 artifact，而不是每
轮都粘在聊天里。

4) 如果你有 API 工作负载：在“重复上下文多”的场景启用 prompt caching 与 batch；更复杂的工具密集型
系统可考虑 Tool Search Tool 与 Programmatic Tool Calling 来避免工具定义与中间结果污染上下文。


## 2.1 基于任务的复杂度选择合适的模型

Opus 模型虽然在多步骤推理和长上下文检索中具有显著优势，但其成本通常是 Sonnet 的数倍，也就是说，Opus 4.5/4.6 等
高级模型的使用会比 Sonnet 模型更快地耗尽这些配额。因此，在模型选择上，除非面临极端复杂的架构挑战，否则将 Sonnet 
作为默认模型是实现成本效益平衡的首要准则。

原理：Claude Code 官方建议：Sonnet 足以覆盖大多数编码任务且更便宜；Opus 用于复杂架构决策/多步推
理；简单 subagent 任务可以指定 Haiku。
此外，extended thinking 的预算很大时会显著推高输出 token；官方给出降低 effort、 /config 禁用、或下
调 MAX_THINKING_TOKENS 的方法。

优点：不必牺牲能力——把“贵的推理”集中在真正需要的点。
缺点：需要你对任务分级；过度切换会增加流程复杂度。
适用场景：大需求拆分、架构/迁移方案、复杂 bug 推理用 Opus；执行/改文件/写测试多用 Sonnet；批量小任务用 Haiku。

示例工作流：
(1) Sonnet：收集上下文+给出实现计划
(2) Opus：只对计划的关键风险点做深推理/替代方案
(3) Sonnet：按计划实现+验证




## 2.2 分层上下文架构：文档与代码的高效组织

### 2.2.1 上下文窗口的物理边界与性能衰减
Claude 的上下文窗口虽然庞大，但在接近饱和时，模型往往会出现“幻觉”或忽略早期关键指令的现象 。这种性能降级通常发生在上下文
占用超过 70% 时。每一次文件读取、每一条 /grep 结果以及每一段错误日志，都会永久性地占据该会话的内存空间，直到触发自动压缩（
Auto-compaction）或手动清除。

要从根本上控制 Token 消耗，必须从项目的知识组织结构入手。传统的做法是将所有信息堆砌在CLAUDE.md 或 README 中，这会导致
Claude 在每次启动会话时都要读取大量冗余数据。

### 2.2.2 token 快速消耗的常见场景

- 第一类是“常驻上下文过大”。
例如：CLAUDE.md 过长、过多 skills 描述常驻、连接太多 MCP servers（即使 idle 也会把工具定义放进上下文）。官方明确提到：
每个 MCP server 都会把工具定义加入上下文；并建议用 / context 查看占用，用 /mcp 禁用不用的 server。 Anthropic 的工程
博客用更量化的例子说明：在多 server 设置中，仅工具定义就可能在会话开始前消耗 50K+ tokens，甚至 100K+ tokens。

- 第二类是“过程噪声被带回上下文”。
最典型的是：把 10,000 行日志、完整测试输出、或大型数据集原样回传 给 Claude；这些内容既挤占窗口，也会让模型注意力被噪声分散。
Claude Code 官方建议用 hooks 在进入模型前过滤命令输出，例如用 grep/head 只保留失败行，把“上万 tokens”压到“几百 tokens”。

- 第三类是“交互模式导致返工”。
当 prompt 含糊（如“改进整个代码库”）时，会触发更大范围扫描与更多文件读取；官方建议用更具体地请求 （指向文件与函数）来减少不必要
的上下文装配。 
同时，复杂任务如果直接实现可能走错方向而反复改动；官方建议先用 plan mode（相当于先做方案评审）并
尽早中止错误方向以减少昂贵返工。

- 第四类是“多代理并行的乘法效应”。
Claude Code 的 agent teams 会启动多个独立实例，每个都有自己的上下文窗口；官方成本页指出团队规模与运行时长会近似成比例放大 token，
并给出“plan mode 下大约 7 倍 token”的量级提示。

- 第五类是“推理参数导致输出暴涨”。
Claude Code 默认启用 extended thinking，预算可达 31,999 tokens； 官方指出它能显著提升复杂规划/推理表现，但 thinking tokens 
作为输出 token 计费，因此简单任务应降低 effort 或下调 thinking 预算。


### 2.2.3 三层上下文治理模型
一种被验证有效地优化策略是实施“三层上下文架构” ，将知识按需进行隔离。这种方法的核心在于利用 Claude 的文件检索工具来替代全量载入。

- 第一层：关键全局上下文（Critical Context） 
此层级的信息应存放在根目录的 CLAUDE.md 中。它必须保持极度地简洁（建议少于 200 行或 1,000 Tokens），仅包含项目名称、核心技术
栈、绝对禁令（如“严禁提交 secrets”）以及最常用地构建命令。

- 第二层：按需加载的语境信息（Contextual on Demand） 
将详细的 API 定义、数据库架构（Schema）和测试规范移动到 docs/ 文件夹下独立的文件中。在 CLAUDE.md 中，仅保留指向这些文件的索引（例如：
“API 定义请参考 docs/api.md”）。只有当 Claude 实际执行涉及这些模块的任务时，它才会通过读取操作消耗这部分 Token。

- 第三层：被动参考资料（Reference Material） 
包括历史变更记录、旧版本的存档文档或第三方库的完整规格书。这些内容应存放在更深层的子目录中，甚至不应出现在工作目录内，以防止 Claude 的自动
索引机制误读。


## 2.3 利用 SKILL.md 进行指令解耦
对于特定领域的知识或复杂的重复性任务流程（如 PR 审核清单, Code Review），使用 Claude Code 的“技能（ Skills）”机制比直接写入 CLAUDE.md 
更具 Token 优势。技能文件（SKILL.md）仅在被显式调用，或模型判断需要时才会载入内存，这有效地避免了在简单任务中携带沉重的指令负担。

原理：CLAUDE.md 在 session start 进入上下文并在后续请求中常驻；如果它包含大量“只偶尔用”的工作流说明，会导致每轮输入都背负这部分 token。
官方建议把专门工作流移到 skills（按需加载），并给出“CLAUDE.md 尽量 <~500 行”的经验性建议。

优点：对能力影响最小，且往往是“长期复利”。
缺点：需要一些信息架构工作（拆分、命名、组织技能）。
适用场景：团队统一规范、多工作流（review、deploy、migration）混在一个 CLAUDE.md。

步骤：
1) CLAUDE.md 只保留“所有任务都必须遵守”的规则（构建/测试命令、目录结构、编码规范、危险操作禁令）；
2) 把“某类任务才需要”的内容做成 skill（如 /review-pr、 /db-migrate ）；
3) 对“只想手动触发”的 skill 设置 disable-model-invocation: true ，让描述也不常驻上下文。

skill 前言示例：
---
name: review-pr
description: 运行 PR review 清单（安全/性能/可维护性）
disable-model-invocation: true
---


## 2.4 自适应思维（Adaptive Thinking）与努力级别（Effort）
模型自身的配置参数是控制消耗的直接杠杆。随着 Opus 4.6 的发布，Anthropic 引入了更智能的资源管理机制，旨在通过自适应推理来平衡质量与成本。

Opus 4.6 弃用了传统的固定 Token 预算模式，转而采用自适应思维。这一机制允许模型根据任务难度自动分配推理资源。开发者可以通过 effort 参数
提供软性引导，从而在微小任务中节省昂贵的输出 Token。


| 努力级别(Effort Level) | 行为描述           | Token 消耗与成本影响     |
|--------------------|----------------|-----------------|
| low                | 最小化思考过程，追求响应速度。  | 最低消耗，适合重命名、格式化等简单任务。|
| medium             | 中度思考，仅在必要时启动深入推理。  | 适中，适合标准功能开发。|
| high (默认)            | 始终进行深度思考。 | 较高，保证复杂问题的解决质量。|
| max                 | 不受限制的思考深度   | 最高，仅建议用于攻克极具挑战性的逻辑难题。|


**在 Claude Code 中设置 effort 的三种方式**

- 第一种，交互式（推荐，最灵活）。 在 /model 中使用左右方向键调整 effort 滑块
在 Claude Code 会话中输入 /model，选中 Opus 4.6 后用 ← → 方向键调节 effort。

- 第二种，通过环境变量设置，全局生效。CLAUDE_CODE_EFFORT_LEVEL=low|medium|high
```shell
# 加到 ~/.zshrc 或 ~/.bashrc
export CLAUDE_CODE_EFFORT_LEVEL=medium
```

- 第三种，在 settings 文件中设置 effortLevel
```shell
# ~/.claude/settings.json
{
  "effortLevel": "medium"
}
```

## 2.5 利用提示词缓存（Prompt Caching）
Claude API 的一个核心经济优势是提示词缓存。Claude Code 会自动缓存系统提示词、工具定义以及相对稳定的历史对话部分。只有未命中的部分（Uncached tokens）
才会被计入高额的 ITPM 限制。为了最大化缓存命中率，开发者应尽量保持 CLAUDE.md 的稳定，并避免在会话中频繁修改全局指令，因为任何微小的改动都会导致后续的所有
缓存失效，从而增加重复写入的成本。

提示词缓存不仅仅是"API 功能"，Claude Code CLI 作为 API 的消费者，已经自动帮你利用了这项能力。 你需要做的只是别破坏它——保持 CLAUDE.md 稳定、
避免频繁切换 MCP 服务器配置、在单个会话内保持 5 分钟内持续交互即可。

原理：prompt caching 可缓存请求前缀；命中要求前缀 100% 一致。
成本上：5m 缓存写入是 base 输入价的 1.25 倍，读取是 0.1 倍；还可用 1h TTL（写入更贵），并支持多个
cache breakpoints。
文档也指出缓存不会改变输出内容（质量不变）。
优点：当你有大量重复系统提示/工具定义/背景上下文时，成本可显著下降；并且 cache hits 有助于速率利用
（文档给出了“cache hits 不从 rate limit 中扣减”的使用动机）。
缺点：对“每次都变化”的前缀几乎无效；需要工程实现与缓存命中监控。
适用场景：多轮 agent、同一套 system prompt/工具定义反复使用、批量处理同类任务。


## 2.6 高效的工作流习惯(Explore-Plan-Code)
优化技巧并非仅限于配置文件的修改，开发者的交互方式对 Token 的利用率有着决定性的影响。遵循“Explore-Plan-Code”的思维框架可以显著减少无效的尝试。

### 2.6.1 规划模式（Plan Mode）的强制性应用
直接让 Claude 开始编写代码通常会导致模型在未充分理解代码库的情况下产生错误的实现，从而引发代价昂贵的纠错循环。通过按下 Shift+Tab 进入规划模式，
开发者可以强制模型先进行调研并提交一份书面计划供审核。这种前置的逻辑校验能减少约 30-40% 的无效代码生成消耗，因为它在 Token 还没被浪费在具体的
错误代码上时就修正了方向。

### 2.6.2 增量验证与测试驱动开发 (TDD)
通过提供明确的验证目标（如现有的单元测试或预期的输出截图），Claude 可以实现自主的闭环验证。采用 TDD 流程——即先让 Claude 编写测试，确认测试失败，
然后再编写实现代码——可以确保模型始终朝着正确的方向前进，避免了因为理解偏差而导致的推倒重来。每次只实现一小段逻辑并立即验证，比一次性请求跨越十个
文件的庞大功能要高效得多。


## 2.7 会话生命周期管理
过长地会话是 Token 消耗的元凶。当一个子任务完成后，应养成使用 /clear 命令的习惯。如果担心丢失之前的状态，可以使用 /rename 为当前会话命名，
待需要时再通过 /resume 找回，而不是让旧地调试日志污染新地开发语境。如果连续两次对同一问题的修复都告失败，说明当前上下文已经充满了错误的逻辑路径，
此时最明智的选择是 /rewind 到最近的正确状态或干脆 /clear 重新开始。

原理：Claude 的历史会线性累积； /clear （或重启 session）相当于把“历史项”归零，让后续请求不再重
复背负旧上下文。
优点：几乎不损失能力（前提是你把关键规则/状态放在可重载的位置）。
缺点：会丢失“对话里才有”的中间结论，需要你提前做摘要/落盘。
适用场景：任务切换、长会话纠错多次、或已完成一个 feature/bugfix。
步骤：
1) 把当前状态写入短文件（如 SESSION_STATE.md ）；
2) /rename （便于之后用 /resume 找到）；
3) /clear；
4) 让 Claude 先读取 SESSION_STATE.md （必要时再读取相关文件）。
   
示例提示词（CLI）：
把当前进度写入 SESSION_STATE.md：包括完成了什么、修改了哪些文件、如何复现、下一步建议。
然后我会 /clear。清理后你只需要先读取 SESSION_STATE.md 和相关文件再继续。


## 2.8 工具化优化：MCP 与终端输出的精细控制

模型上下文协议（MCP）极大地扩展了 Claude Code 的能力，但同时也带来了沉重的“工具税”。

### 2.8.1 应对 MCP 服务器带来的上下文膨胀
每一个加载的 MCP 服务器都会将其所有的工具定义注入上下文。拥有 7-8 个服务器的配置可能会在会话开始前就吞噬掉超过 60,000 个 Tokens。


| 常见 MCP 服务示例 | 包含工具数量           | Token 开销（估算）    |
|--------------------|---------------|-----------------|
| GitHub                | 35 工具  | ~26,000 Tokens|
| Slack             | 11 工具  | ~21,000 Tokens|
| Jira            | 15 工具  | ~17,000 Tokens|
| Sentry                  | 5 工具  | ~3,000 Tokens|


为了解决这一问题，Claude Code 引入了 ENABLE TOOL SEARCH 机制。通过将该变量设置为 auto:5（即当工具定义占用超过 5% 的上下文时启动搜索模式），
模型将不再预加载所有工具，而是根据需求动态搜索并加载必要的定义。这种延迟加载（Lazy-loading）策略可以将工具开销降低 90% 以上。

注意，虽然Tool Search 是默认启用的，但社区中有多个 bug 报告反映 auto 模式没有按预期触发。所以，如果你使用了多个 MCP 服务器
（特别是 GitHub、Slack、Jira 这类工具数量多的），建议主动确认一下：

```shell
# 1. 先用 /context 命令检查 MCP 工具实际占用了多少上下文
/context

# 2. 如果发现工具占用过高但 Tool Search 没自动触发，手动启用：
# 方式一：环境变量
export ENABLE_TOOL_SEARCH=true
# 重启claude
claude

# 方式二：使用自定义阈值（比如 5%）
export ENABLE_TOOL_SEARCH=auto:5
# 重启claude
claude

# 方式三：写入 settings.json 永久生效
# ~/.claude/settings.json
{
  "env": {
    "ENABLE_TOOL_SEARCH": "true"
  }
}
```

原理：当工具库很大时，把所有工具定义塞进上下文会产生巨额固定开销；Tool Search Tool 允许按需发现工具，官方示例中将会话开始前的工具
定义开销从“数万 tokens”降到约 8.7K，并给出约 85% token 降幅与准确率提升的内部测试数据。
Programmatic Tool Calling 则把大量中间结果留在代码执行环境中处理，仅把最终摘要进入上下文；文中给出平均 token 用量从 43,588 降到
27,297（约 37%）的内部测试数据。
优点：在“大工具/大数据/多步流程”下通常是最高 ROI 的结构性优化。
缺点：工程复杂度高；更适合“你在做自己的 agent 系统”，而非纯 CLI 用户。


### 2.8.2 终端输出与 Bash 截断策略

过大的终端输出是另一个被忽视的 Token 消耗点。如果 Claude 运行了一个生成 10,000 行日志的命令，整个输出都会被强制塞进上下文，甚至可能直接刷爆窗口。通过配置
BASH MAX OUTPUT LENGTH，开发者可以控制 Bash 工具返回的最大字符数（默认为 30,000）。当输出超限时，Claude 会采用“中间截断”法，保留头部和尾部的关键信息，
这既节省了空间， 又保留了最有价值的错误堆栈末端信息。此外，对于 typed languages，使用专门的代码智能插件（Code Intelligence Plugins）可以使
Claude 通过精确的符号导航（如“跳转到定义”）而非昂贵的全量文本搜索或读取整个文件来获取信息，这在大型单体库（Monorepo）中尤为有效。

虽然默认值已经存在，但社区对"30,000 应该调高还是调低"有不同看法：
有的开发者选择把它调低到 20,000 来进一步减少 Token 消耗（因为 30,000 字符大约是 7,500-10,000 Token，调低到 20,000 字符可以省下约 2,500-3,000 Token/次）。

配置方式
```shell
# 方式一：环境变量（当前终端会话）
export BASH_MAX_OUTPUT_LENGTH=20000
claude

# 方式二：写入 shell profile（永久生效）
echo 'export BASH_MAX_OUTPUT_LENGTH=20000' >> ~/.zshrc
source ~/.zshrc

# 方式三：settings.json（推荐，跟其他配置统一管理）
# ~/.claude/settings.json
{
  "env": {
    "BASH_MAX_OUTPUT_LENGTH": "20000"
  }
}
```

**实操建议**
默认的 30K 字符对大多数场景够用了。但如果你经常跑测试套件、编译日志、或者大型 git log 输出，可以考虑将它调到 15,000-20,000。不过不建议设得太低
（比如 5,000），否则你可能会丢失关键的错误信息，导致 Claude 无法正确诊断问题，反而需要更多轮对话来解决——最终 Token 消耗可能更高。
另外，除了被动截断，你还可以在 CLAUDE.md 中加上主动策略引导 Claude：

```markdown
## Bash 输出规范
- 运行测试时使用 `npm test -- --reporter=dot` 而非默认 verbose 输出
- 查看日志时使用 `tail -n 50` 而非 `cat`
- 编译错误用 `2>&1 | head -100` 截取
```

这样 Claude 在源头就会产生更精简的输出，比依赖截断更高效。


## 2.9 高级上下文工程：Compaction 与隔离技术
在处理超长任务时，Claude Code 会自动执行上下文压缩（Compaction）。深入了解这一机制的运作方式，有助于我们在模型开始遗忘之前采取主动措施。

### 2.9.1 服务器端压缩（Server-side Compaction）
Opus 4.6 引入的服务器端压缩功能可以在会话接近限制时自动生成总结并替换旧消息。开发者可以通过 /compact 命令并附带具体指令来引导压缩过程，
例如执行 /compact Focus on the API changes and ignore previous test logs。这样可以确保在减少 Token 数量的同时，最关键的技
术决策和代码片段得以保留。

原理：compaction 用更短地总结替换长历史以释放窗口；Claude Code 支持通过 /compact <focus> 或在
CLAUDE.md 中添加 “Compact instructions” 指导总结时“保留什么”。
优点：可继续在同一 session 内推进；比硬性断档更顺滑。
缺点：本质有损；如果保存策略不当，会导致“模型忘记关键约束”，需要补充重载。
适用场景：长链路任务进行到“里程碑点”（例如完成实现并通过测试），需要保留关键决策但不再需要大量
过程细节。

步骤：
1) 在 CLAUDE.md 增加 compact 指令（例如“保留修改文件清单与测试命令”）；
2) 运行 /compact Focus on ... ；
3) 运行 /context 检查；必要时补充读取关键文件。
   
示例：
/compact Focus on: (1) modified files list, (2) API behavior changes, (3) test commands &
results, (4) remaining TODOs.


### 2.9.2 隔离与排除 - .claudeignore 的作用
如果 Claude Code 在扫描文件系统时“窥视”了不相关的文件夹，它会将这些文件的结构信息甚至内容带入语境。实施严格的 .claudeignore 策略至关重要。
这不仅是为了安全（防止读取 .env 等敏感文件），更是为了性能优化。

应在 .claudeignore 中包含以下常见路径，以防止无效的 Token 支出：
- 构建产物：dist/, build/, out/
- 依赖包：node_modules/, venv/, .pyenv/
- 大型临时文件：tmp/, log/, .cache/
- 静态资源：大型图片、视频文件夹（除非正在开发多媒体功能）

对于极其敏感的密钥文件，除了 ignore 规则，还应在 settings.json 的 permissions.deny 中显式封锁读取权限，因为某些检索机制可能会绕过简单的
ignore 文件。

## 2.10 用 hooks 做“确定性预处理” - 把大输出变小输出
原理：hooks 在模型之外执行脚本；可以在 Claude 看到结果前过滤数据，例如把测试输出裁剪成只包含 FAIL/ ERROR 的 100 行，避免把上万行塞进上下文。
优点：极高的 token ROI；同时减少噪声，往往还能提升推理准确率。
缺点：过滤规则写得不好可能丢失关键信息；需要维护脚本。
适用场景：日志分析、测试失败定位、CI 输出、lint 报告、长编译错误。

步骤：
1) 把常见的“大输出命令”识别出来（pytest/go test/npm test 等）；
2) 写 PreToolUse hook：在命令执行前把命令改写为“仅输出失败片段”；
3) 把“完整输出”保存到文件供人工/后续按需读取。


## 2.11 让 prompt “具体且可验证-把输出限制为“可执行最小产物”
原理：含糊请求会触发更大范围扫描与更多文件读取；官方明确建议用具体目标（文件/函数/行为）减少不必要上下文。

同时要求输出 diff/patch 与命令，而不是长解释，可显著压缩输出 token（且更利于 review）。
优点：低成本、高收益；往往也提升正确率。
缺点：需要你前置给出验收与限制。
适用场景：任何任务。
提示词模板：
目标：在 auth.ts 的 login() 增加 input validation（空/长度/格式）。
范围：只修改 auth.ts 与其单元测试；不要重构其他模块。
验收：npm test 通过；新增测试覆盖无效输入。
输出：先给出 plan（≤10 行），获批后只输出 unified diff，并给出运行的命令。

## 2.12 Batch API：对非实时任务直接 50% 折扣
原理：Claude API 的 Batch API 支持异步批处理大量请求，并对输入与输出 token 都提供 50% 折扣；也可与prompt caching 叠加。
优点：在不影响单次质量的情况下，直接降成本。
缺点：非实时；需要作业队列与结果收集。
适用场景：批量 code review、生成文档、迁移建议、离线评测与回归实验。



| 策略                                   | 预期节省          | 实现复杂度 | 对能力影响 | 适用场景               |
|--------------------------------------|---------------|-------|-----|--------------------|
| 精简 CLAUDE.md、拆分 skills               | 10%-40%       | 中     | 极低(更稳) | 长期使用、团队规范多、monorepo |
| 减少/延迟 MCP 工具定义（mcp + tool search 阈值） | 10%–70%       | 中     | 低   | MCP servers 多、但每次只用少数 |
| hooks 预处理（过滤日志/测试输出）                 | 20%–90%（视输出体量） | 中     | 低–中（看过滤是否丢信号） | CI/日志/编译错误很长       |
| subagents （主对话只拿总结）                  | 15%–60%       | 低-中   | 低   | 全库检索、架构梳理、复杂排查     |
| 清晰 prompt + 限制输出为 diff/patch         | 10%–50%       | 低     | 低（常提升正确率） | 绝大多数编码任务           |
| /clear 分段（配合落盘摘要）                    | 10%–60%（视对话长度） | 低     | 低   | 多任务切换、长会话纠错多       |
| /compact（带保留指令）                      | 5%–40%        | 低     | 中（有损） | 单任务极长，但可接受总结替换     |
| 降低 extended thinking（effort)         | 5%–60%(输出侧)   | 低     | 中–高（复杂推理可能变差） | 简单任务、机械执行、已确认方案    |
| API prompt caching                 | 成本 10%–70%    | 中–高   | 无（输出不变） | 重复系统提示/背景多、并发多     |
| Batch API（异步 50% 折扣）                | 50%           | 中     | 无   | 离线批处理、评测、批量 review |
| Tool Search Tool（API）                  | 输入 30%–85%  | 高     | 低–中 | 工具库巨大（10+ 工具/多 MCP）        |
| Programmatic Tool Calling（API）                 | 20%–60%  | 高     | 低–中 | 多工具、多步、大中间结果       |


# 3 子代理与代理团队
当单一会话的上下文容量不足以承载整个大型项目时，横向扩展智能水平是唯一的出路。

## 3.1 子代理（Subagents）的任务委派
Claude Code 允许创建专门的子代理来处理隔离的任务，例如“让子代理去分析 docs 目录并写出一份迁移草案”。这种模式的优势在于，子代理在阅读大量文档
或执行冗长命令时消耗的 Token 不会污染主会话的上下文窗口。只有经过精炼后的结果才会返回给主代理，从而显著延长了主会话的寿命。

原理：subagent 在隔离的上下文窗口中运行，结束后只把总结回传主对话；官方强调 subagents 能避免“读大量文件导致主对话上下文膨胀”。
优点：对主对话几乎“零污染”；复杂 repo 探索更可控。
缺点：多一次协调；如果总结不充分，主对话仍需补读。
适用场景：定位某模块实现、全库搜索、依赖与调用链梳理、性能瓶颈排查、文档/规范收集。

示例提示词：
用 subagent 调查：auth 模块的 token refresh 流程与 OAuth 复用点。返回：
1) 关键文件列表 2) 关键函数签名 3) 可复用工具/中间件 4) 风险与建议
主对话不需要完整文件内容。

## 3.2 代理团队（Agent Teams）的经济考量
代理团队模式允许并行处理复杂的工程任务，但这也意味着 Token 消耗会随着团队规模成倍增长。在团队模式下，每位成员都拥有独立的上下文窗口。官方数据显示，
团队模式在规划阶段的 Token 消耗量约为标准模式的 7 倍。因此，只有在任务高度解耦且时间效率高于资金预算的情况下，才应开启 CLAUDE CODE EXPERIMENTAL AGENT TEAMS=1。